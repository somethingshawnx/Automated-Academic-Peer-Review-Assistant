[
    {
        "title": "Lecture Notes: Optimization for Machine Learning",
        "abstract": "Lecture notes on optimization for machine learning, derived from a course at\nPrinceton University and tutorials given in MLSS, Buenos Aires, as well as\nSimons Foundation, Berkeley.",
        "link": "http://arxiv.org/abs/1909.03550v1",
        "published": "2019-09-08T21:49:42Z",
        "pdf_url": "http://arxiv.org/pdf/1909.03550v1.pdf",
        "txt_path": "data/txt/machine learning_paper_1.txt",
        "pdf_path": "data/pdfs/machine learning_paper_1.pdf"
    },
    {
        "title": "An Optimal Control View of Adversarial Machine Learning",
        "abstract": "I describe an optimal control view of adversarial machine learning, where the\ndynamical system is the machine learner, the input are adversarial actions, and\nthe control costs are defined by the adversary's goals to do harm and be hard\nto detect. This view encompasses many types of adversarial machine learning,\nincluding test-item attacks, training-data poisoning, and adversarial reward\nshaping. The view encourages adversarial machine learning researcher to utilize\nadvances in control theory and reinforcement learning.",
        "link": "http://arxiv.org/abs/1811.04422v1",
        "published": "2018-11-11T14:28:34Z",
        "pdf_url": "http://arxiv.org/pdf/1811.04422v1.pdf",
        "txt_path": "data/txt/machine learning_paper_2.txt",
        "pdf_path": "data/pdfs/machine learning_paper_2.pdf"
    },
    {
        "title": "Minimax deviation strategies for machine learning and recognition with\n  short learning samples",
        "abstract": "The article is devoted to the problem of small learning samples in machine\nlearning. The flaws of maximum likelihood learning and minimax learning are\nlooked into and the concept of minimax deviation learning is introduced that is\nfree of those flaws.",
        "link": "http://arxiv.org/abs/1707.04849v1",
        "published": "2017-07-16T09:15:08Z",
        "pdf_url": "http://arxiv.org/pdf/1707.04849v1.pdf",
        "txt_path": "data/txt/machine learning_paper_3.txt",
        "pdf_path": "data/pdfs/machine learning_paper_3.pdf"
    },
    {
        "title": "Machine Learning for Clinical Predictive Analytics",
        "abstract": "In this chapter, we provide a brief overview of applying machine learning\ntechniques for clinical prediction tasks. We begin with a quick introduction to\nthe concepts of machine learning and outline some of the most common machine\nlearning algorithms. Next, we demonstrate how to apply the algorithms with\nappropriate toolkits to conduct machine learning experiments for clinical\nprediction tasks. The objectives of this chapter are to (1) understand the\nbasics of machine learning techniques and the reasons behind why they are\nuseful for solving clinical prediction problems, (2) understand the intuition\nbehind some machine learning models, including regression, decision trees, and\nsupport vector machines, and (3) understand how to apply these models to\nclinical prediction problems using publicly available datasets via case\nstudies.",
        "link": "http://arxiv.org/abs/1909.09246v1",
        "published": "2019-09-19T22:02:00Z",
        "pdf_url": "http://arxiv.org/pdf/1909.09246v1.pdf",
        "txt_path": "data/txt/machine learning_paper_4.txt",
        "pdf_path": "data/pdfs/machine learning_paper_4.pdf"
    },
    {
        "title": "Towards Modular Machine Learning Solution Development: Benefits and\n  Trade-offs",
        "abstract": "Machine learning technologies have demonstrated immense capabilities in\nvarious domains. They play a key role in the success of modern businesses.\nHowever, adoption of machine learning technologies has a lot of untouched\npotential. Cost of developing custom machine learning solutions that solve\nunique business problems is a major inhibitor to far-reaching adoption of\nmachine learning technologies. We recognize that the monolithic nature\nprevalent in today's machine learning applications stands in the way of\nefficient and cost effective customized machine learning solution development.\nIn this work we explore the benefits of modular machine learning solutions and\ndiscuss how modular machine learning solutions can overcome some of the major\nsolution engineering limitations of monolithic machine learning solutions. We\nanalyze the trade-offs between modular and monolithic machine learning\nsolutions through three deep learning problems; one text based and the two\nimage based. Our experimental results show that modular machine learning\nsolutions have a promising potential to reap the solution engineering\nadvantages of modularity while gaining performance and data advantages in a way\nthe monolithic machine learning solutions do not permit.",
        "link": "http://arxiv.org/abs/2301.09753v1",
        "published": "2023-01-23T22:54:34Z",
        "pdf_url": "http://arxiv.org/pdf/2301.09753v1.pdf",
        "txt_path": "data/txt/machine learning_paper_5.txt",
        "pdf_path": "data/pdfs/machine learning_paper_5.pdf"
    },
    {
        "title": "Introduction to Machine Learning: Class Notes 67577",
        "abstract": "Introduction to Machine learning covering Statistical Inference (Bayes, EM,\nML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering),\nand PAC learning (the Formal model, VC dimension, Double Sampling theorem).",
        "link": "http://arxiv.org/abs/0904.3664v1",
        "published": "2009-04-23T11:40:57Z",
        "pdf_url": "http://arxiv.org/pdf/0904.3664v1.pdf",
        "txt_path": "data/txt/machine learning_paper_6.txt",
        "pdf_path": "data/pdfs/machine learning_paper_6.pdf"
    },
    {
        "title": "The Tribes of Machine Learning and the Realm of Computer Architecture",
        "abstract": "Machine learning techniques have influenced the field of computer\narchitecture like many other fields. This paper studies how the fundamental\nmachine learning techniques can be applied towards computer architecture\nproblems. We also provide a detailed survey of computer architecture research\nthat employs different machine learning methods. Finally, we present some\nfuture opportunities and the outstanding challenges that need to be overcome to\nexploit full potential of machine learning for computer architecture.",
        "link": "http://arxiv.org/abs/2012.04105v1",
        "published": "2020-12-07T23:10:51Z",
        "pdf_url": "http://arxiv.org/pdf/2012.04105v1.pdf",
        "txt_path": "data/txt/machine learning_paper_7.txt",
        "pdf_path": "data/pdfs/machine learning_paper_7.pdf"
    },
    {
        "title": "A Machine Learning Tutorial for Operational Meteorology, Part I:\n  Traditional Machine Learning",
        "abstract": "Recently, the use of machine learning in meteorology has increased greatly.\nWhile many machine learning methods are not new, university classes on machine\nlearning are largely unavailable to meteorology students and are not required\nto become a meteorologist. The lack of formal instruction has contributed to\nperception that machine learning methods are 'black boxes' and thus end-users\nare hesitant to apply the machine learning methods in their every day workflow.\nTo reduce the opaqueness of machine learning methods and lower hesitancy\ntowards machine learning in meteorology, this paper provides a survey of some\nof the most common machine learning methods. A familiar meteorological example\nis used to contextualize the machine learning methods while also discussing\nmachine learning topics using plain language. The following machine learning\nmethods are demonstrated: linear regression; logistic regression; decision\ntrees; random forest; gradient boosted decision trees; naive Bayes; and support\nvector machines. Beyond discussing the different methods, the paper also\ncontains discussions on the general machine learning process as well as best\npractices to enable readers to apply machine learning to their own datasets.\nFurthermore, all code (in the form of Jupyter notebooks and Google Colaboratory\nnotebooks) used to make the examples in the paper is provided in an effort to\ncatalyse the use of machine learning in meteorology.",
        "link": "http://arxiv.org/abs/2204.07492v2",
        "published": "2022-04-15T14:48:04Z",
        "pdf_url": "http://arxiv.org/pdf/2204.07492v2.pdf",
        "txt_path": "data/txt/machine learning_paper_8.txt",
        "pdf_path": "data/pdfs/machine learning_paper_8.pdf"
    },
    {
        "title": "Understanding Bias in Machine Learning",
        "abstract": "Bias is known to be an impediment to fair decisions in many domains such as\nhuman resources, the public sector, health care etc. Recently, hope has been\nexpressed that the use of machine learning methods for taking such decisions\nwould diminish or even resolve the problem. At the same time, machine learning\nexperts warn that machine learning models can be biased as well. In this\narticle, our goal is to explain the issue of bias in machine learning from a\ntechnical perspective and to illustrate the impact that biased data can have on\na machine learning model. To reach such a goal, we develop interactive plots to\nvisualizing the bias learned from synthetic data.",
        "link": "http://arxiv.org/abs/1909.01866v1",
        "published": "2019-09-02T20:36:19Z",
        "pdf_url": "http://arxiv.org/pdf/1909.01866v1.pdf",
        "txt_path": "data/txt/machine learning_paper_9.txt",
        "pdf_path": "data/pdfs/machine learning_paper_9.pdf"
    },
    {
        "title": "Position Paper: Towards Transparent Machine Learning",
        "abstract": "Transparent machine learning is introduced as an alternative form of machine\nlearning, where both the model and the learning system are represented in\nsource code form. The goal of this project is to enable direct human\nunderstanding of machine learning models, giving us the ability to learn,\nverify, and refine them as programs. If solved, this technology could represent\na best-case scenario for the safety and security of AI systems going forward.",
        "link": "http://arxiv.org/abs/1911.06612v1",
        "published": "2019-11-12T10:49:55Z",
        "pdf_url": "http://arxiv.org/pdf/1911.06612v1.pdf",
        "txt_path": "data/txt/machine learning_paper_10.txt",
        "pdf_path": "data/pdfs/machine learning_paper_10.pdf"
    },
    {
        "title": "A Unified Analytical Framework for Trustable Machine Learning and\n  Automation Running with Blockchain",
        "abstract": "Traditional machine learning algorithms use data from databases that are\nmutable, and therefore the data cannot be fully trusted. Also, the machine\nlearning process is difficult to automate. This paper proposes building a\ntrustable machine learning system by using blockchain technology, which can\nstore data in a permanent and immutable way. In addition, smart contracts are\nused to automate the machine learning process. This paper makes three\ncontributions. First, it establishes a link between machine learning technology\nand blockchain technology. Previously, machine learning and blockchain have\nbeen considered two independent technologies without an obvious link. Second,\nit proposes a unified analytical framework for trustable machine learning by\nusing blockchain technology. This unified framework solves both the\ntrustability and automation issues in machine learning. Third, it enables a\ncomputer to translate core machine learning implementation from a single thread\non a single machine to multiple threads on multiple machines running with\nblockchain by using a unified approach. The paper uses association rule mining\nas an example to demonstrate how trustable machine learning can be implemented\nwith blockchain, and it shows how this approach can be used to analyze opioid\nprescriptions to help combat the opioid crisis.",
        "link": "http://arxiv.org/abs/1903.08801v1",
        "published": "2019-03-21T02:17:08Z",
        "pdf_url": "http://arxiv.org/pdf/1903.08801v1.pdf",
        "txt_path": "data/txt/machine learning_paper_11.txt",
        "pdf_path": "data/pdfs/machine learning_paper_11.pdf"
    },
    {
        "title": "MLBench: How Good Are Machine Learning Clouds for Binary Classification\n  Tasks on Structured Data?",
        "abstract": "We conduct an empirical study of machine learning functionalities provided by\nmajor cloud service providers, which we call machine learning clouds. Machine\nlearning clouds hold the promise of hiding all the sophistication of running\nlarge-scale machine learning: Instead of specifying how to run a machine\nlearning task, users only specify what machine learning task to run and the\ncloud figures out the rest. Raising the level of abstraction, however, rarely\ncomes free - a performance penalty is possible. How good, then, are current\nmachine learning clouds on real-world machine learning workloads?\n  We study this question with a focus on binary classication problems. We\npresent mlbench, a novel benchmark constructed by harvesting datasets from\nKaggle competitions. We then compare the performance of the top winning code\navailable from Kaggle with that of running machine learning clouds from both\nAzure and Amazon on mlbench. Our comparative study reveals the strength and\nweakness of existing machine learning clouds and points out potential future\ndirections for improvement.",
        "link": "http://arxiv.org/abs/1707.09562v3",
        "published": "2017-07-29T21:59:18Z",
        "pdf_url": "http://arxiv.org/pdf/1707.09562v3.pdf",
        "txt_path": "data/txt/machine learning_paper_12.txt",
        "pdf_path": "data/pdfs/machine learning_paper_12.pdf"
    },
    {
        "title": "Data Pricing in Machine Learning Pipelines",
        "abstract": "Machine learning is disruptive. At the same time, machine learning can only\nsucceed by collaboration among many parties in multiple steps naturally as\npipelines in an eco-system, such as collecting data for possible machine\nlearning applications, collaboratively training models by multiple parties and\ndelivering machine learning services to end users. Data is critical and\npenetrating in the whole machine learning pipelines. As machine learning\npipelines involve many parties and, in order to be successful, have to form a\nconstructive and dynamic eco-system, marketplaces and data pricing are\nfundamental in connecting and facilitating those many parties. In this article,\nwe survey the principles and the latest research development of data pricing in\nmachine learning pipelines. We start with a brief review of data marketplaces\nand pricing desiderata. Then, we focus on pricing in three important steps in\nmachine learning pipelines. To understand pricing in the step of training data\ncollection, we review pricing raw data sets and data labels. We also\ninvestigate pricing in the step of collaborative training of machine learning\nmodels, and overview pricing machine learning models for end users in the step\nof machine learning deployment. We also discuss a series of possible future\ndirections.",
        "link": "http://arxiv.org/abs/2108.07915v1",
        "published": "2021-08-18T00:57:06Z",
        "pdf_url": "http://arxiv.org/pdf/2108.07915v1.pdf",
        "txt_path": "data/txt/machine learning_paper_13.txt",
        "pdf_path": "data/pdfs/machine learning_paper_13.pdf"
    },
    {
        "title": "Techniques for Automated Machine Learning",
        "abstract": "Automated machine learning (AutoML) aims to find optimal machine learning\nsolutions automatically given a machine learning problem. It could release the\nburden of data scientists from the multifarious manual tuning process and\nenable the access of domain experts to the off-the-shelf machine learning\nsolutions without extensive experience. In this paper, we review the current\ndevelopments of AutoML in terms of three categories, automated feature\nengineering (AutoFE), automated model and hyperparameter learning (AutoMHL),\nand automated deep learning (AutoDL). State-of-the-art techniques adopted in\nthe three categories are presented, including Bayesian optimization,\nreinforcement learning, evolutionary algorithm, and gradient-based approaches.\nWe summarize popular AutoML frameworks and conclude with current open\nchallenges of AutoML.",
        "link": "http://arxiv.org/abs/1907.08908v1",
        "published": "2019-07-21T04:03:36Z",
        "pdf_url": "http://arxiv.org/pdf/1907.08908v1.pdf",
        "txt_path": "data/txt/machine learning_paper_14.txt",
        "pdf_path": "data/pdfs/machine learning_paper_14.pdf"
    },
    {
        "title": "The Landscape of Modern Machine Learning: A Review of Machine,\n  Distributed and Federated Learning",
        "abstract": "With the advance of the powerful heterogeneous, parallel and distributed\ncomputing systems and ever increasing immense amount of data, machine learning\nhas become an indispensable part of cutting-edge technology, scientific\nresearch and consumer products. In this study, we present a review of modern\nmachine and deep learning. We provide a high-level overview for the latest\nadvanced machine learning algorithms, applications, and frameworks. Our\ndiscussion encompasses parallel distributed learning, deep learning as well as\nfederated learning. As a result, our work serves as an introductory text to the\nvast field of modern machine learning.",
        "link": "http://arxiv.org/abs/2312.03120v1",
        "published": "2023-12-05T20:40:05Z",
        "pdf_url": "http://arxiv.org/pdf/2312.03120v1.pdf",
        "txt_path": "data/txt/machine learning_paper_15.txt",
        "pdf_path": "data/pdfs/machine learning_paper_15.pdf"
    },
    {
        "title": "Parallelization of Machine Learning Algorithms Respectively on Single\n  Machine and Spark",
        "abstract": "With the rapid development of big data technologies, how to dig out useful\ninformation from massive data becomes an essential problem. However, using\nmachine learning algorithms to analyze large data may be time-consuming and\ninefficient on the traditional single machine. To solve these problems, this\npaper has made some research on the parallelization of several classic machine\nlearning algorithms respectively on the single machine and the big data\nplatform Spark. We compare the runtime and efficiency of traditional machine\nlearning algorithms with parallelized machine learning algorithms respectively\non the single machine and Spark platform. The research results have shown\nsignificant improvement in runtime and efficiency of parallelized machine\nlearning algorithms.",
        "link": "http://arxiv.org/abs/2206.07090v2",
        "published": "2022-05-08T03:47:30Z",
        "pdf_url": "http://arxiv.org/pdf/2206.07090v2.pdf",
        "txt_path": "data/txt/machine learning_paper_16.txt",
        "pdf_path": null
    },
    {
        "title": "AutoCompete: A Framework for Machine Learning Competition",
        "abstract": "In this paper, we propose AutoCompete, a highly automated machine learning\nframework for tackling machine learning competitions. This framework has been\nlearned by us, validated and improved over a period of more than two years by\nparticipating in online machine learning competitions. It aims at minimizing\nhuman interference required to build a first useful predictive model and to\nassess the practical difficulty of a given machine learning challenge. The\nproposed system helps in identifying data types, choosing a machine learn- ing\nmodel, tuning hyper-parameters, avoiding over-fitting and optimization for a\nprovided evaluation metric. We also observe that the proposed system produces\nbetter (or comparable) results with less runtime as compared to other\napproaches.",
        "link": "http://arxiv.org/abs/1507.02188v1",
        "published": "2015-07-08T15:07:39Z",
        "pdf_url": "http://arxiv.org/pdf/1507.02188v1.pdf",
        "txt_path": "data/txt/machine learning_paper_17.txt",
        "pdf_path": "data/pdfs/machine learning_paper_17.pdf"
    },
    {
        "title": "Joint Training of Deep Boltzmann Machines",
        "abstract": "We introduce a new method for training deep Boltzmann machines jointly. Prior\nmethods require an initial learning pass that trains the deep Boltzmann machine\ngreedily, one layer at a time, or do not perform well on classifi- cation\ntasks.",
        "link": "http://arxiv.org/abs/1212.2686v1",
        "published": "2012-12-12T01:59:27Z",
        "pdf_url": "http://arxiv.org/pdf/1212.2686v1.pdf",
        "txt_path": "data/txt/machine learning_paper_18.txt",
        "pdf_path": "data/pdfs/machine learning_paper_18.pdf"
    },
    {
        "title": "Proceedings of the 2016 ICML Workshop on #Data4Good: Machine Learning in\n  Social Good Applications",
        "abstract": "This is the Proceedings of the ICML Workshop on #Data4Good: Machine Learning\nin Social Good Applications, which was held on June 24, 2016 in New York.",
        "link": "http://arxiv.org/abs/1607.02450v2",
        "published": "2016-07-08T16:55:31Z",
        "pdf_url": "http://arxiv.org/pdf/1607.02450v2.pdf",
        "txt_path": "data/txt/machine learning_paper_19.txt",
        "pdf_path": null
    },
    {
        "title": "Mathematical Perspective of Machine Learning",
        "abstract": "We take a closer look at some theoretical challenges of Machine Learning as a\nfunction approximation, gradient descent as the default optimization algorithm,\nlimitations of fixed length and width networks and a different approach to RNNs\nfrom a mathematical perspective.",
        "link": "http://arxiv.org/abs/2007.01503v1",
        "published": "2020-07-03T05:26:02Z",
        "pdf_url": "http://arxiv.org/pdf/2007.01503v1.pdf",
        "txt_path": "data/txt/machine learning_paper_20.txt",
        "pdf_path": "data/pdfs/machine learning_paper_20.pdf"
    },
    {
        "title": "Private Machine Learning via Randomised Response",
        "abstract": "We introduce a general learning framework for private machine learning based\non randomised response. Our assumption is that all actors are potentially\nadversarial and as such we trust only to release a single noisy version of an\nindividual's datapoint. We discuss a general approach that forms a consistent\nway to estimate the true underlying machine learning model and demonstrate this\nin the case of logistic regression.",
        "link": "http://arxiv.org/abs/2001.04942v2",
        "published": "2020-01-14T17:56:16Z",
        "pdf_url": "http://arxiv.org/pdf/2001.04942v2.pdf",
        "txt_path": "data/txt/machine learning_paper_21.txt",
        "pdf_path": "data/pdfs/machine learning_paper_21.pdf"
    },
    {
        "title": "A Survey of Optimization Methods from a Machine Learning Perspective",
        "abstract": "Machine learning develops rapidly, which has made many theoretical\nbreakthroughs and is widely applied in various fields. Optimization, as an\nimportant part of machine learning, has attracted much attention of\nresearchers. With the exponential growth of data amount and the increase of\nmodel complexity, optimization methods in machine learning face more and more\nchallenges. A lot of work on solving optimization problems or improving\noptimization methods in machine learning has been proposed successively. The\nsystematic retrospect and summary of the optimization methods from the\nperspective of machine learning are of great significance, which can offer\nguidance for both developments of optimization and machine learning research.\nIn this paper, we first describe the optimization problems in machine learning.\nThen, we introduce the principles and progresses of commonly used optimization\nmethods. Next, we summarize the applications and developments of optimization\nmethods in some popular machine learning fields. Finally, we explore and give\nsome challenges and open problems for the optimization in machine learning.",
        "link": "http://arxiv.org/abs/1906.06821v2",
        "published": "2019-06-17T02:54:51Z",
        "pdf_url": "http://arxiv.org/pdf/1906.06821v2.pdf",
        "txt_path": "data/txt/machine learning_paper_22.txt",
        "pdf_path": "data/pdfs/machine learning_paper_22.pdf"
    },
    {
        "title": "Ten-year Survival Prediction for Breast Cancer Patients",
        "abstract": "This report assesses different machine learning approaches to 10-year\nsurvival prediction of breast cancer patients.",
        "link": "http://arxiv.org/abs/1911.00776v1",
        "published": "2019-11-02T19:53:32Z",
        "pdf_url": "http://arxiv.org/pdf/1911.00776v1.pdf",
        "txt_path": "data/txt/machine learning_paper_23.txt",
        "pdf_path": "data/pdfs/machine learning_paper_23.pdf"
    },
    {
        "title": "Tuning Learning Rates with the Cumulative-Learning Constant",
        "abstract": "This paper introduces a novel method for optimizing learning rates in machine\nlearning. A previously unrecognized proportionality between learning rates and\ndataset sizes is discovered, providing valuable insights into how dataset scale\ninfluences training dynamics. Additionally, a cumulative learning constant is\nidentified, offering a framework for designing and optimizing advanced learning\nrate schedules. These findings have the potential to enhance training\nefficiency and performance across a wide range of machine learning\napplications.",
        "link": "http://arxiv.org/abs/2505.13457v1",
        "published": "2025-04-30T00:07:48Z",
        "pdf_url": "http://arxiv.org/pdf/2505.13457v1.pdf",
        "txt_path": "data/txt/machine learning_paper_24.txt",
        "pdf_path": "data/pdfs/machine learning_paper_24.pdf"
    },
    {
        "title": "When Machine Learning Meets Privacy: A Survey and Outlook",
        "abstract": "The newly emerged machine learning (e.g. deep learning) methods have become a\nstrong driving force to revolutionize a wide range of industries, such as smart\nhealthcare, financial technology, and surveillance systems. Meanwhile, privacy\nhas emerged as a big concern in this machine learning-based artificial\nintelligence era. It is important to note that the problem of privacy\npreservation in the context of machine learning is quite different from that in\ntraditional data privacy protection, as machine learning can act as both friend\nand foe. Currently, the work on the preservation of privacy and machine\nlearning (ML) is still in an infancy stage, as most existing solutions only\nfocus on privacy problems during the machine learning process. Therefore, a\ncomprehensive study on the privacy preservation problems and machine learning\nis required. This paper surveys the state of the art in privacy issues and\nsolutions for machine learning. The survey covers three categories of\ninteractions between privacy and machine learning: (i) private machine\nlearning, (ii) machine learning aided privacy protection, and (iii) machine\nlearning-based privacy attack and corresponding protection schemes. The current\nresearch progress in each category is reviewed and the key challenges are\nidentified. Finally, based on our in-depth analysis of the area of privacy and\nmachine learning, we point out future research directions in this field.",
        "link": "http://arxiv.org/abs/2011.11819v1",
        "published": "2020-11-24T00:52:49Z",
        "pdf_url": "http://arxiv.org/pdf/2011.11819v1.pdf",
        "txt_path": "data/txt/machine learning_paper_25.txt",
        "pdf_path": "data/pdfs/machine learning_paper_25.pdf"
    },
    {
        "title": "A method to benchmark high-dimensional process drift detection",
        "abstract": "Process curves are multivariate finite time series data coming from\nmanufacturing processes. This paper studies machine learning that detect drifts\nin process curve datasets. A theoretic framework to synthetically generate\nprocess curves in a controlled way is introduced in order to benchmark machine\nlearning algorithms for process drift detection. An evaluation score, called\nthe temporal area under the curve, is introduced, which allows to quantify how\nwell machine learning models unveil curves belonging to drift segments.\nFinally, a benchmark study comparing popular machine learning approaches on\nsynthetic data generated with the introduced framework is presented that shows\nthat existing algorithms often struggle with datasets containing multiple drift\nsegments.",
        "link": "http://arxiv.org/abs/2409.03669v2",
        "published": "2024-09-05T16:23:07Z",
        "pdf_url": "http://arxiv.org/pdf/2409.03669v2.pdf",
        "txt_path": "data/txt/machine learning_paper_26.txt",
        "pdf_path": "data/pdfs/machine learning_paper_26.pdf"
    },
    {
        "title": "Inverse Problems and Data Assimilation: A Machine Learning Approach",
        "abstract": "The aim of these notes is to demonstrate the potential for ideas in machine\nlearning to impact on the fields of inverse problems and data assimilation. The\nperspective is one that is primarily aimed at researchers from inverse problems\nand/or data assimilation who wish to see a mathematical presentation of machine\nlearning as it pertains to their fields. As a by-product, we include a succinct\nmathematical treatment of various topics in machine learning.",
        "link": "http://arxiv.org/abs/2410.10523v1",
        "published": "2024-10-14T14:01:35Z",
        "pdf_url": "http://arxiv.org/pdf/2410.10523v1.pdf",
        "txt_path": "data/txt/machine learning_paper_27.txt",
        "pdf_path": "data/pdfs/machine learning_paper_27.pdf"
    },
    {
        "title": "Proceedings of NIPS 2016 Workshop on Interpretable Machine Learning for\n  Complex Systems",
        "abstract": "This is the Proceedings of NIPS 2016 Workshop on Interpretable Machine\nLearning for Complex Systems, held in Barcelona, Spain on December 9, 2016",
        "link": "http://arxiv.org/abs/1611.09139v1",
        "published": "2016-11-28T14:34:15Z",
        "pdf_url": "http://arxiv.org/pdf/1611.09139v1.pdf",
        "txt_path": "data/txt/machine learning_paper_28.txt",
        "pdf_path": null
    },
    {
        "title": "Linear, Machine Learning and Probabilistic Approaches for Time Series\n  Analysis",
        "abstract": "In this paper we study different approaches for time series modeling. The\nforecasting approaches using linear models, ARIMA alpgorithm, XGBoost machine\nlearning algorithm are described. Results of different model combinations are\nshown. For probabilistic modeling the approaches using copulas and Bayesian\ninference are considered.",
        "link": "http://arxiv.org/abs/1703.01977v1",
        "published": "2017-02-26T10:41:26Z",
        "pdf_url": "http://arxiv.org/pdf/1703.01977v1.pdf",
        "txt_path": "data/txt/machine learning_paper_29.txt",
        "pdf_path": "data/pdfs/machine learning_paper_29.pdf"
    },
    {
        "title": "Proceedings of NIPS 2017 Workshop on Machine Learning for the Developing\n  World",
        "abstract": "This is the Proceedings of NIPS 2017 Workshop on Machine Learning for the\nDeveloping World, held in Long Beach, California, USA on December 8, 2017",
        "link": "http://arxiv.org/abs/1711.09522v2",
        "published": "2017-11-27T03:27:17Z",
        "pdf_url": "http://arxiv.org/pdf/1711.09522v2.pdf",
        "txt_path": "data/txt/machine learning_paper_30.txt",
        "pdf_path": null
    },
    {
        "title": "Classifying medical notes into standard disease codes using Machine\n  Learning",
        "abstract": "We investigate the automatic classification of patient discharge notes into\nstandard disease labels. We find that Convolutional Neural Networks with\nAttention outperform previous algorithms used in this task, and suggest further\nareas for improvement.",
        "link": "http://arxiv.org/abs/1802.00382v1",
        "published": "2018-02-01T16:46:00Z",
        "pdf_url": "http://arxiv.org/pdf/1802.00382v1.pdf",
        "txt_path": "data/txt/machine learning_paper_31.txt",
        "pdf_path": "data/pdfs/machine learning_paper_31.pdf"
    },
    {
        "title": "Mixed integer programming formulation of unsupervised learning",
        "abstract": "A novel formulation and training procedure for full Boltzmann machines in\nterms of a mixed binary quadratic feasibility problem is given. As a proof of\nconcept, the theory is analytically and numerically tested on XOR patterns.",
        "link": "http://arxiv.org/abs/2001.07278v1",
        "published": "2020-01-20T23:09:32Z",
        "pdf_url": "http://arxiv.org/pdf/2001.07278v1.pdf",
        "txt_path": "data/txt/machine learning_paper_32.txt",
        "pdf_path": "data/pdfs/machine learning_paper_32.pdf"
    },
    {
        "title": "Detection of brain tumors using machine learning algorithms",
        "abstract": "An algorithm capable of processing NMR images was developed for analysis\nusing machine learning techniques to detect the presence of brain tumors.",
        "link": "http://arxiv.org/abs/2201.04703v1",
        "published": "2022-01-12T21:08:38Z",
        "pdf_url": "http://arxiv.org/pdf/2201.04703v1.pdf",
        "txt_path": "data/txt/machine learning_paper_33.txt",
        "pdf_path": "data/pdfs/machine learning_paper_33.pdf"
    },
    {
        "title": "Elements of effective machine learning datasets in astronomy",
        "abstract": "In this work, we identify elements of effective machine learning datasets in\nastronomy and present suggestions for their design and creation. Machine\nlearning has become an increasingly important tool for analyzing and\nunderstanding the large-scale flood of data in astronomy. To take advantage of\nthese tools, datasets are required for training and testing. However, building\nmachine learning datasets for astronomy can be challenging. Astronomical data\nis collected from instruments built to explore science questions in a\ntraditional fashion rather than to conduct machine learning. Thus, it is often\nthe case that raw data, or even downstream processed data is not in a form\namenable to machine learning. We explore the construction of machine learning\ndatasets and we ask: what elements define effective machine learning datasets?\nWe define effective machine learning datasets in astronomy to be formed with\nwell-defined data points, structure, and metadata. We discuss why these\nelements are important for astronomical applications and ways to put them in\npractice. We posit that these qualities not only make the data suitable for\nmachine learning, they also help to foster usable, reusable, and replicable\nscience practices.",
        "link": "http://arxiv.org/abs/2211.14401v2",
        "published": "2022-11-25T23:37:24Z",
        "pdf_url": "http://arxiv.org/pdf/2211.14401v2.pdf",
        "txt_path": "data/txt/machine learning_paper_34.txt",
        "pdf_path": "data/pdfs/machine learning_paper_34.pdf"
    },
    {
        "title": "Efficient Deep Learning on Multi-Source Private Data",
        "abstract": "Machine learning models benefit from large and diverse datasets. Using such\ndatasets, however, often requires trusting a centralized data aggregator. For\nsensitive applications like healthcare and finance this is undesirable as it\ncould compromise patient privacy or divulge trade secrets. Recent advances in\nsecure and privacy-preserving computation, including trusted hardware enclaves\nand differential privacy, offer a way for mutually distrusting parties to\nefficiently train a machine learning model without revealing the training data.\nIn this work, we introduce Myelin, a deep learning framework which combines\nthese privacy-preservation primitives, and use it to establish a baseline level\nof performance for fully private machine learning.",
        "link": "http://arxiv.org/abs/1807.06689v1",
        "published": "2018-07-17T22:18:19Z",
        "pdf_url": "http://arxiv.org/pdf/1807.06689v1.pdf",
        "txt_path": "data/txt/machine learning_paper_35.txt",
        "pdf_path": "data/pdfs/machine learning_paper_35.pdf"
    },
    {
        "title": "Pymc-learn: Practical Probabilistic Machine Learning in Python",
        "abstract": "$\\textit{Pymc-learn}$ is a Python package providing a variety of\nstate-of-the-art probabilistic models for supervised and unsupervised machine\nlearning. It is inspired by $\\textit{scikit-learn}$ and focuses on bringing\nprobabilistic machine learning to non-specialists. It uses a general-purpose\nhigh-level language that mimics $\\textit{scikit-learn}$. Emphasis is put on\nease of use, productivity, flexibility, performance, documentation, and an API\nconsistent with $\\textit{scikit-learn}$. It depends on $\\textit{scikit-learn}$\nand $\\textit{pymc3}$ and is distributed under the new BSD-3 license,\nencouraging its use in both academia and industry. Source code, binaries, and\ndocumentation are available on http://github.com/pymc-learn/pymc-learn.",
        "link": "http://arxiv.org/abs/1811.00542v1",
        "published": "2018-10-31T22:54:12Z",
        "pdf_url": "http://arxiv.org/pdf/1811.00542v1.pdf",
        "txt_path": "data/txt/machine learning_paper_36.txt",
        "pdf_path": "data/pdfs/machine learning_paper_36.pdf"
    },
    {
        "title": "Machine learning in physics: a short guide",
        "abstract": "Machine learning is a rapidly growing field with the potential to\nrevolutionize many areas of science, including physics. This review provides a\nbrief overview of machine learning in physics, covering the main concepts of\nsupervised, unsupervised, and reinforcement learning, as well as more\nspecialized topics such as causal inference, symbolic regression, and deep\nlearning. We present some of the principal applications of machine learning in\nphysics and discuss the associated challenges and perspectives.",
        "link": "http://arxiv.org/abs/2310.10368v1",
        "published": "2023-10-16T13:05:47Z",
        "pdf_url": "http://arxiv.org/pdf/2310.10368v1.pdf",
        "txt_path": "data/txt/machine learning_paper_37.txt",
        "pdf_path": "data/pdfs/machine learning_paper_37.pdf"
    },
    {
        "title": "Quantum-Classical Machine learning by Hybrid Tensor Networks",
        "abstract": "Tensor networks (TN) have found a wide use in machine learning, and in\nparticular, TN and deep learning bear striking similarities. In this work, we\npropose the quantum-classical hybrid tensor networks (HTN) which combine tensor\nnetworks with classical neural networks in a uniform deep learning framework to\novercome the limitations of regular tensor networks in machine learning. We\nfirst analyze the limitations of regular tensor networks in the applications of\nmachine learning involving the representation power and architecture\nscalability. We conclude that in fact the regular tensor networks are not\ncompetent to be the basic building blocks of deep learning. Then, we discuss\nthe performance of HTN which overcome all the deficiency of regular tensor\nnetworks for machine learning. In this sense, we are able to train HTN in the\ndeep learning way which is the standard combination of algorithms such as Back\nPropagation and Stochastic Gradient Descent. We finally provide two applicable\ncases to show the potential applications of HTN, including quantum states\nclassification and quantum-classical autoencoder. These cases also demonstrate\nthe great potentiality to design various HTN in deep learning way.",
        "link": "http://arxiv.org/abs/2005.09428v2",
        "published": "2020-05-15T10:20:35Z",
        "pdf_url": "http://arxiv.org/pdf/2005.09428v2.pdf",
        "txt_path": "data/txt/machine learning_paper_38.txt",
        "pdf_path": "data/pdfs/machine learning_paper_38.pdf"
    },
    {
        "title": "A Review on Machine Unlearning",
        "abstract": "Recently, an increasing number of laws have governed the useability of users'\nprivacy. For example, Article 17 of the General Data Protection Regulation\n(GDPR), the right to be forgotten, requires machine learning applications to\nremove a portion of data from a dataset and retrain it if the user makes such a\nrequest. Furthermore, from the security perspective, training data for machine\nlearning models, i.e., data that may contain user privacy, should be\neffectively protected, including appropriate erasure. Therefore, researchers\npropose various privacy-preserving methods to deal with such issues as machine\nunlearning. This paper provides an in-depth review of the security and privacy\nconcerns in machine learning models. First, we present how machine learning can\nuse users' private data in daily life and the role that the GDPR plays in this\nproblem. Then, we introduce the concept of machine unlearning by describing the\nsecurity threats in machine learning models and how to protect users' privacy\nfrom being violated using machine learning platforms. As the core content of\nthe paper, we introduce and analyze current machine unlearning approaches and\nseveral representative research results and discuss them in the context of the\ndata lineage. Furthermore, we also discuss the future research challenges in\nthis field.",
        "link": "http://arxiv.org/abs/2411.11315v1",
        "published": "2024-11-18T06:18:13Z",
        "pdf_url": "http://arxiv.org/pdf/2411.11315v1.pdf",
        "txt_path": "data/txt/machine learning_paper_39.txt",
        "pdf_path": "data/pdfs/machine learning_paper_39.pdf"
    },
    {
        "title": "Dex: Incremental Learning for Complex Environments in Deep Reinforcement\n  Learning",
        "abstract": "This paper introduces Dex, a reinforcement learning environment toolkit\nspecialized for training and evaluation of continual learning methods as well\nas general reinforcement learning problems. We also present the novel continual\nlearning method of incremental learning, where a challenging environment is\nsolved using optimal weight initialization learned from first solving a similar\neasier environment. We show that incremental learning can produce vastly\nsuperior results than standard methods by providing a strong baseline method\nacross ten Dex environments. We finally develop a saliency method for\nqualitative analysis of reinforcement learning, which shows the impact\nincremental learning has on network attention.",
        "link": "http://arxiv.org/abs/1706.05749v1",
        "published": "2017-06-19T00:16:24Z",
        "pdf_url": "http://arxiv.org/pdf/1706.05749v1.pdf",
        "txt_path": "data/txt/machine learning_paper_40.txt",
        "pdf_path": "data/pdfs/machine learning_paper_40.pdf"
    },
    {
        "title": "Bridging belief function theory to modern machine learning",
        "abstract": "Machine learning is a quickly evolving field which now looks really different\nfrom what it was 15 years ago, when classification and clustering were major\nissues. This document proposes several trends to explore the new questions of\nmodern machine learning, with the strong afterthought that the belief function\nframework has a major role to play.",
        "link": "http://arxiv.org/abs/1504.03874v1",
        "published": "2015-04-15T12:04:58Z",
        "pdf_url": "http://arxiv.org/pdf/1504.03874v1.pdf",
        "txt_path": "data/txt/machine learning_paper_41.txt",
        "pdf_path": "data/pdfs/machine learning_paper_41.pdf"
    },
    {
        "title": "Electre Tri-Machine Learning Approach to the Record Linkage Problem",
        "abstract": "In this short paper, the Electre Tri-Machine Learning Method, generally used\nto solve ordinal classification problems, is proposed for solving the Record\nLinkage problem. Preliminary experimental results show that, using the Electre\nTri method, high accuracy can be achieved and more than 99% of the matches and\nnonmatches were correctly identified by the procedure.",
        "link": "http://arxiv.org/abs/1505.06614v1",
        "published": "2015-05-25T13:02:32Z",
        "pdf_url": "http://arxiv.org/pdf/1505.06614v1.pdf",
        "txt_path": "data/txt/machine learning_paper_42.txt",
        "pdf_path": "data/pdfs/machine learning_paper_42.pdf"
    },
    {
        "title": "Theoretical Robopsychology: Samu Has Learned Turing Machines",
        "abstract": "From the point of view of a programmer, the robopsychology is a synonym for\nthe activity is done by developers to implement their machine learning\napplications. This robopsychological approach raises some fundamental\ntheoretical questions of machine learning. Our discussion of these questions is\nconstrained to Turing machines. Alan Turing had given an algorithm (aka the\nTuring Machine) to describe algorithms. If it has been applied to describe\nitself then this brings us to Turing's notion of the universal machine. In the\npresent paper, we investigate algorithms to write algorithms. From a pedagogy\npoint of view, this way of writing programs can be considered as a combination\nof learning by listening and learning by doing due to it is based on applying\nagent technology and machine learning. As the main result we introduce the\nproblem of learning and then we show that it cannot easily be handled in\nreality therefore it is reasonable to use machine learning algorithm for\nlearning Turing machines.",
        "link": "http://arxiv.org/abs/1606.02767v2",
        "published": "2016-06-08T21:46:20Z",
        "pdf_url": "http://arxiv.org/pdf/1606.02767v2.pdf",
        "txt_path": "data/txt/machine learning_paper_43.txt",
        "pdf_path": "data/pdfs/machine learning_paper_43.pdf"
    },
    {
        "title": "Model-Agnostic Interpretability of Machine Learning",
        "abstract": "Understanding why machine learning models behave the way they do empowers\nboth system designers and end-users in many ways: in model selection, feature\nengineering, in order to trust and act upon the predictions, and in more\nintuitive user interfaces. Thus, interpretability has become a vital concern in\nmachine learning, and work in the area of interpretable models has found\nrenewed interest. In some applications, such models are as accurate as\nnon-interpretable ones, and thus are preferred for their transparency. Even\nwhen they are not accurate, they may still be preferred when interpretability\nis of paramount importance. However, restricting machine learning to\ninterpretable models is often a severe limitation. In this paper we argue for\nexplaining machine learning predictions using model-agnostic approaches. By\ntreating the machine learning models as black-box functions, these approaches\nprovide crucial flexibility in the choice of models, explanations, and\nrepresentations, improving debugging, comparison, and interfaces for a variety\nof users and models. We also outline the main challenges for such methods, and\nreview a recently-introduced model-agnostic explanation approach (LIME) that\naddresses these challenges.",
        "link": "http://arxiv.org/abs/1606.05386v1",
        "published": "2016-06-16T23:39:41Z",
        "pdf_url": "http://arxiv.org/pdf/1606.05386v1.pdf",
        "txt_path": "data/txt/machine learning_paper_44.txt",
        "pdf_path": "data/pdfs/machine learning_paper_44.pdf"
    },
    {
        "title": "Proceedings of the 2016 ICML Workshop on Human Interpretability in\n  Machine Learning (WHI 2016)",
        "abstract": "This is the Proceedings of the 2016 ICML Workshop on Human Interpretability\nin Machine Learning (WHI 2016), which was held in New York, NY, June 23, 2016.\n  Invited speakers were Susan Athey, Rich Caruana, Jacob Feldman, Percy Liang,\nand Hanna Wallach.",
        "link": "http://arxiv.org/abs/1607.02531v2",
        "published": "2016-07-08T21:07:54Z",
        "pdf_url": "http://arxiv.org/pdf/1607.02531v2.pdf",
        "txt_path": "data/txt/machine learning_paper_45.txt",
        "pdf_path": null
    },
    {
        "title": "The Top 10 Topics in Machine Learning Revisited: A Quantitative\n  Meta-Study",
        "abstract": "Which topics of machine learning are most commonly addressed in research?\nThis question was initially answered in 2007 by doing a qualitative survey\namong distinguished researchers. In our study, we revisit this question from a\nquantitative perspective. Concretely, we collect 54K abstracts of papers\npublished between 2007 and 2016 in leading machine learning journals and\nconferences. We then use machine learning in order to determine the top 10\ntopics in machine learning. We not only include models, but provide a holistic\nview across optimization, data, features, etc. This quantitative approach\nallows reducing the bias of surveys. It reveals new and up-to-date insights\ninto what the 10 most prolific topics in machine learning research are. This\nallows researchers to identify popular topics as well as new and rising topics\nfor their research.",
        "link": "http://arxiv.org/abs/1703.10121v1",
        "published": "2017-03-29T16:29:04Z",
        "pdf_url": "http://arxiv.org/pdf/1703.10121v1.pdf",
        "txt_path": "data/txt/machine learning_paper_46.txt",
        "pdf_path": "data/pdfs/machine learning_paper_46.pdf"
    },
    {
        "title": "On conditional parity as a notion of non-discrimination in machine\n  learning",
        "abstract": "We identify conditional parity as a general notion of non-discrimination in\nmachine learning. In fact, several recently proposed notions of\nnon-discrimination, including a few counterfactual notions, are instances of\nconditional parity. We show that conditional parity is amenable to statistical\nanalysis by studying randomization as a general mechanism for achieving\nconditional parity and a kernel-based test of conditional parity.",
        "link": "http://arxiv.org/abs/1706.08519v1",
        "published": "2017-06-26T17:41:20Z",
        "pdf_url": "http://arxiv.org/pdf/1706.08519v1.pdf",
        "txt_path": "data/txt/machine learning_paper_47.txt",
        "pdf_path": "data/pdfs/machine learning_paper_47.pdf"
    },
    {
        "title": "Proceedings of the 2017 ICML Workshop on Human Interpretability in\n  Machine Learning (WHI 2017)",
        "abstract": "This is the Proceedings of the 2017 ICML Workshop on Human Interpretability\nin Machine Learning (WHI 2017), which was held in Sydney, Australia, August 10,\n2017. Invited speakers were Tony Jebara, Pang Wei Koh, and David Sontag.",
        "link": "http://arxiv.org/abs/1708.02666v1",
        "published": "2017-08-08T22:21:11Z",
        "pdf_url": "http://arxiv.org/pdf/1708.02666v1.pdf",
        "txt_path": "data/txt/machine learning_paper_48.txt",
        "pdf_path": null
    },
    {
        "title": "Privacy Preserving Machine Learning: Threats and Solutions",
        "abstract": "For privacy concerns to be addressed adequately in current machine learning\nsystems, the knowledge gap between the machine learning and privacy communities\nmust be bridged. This article aims to provide an introduction to the\nintersection of both fields with special emphasis on the techniques used to\nprotect the data.",
        "link": "http://arxiv.org/abs/1804.11238v1",
        "published": "2018-03-27T15:10:31Z",
        "pdf_url": "http://arxiv.org/pdf/1804.11238v1.pdf",
        "txt_path": "data/txt/machine learning_paper_49.txt",
        "pdf_path": "data/pdfs/machine learning_paper_49.pdf"
    },
    {
        "title": "An $O(N)$ Sorting Algorithm: Machine Learning Sort",
        "abstract": "We propose an $O(N\\cdot M)$ sorting algorithm by Machine Learning method,\nwhich shows a huge potential sorting big data. This sorting algorithm can be\napplied to parallel sorting and is suitable for GPU or TPU acceleration.\nFurthermore, we discuss the application of this algorithm to sparse hash table.",
        "link": "http://arxiv.org/abs/1805.04272v2",
        "published": "2018-05-11T08:28:55Z",
        "pdf_url": "http://arxiv.org/pdf/1805.04272v2.pdf",
        "txt_path": "data/txt/machine learning_paper_50.txt",
        "pdf_path": "data/pdfs/machine learning_paper_50.pdf"
    },
    {
        "title": "Proceedings of the 2018 ICML Workshop on Human Interpretability in\n  Machine Learning (WHI 2018)",
        "abstract": "This is the Proceedings of the 2018 ICML Workshop on Human Interpretability\nin Machine Learning (WHI 2018), which was held in Stockholm, Sweden, July 14,\n2018. Invited speakers were Barbara Engelhardt, Cynthia Rudin, Fernanda\nVi\\'egas, and Martin Wattenberg.",
        "link": "http://arxiv.org/abs/1807.01308v1",
        "published": "2018-07-03T17:49:14Z",
        "pdf_url": "http://arxiv.org/pdf/1807.01308v1.pdf",
        "txt_path": "data/txt/machine learning_paper_51.txt",
        "pdf_path": null
    },
    {
        "title": "TherML: Thermodynamics of Machine Learning",
        "abstract": "In this work we offer a framework for reasoning about a wide class of\nexisting objectives in machine learning. We develop a formal correspondence\nbetween this work and thermodynamics and discuss its implications.",
        "link": "http://arxiv.org/abs/1807.04162v3",
        "published": "2018-07-11T14:39:17Z",
        "pdf_url": "http://arxiv.org/pdf/1807.04162v3.pdf",
        "txt_path": "data/txt/machine learning_paper_52.txt",
        "pdf_path": "data/pdfs/machine learning_paper_52.pdf"
    },
    {
        "title": "ML-Schema: Exposing the Semantics of Machine Learning with Schemas and\n  Ontologies",
        "abstract": "The ML-Schema, proposed by the W3C Machine Learning Schema Community Group,\nis a top-level ontology that provides a set of classes, properties, and\nrestrictions for representing and interchanging information on machine learning\nalgorithms, datasets, and experiments. It can be easily extended and\nspecialized and it is also mapped to other more domain-specific ontologies\ndeveloped in the area of machine learning and data mining. In this paper we\noverview existing state-of-the-art machine learning interchange formats and\npresent the first release of ML-Schema, a canonical format resulted of more\nthan seven years of experience among different research institutions. We argue\nthat exposing semantics of machine learning algorithms, models, and experiments\nthrough a canonical format may pave the way to better interpretability and to\nrealistically achieve the full interoperability of experiments regardless of\nplatform or adopted workflow solution.",
        "link": "http://arxiv.org/abs/1807.05351v1",
        "published": "2018-07-14T08:07:31Z",
        "pdf_url": "http://arxiv.org/pdf/1807.05351v1.pdf",
        "txt_path": "data/txt/machine learning_paper_53.txt",
        "pdf_path": "data/pdfs/machine learning_paper_53.pdf"
    },
    {
        "title": "Characterizing machine learning process: A maturity framework",
        "abstract": "Academic literature on machine learning modeling fails to address how to make\nmachine learning models work for enterprises. For example, existing machine\nlearning processes cannot address how to define business use cases for an AI\napplication, how to convert business requirements from offering managers into\ndata requirements for data scientists, and how to continuously improve AI\napplications in term of accuracy and fairness, and how to customize general\npurpose machine learning models with industry, domain, and use case specific\ndata to make them more accurate for specific situations etc. Making AI work for\nenterprises requires special considerations, tools, methods and processes. In\nthis paper we present a maturity framework for machine learning model lifecycle\nmanagement for enterprises. Our framework is a re-interpretation of the\nsoftware Capability Maturity Model (CMM) for machine learning model development\nprocess. We present a set of best practices from our personal experience of\nbuilding large scale real-world machine learning models to help organizations\nachieve higher levels of maturity independent of their starting point.",
        "link": "http://arxiv.org/abs/1811.04871v1",
        "published": "2018-11-12T17:32:24Z",
        "pdf_url": "http://arxiv.org/pdf/1811.04871v1.pdf",
        "txt_path": "data/txt/machine learning_paper_54.txt",
        "pdf_path": "data/pdfs/machine learning_paper_54.pdf"
    },
    {
        "title": "Towards Identifying and Managing Sources of Uncertainty in AI and\n  Machine Learning Models - An Overview",
        "abstract": "Quantifying and managing uncertainties that occur when data-driven models\nsuch as those provided by AI and machine learning methods are applied is\ncrucial. This whitepaper provides a brief motivation and first overview of the\nstate of the art in identifying and quantifying sources of uncertainty for\ndata-driven components as well as means for analyzing their impact.",
        "link": "http://arxiv.org/abs/1811.11669v1",
        "published": "2018-11-28T16:49:37Z",
        "pdf_url": "http://arxiv.org/pdf/1811.11669v1.pdf",
        "txt_path": "data/txt/machine learning_paper_55.txt",
        "pdf_path": "data/pdfs/machine learning_paper_55.pdf"
    },
    {
        "title": "Proceedings of NeurIPS 2018 Workshop on Machine Learning for the\n  Developing World: Achieving Sustainable Impact",
        "abstract": "This is the Proceedings of NeurIPS 2018 Workshop on Machine Learning for the\nDeveloping World: Achieving Sustainable Impact, held in Montreal, Canada on\nDecember 8, 2018",
        "link": "http://arxiv.org/abs/1812.10398v2",
        "published": "2018-12-21T03:29:09Z",
        "pdf_url": "http://arxiv.org/pdf/1812.10398v2.pdf",
        "txt_path": "data/txt/machine learning_paper_56.txt",
        "pdf_path": null
    },
    {
        "title": "Radiological images and machine learning: trends, perspectives, and\n  prospects",
        "abstract": "The application of machine learning to radiological images is an increasingly\nactive research area that is expected to grow in the next five to ten years.\nRecent advances in machine learning have the potential to recognize and\nclassify complex patterns from different radiological imaging modalities such\nas x-rays, computed tomography, magnetic resonance imaging and positron\nemission tomography imaging. In many applications, machine learning based\nsystems have shown comparable performance to human decision-making. The\napplications of machine learning are the key ingredients of future clinical\ndecision making and monitoring systems. This review covers the fundamental\nconcepts behind various machine learning techniques and their applications in\nseveral radiological imaging areas, such as medical image segmentation, brain\nfunction studies and neurological disease diagnosis, as well as computer-aided\nsystems, image registration, and content-based image retrieval systems.\nSynchronistically, we will briefly discuss current challenges and future\ndirections regarding the application of machine learning in radiological\nimaging. By giving insight on how take advantage of machine learning powered\napplications, we expect that clinicians can prevent and diagnose diseases more\naccurately and efficiently.",
        "link": "http://arxiv.org/abs/1903.11726v1",
        "published": "2019-03-27T23:11:15Z",
        "pdf_url": "http://arxiv.org/pdf/1903.11726v1.pdf",
        "txt_path": "data/txt/machine learning_paper_57.txt",
        "pdf_path": "data/pdfs/machine learning_paper_57.pdf"
    },
    {
        "title": "A Game of Dice: Machine Learning and the Question Concerning Art",
        "abstract": "We review some practical and philosophical questions raised by the use of\nmachine learning in creative practice. Beyond the obvious problems regarding\nplagiarism and authorship, we argue that the novelty in AI Art relies mostly on\na narrow machine learning contribution : manifold approximation. Nevertheless,\nthis contribution creates a radical shift in the way we have to consider this\nmovement. Is this omnipotent tool a blessing or a curse for the artists?",
        "link": "http://arxiv.org/abs/1904.01957v1",
        "published": "2019-04-02T09:37:44Z",
        "pdf_url": "http://arxiv.org/pdf/1904.01957v1.pdf",
        "txt_path": "data/txt/machine learning_paper_58.txt",
        "pdf_path": "data/pdfs/machine learning_paper_58.pdf"
    },
    {
        "title": "Collaborative Machine Learning Markets with Data-Replication-Robust\n  Payments",
        "abstract": "We study the problem of collaborative machine learning markets where multiple\nparties can achieve improved performance on their machine learning tasks by\ncombining their training data. We discuss desired properties for these machine\nlearning markets in terms of fair revenue distribution and potential threats,\nincluding data replication. We then instantiate a collaborative market for\ncases where parties share a common machine learning task and where parties'\ntasks are different. Our marketplace incentivizes parties to submit high\nquality training and true validation data. To this end, we introduce a novel\npayment division function that is robust-to-replication and customized output\nmodels that perform well only on requested machine learning tasks. In\nexperiments, we validate the assumptions underlying our theoretical analysis\nand show that these are approximately satisfied for commonly used machine\nlearning models.",
        "link": "http://arxiv.org/abs/1911.09052v1",
        "published": "2019-11-08T13:58:31Z",
        "pdf_url": "http://arxiv.org/pdf/1911.09052v1.pdf",
        "txt_path": "data/txt/machine learning_paper_59.txt",
        "pdf_path": "data/pdfs/machine learning_paper_59.pdf"
    },
    {
        "title": "Analysis of Software Engineering for Agile Machine Learning Projects",
        "abstract": "The number of machine learning, artificial intelligence or data science\nrelated software engineering projects using Agile methodology is increasing.\nHowever, there are very few studies on how such projects work in practice. In\nthis paper, we analyze project issues tracking data taken from Scrum (a popular\ntool for Agile) for several machine learning projects. We compare this data\nwith corresponding data from non-machine learning projects, in an attempt to\nanalyze how machine learning projects are executed differently from normal\nsoftware engineering projects. On analysis, we find that machine learning\nproject issues use different kinds of words to describe issues, have higher\nnumber of exploratory or research oriented tasks as compared to implementation\ntasks, and have a higher number of issues in the product backlog after each\nsprint, denoting that it is more difficult to estimate the duration of machine\nlearning project related tasks in advance. After analyzing this data, we\npropose a few ways in which Agile machine learning projects can be better\nlogged and executed, given their differences with normal software engineering\nprojects.",
        "link": "http://arxiv.org/abs/1912.07323v1",
        "published": "2019-12-16T12:40:26Z",
        "pdf_url": "http://arxiv.org/pdf/1912.07323v1.pdf",
        "txt_path": "data/txt/machine learning_paper_60.txt",
        "pdf_path": "data/pdfs/machine learning_paper_60.pdf"
    },
    {
        "title": "DriveML: An R Package for Driverless Machine Learning",
        "abstract": "In recent years, the concept of automated machine learning has become very\npopular. Automated Machine Learning (AutoML) mainly refers to the automated\nmethods for model selection and hyper-parameter optimization of various\nalgorithms such as random forests, gradient boosting, neural networks, etc. In\nthis paper, we introduce a new package i.e. DriveML for automated machine\nlearning. DriveML helps in implementing some of the pillars of an automated\nmachine learning pipeline such as automated data preparation, feature\nengineering, model building and model explanation by running the function\ninstead of writing lengthy R codes. The DriveML package is available in CRAN.\nWe compare the DriveML package with other relevant packages in CRAN/Github and\nfind that DriveML performs the best across different parameters. We also\nprovide an illustration by applying the DriveML package with default\nconfiguration on a real world dataset. Overall, the main benefits of DriveML\nare in development time savings, reduce developer's errors, optimal tuning of\nmachine learning models and reproducibility.",
        "link": "http://arxiv.org/abs/2005.00478v3",
        "published": "2020-05-01T16:40:25Z",
        "pdf_url": "http://arxiv.org/pdf/2005.00478v3.pdf",
        "txt_path": "data/txt/machine learning_paper_61.txt",
        "pdf_path": "data/pdfs/machine learning_paper_61.pdf"
    },
    {
        "title": "A combinatorial conjecture from PAC-Bayesian machine learning",
        "abstract": "We present a proof of a combinatorial conjecture from the second author's\nPh.D. thesis. The proof relies on binomial and multinomial sums identities. We\nalso discuss the relevance of the conjecture in the context of PAC-Bayesian\nmachine learning.",
        "link": "http://arxiv.org/abs/2006.01387v2",
        "published": "2020-06-02T04:36:50Z",
        "pdf_url": "http://arxiv.org/pdf/2006.01387v2.pdf",
        "txt_path": "data/txt/machine learning_paper_62.txt",
        "pdf_path": "data/pdfs/machine learning_paper_62.pdf"
    },
    {
        "title": "Integrating Machine Learning with Physics-Based Modeling",
        "abstract": "Machine learning is poised as a very powerful tool that can drastically\nimprove our ability to carry out scientific research. However, many issues need\nto be addressed before this becomes a reality. This article focuses on one\nparticular issue of broad interest: How can we integrate machine learning with\nphysics-based modeling to develop new interpretable and truly reliable physical\nmodels? After introducing the general guidelines, we discuss the two most\nimportant issues for developing machine learning-based physical models:\nImposing physical constraints and obtaining optimal datasets. We also provide a\nsimple and intuitive explanation for the fundamental reasons behind the success\nof modern machine learning, as well as an introduction to the concurrent\nmachine learning framework needed for integrating machine learning with\nphysics-based modeling. Molecular dynamics and moment closure of kinetic\nequations are used as examples to illustrate the main issues discussed. We end\nwith a general discussion on where this integration will lead us to, and where\nthe new frontier will be after machine learning is successfully integrated into\nscientific modeling.",
        "link": "http://arxiv.org/abs/2006.02619v1",
        "published": "2020-06-04T02:35:10Z",
        "pdf_url": "http://arxiv.org/pdf/2006.02619v1.pdf",
        "txt_path": "data/txt/machine learning_paper_63.txt",
        "pdf_path": "data/pdfs/machine learning_paper_63.pdf"
    },
    {
        "title": "Power Consumption Variation over Activation Functions",
        "abstract": "The power that machine learning models consume when making predictions can be\naffected by a model's architecture. This paper presents various estimates of\npower consumption for a range of different activation functions, a core factor\nin neural network model architecture design. Substantial differences in\nhardware performance exist between activation functions. This difference\ninforms how power consumption in machine learning models can be reduced.",
        "link": "http://arxiv.org/abs/2006.07237v1",
        "published": "2020-06-12T14:40:46Z",
        "pdf_url": "http://arxiv.org/pdf/2006.07237v1.pdf",
        "txt_path": "data/txt/machine learning_paper_64.txt",
        "pdf_path": "data/pdfs/machine learning_paper_64.pdf"
    },
    {
        "title": "Classification with Quantum Machine Learning: A Survey",
        "abstract": "Due to the superiority and noteworthy progress of Quantum Computing (QC) in a\nlot of applications such as cryptography, chemistry, Big data, machine\nlearning, optimization, Internet of Things (IoT), Blockchain, communication,\nand many more. Fully towards to combine classical machine learning (ML) with\nQuantum Information Processing (QIP) to build a new field in the quantum world\nis called Quantum Machine Learning (QML) to solve and improve problems that\ndisplayed in classical machine learning (e.g. time and energy consumption,\nkernel estimation). The aim of this paper presents and summarizes a\ncomprehensive survey of the state-of-the-art advances in Quantum Machine\nLearning (QML). Especially, recent QML classification works. Also, we cover\nabout 30 publications that are published lately in Quantum Machine Learning\n(QML). we propose a classification scheme in the quantum world and discuss\nencoding methods for mapping classical data to quantum data. Then, we provide\nquantum subroutines and some methods of Quantum Computing (QC) in improving\nperformance and speed up of classical Machine Learning (ML). And also some of\nQML applications in various fields, challenges, and future vision will be\npresented.",
        "link": "http://arxiv.org/abs/2006.12270v1",
        "published": "2020-06-22T14:05:31Z",
        "pdf_url": "http://arxiv.org/pdf/2006.12270v1.pdf",
        "txt_path": "data/txt/machine learning_paper_65.txt",
        "pdf_path": "data/pdfs/machine learning_paper_65.pdf"
    },
    {
        "title": "Machine Learning and Computational Mathematics",
        "abstract": "Neural network-based machine learning is capable of approximating functions\nin very high dimension with unprecedented efficiency and accuracy. This has\nopened up many exciting new possibilities, not just in traditional areas of\nartificial intelligence, but also in scientific computing and computational\nscience. At the same time, machine learning has also acquired the reputation of\nbeing a set of \"black box\" type of tricks, without fundamental principles. This\nhas been a real obstacle for making further progress in machine learning. In\nthis article, we try to address the following two very important questions: (1)\nHow machine learning has already impacted and will further impact computational\nmathematics, scientific computing and computational science? (2) How\ncomputational mathematics, particularly numerical analysis, {can} impact\nmachine learning? We describe some of the most important progress that has been\nmade on these issues. Our hope is to put things into a perspective that will\nhelp to integrate machine learning with computational mathematics.",
        "link": "http://arxiv.org/abs/2009.14596v1",
        "published": "2020-09-23T23:16:46Z",
        "pdf_url": "http://arxiv.org/pdf/2009.14596v1.pdf",
        "txt_path": "data/txt/machine learning_paper_66.txt",
        "pdf_path": "data/pdfs/machine learning_paper_66.pdf"
    },
    {
        "title": "Risk Assessment for Machine Learning Models",
        "abstract": "In this paper we propose a framework for assessing the risk associated with\ndeploying a machine learning model in a specified environment. For that we\ncarry over the risk definition from decision theory to machine learning. We\ndevelop and implement a method that allows to define deployment scenarios, test\nthe machine learning model under the conditions specified in each scenario, and\nestimate the damage associated with the output of the machine learning model\nunder test. Using the likelihood of each scenario together with the estimated\ndamage we define \\emph{key risk indicators} of a machine learning model.\n  The definition of scenarios and weighting by their likelihood allows for\nstandardized risk assessment in machine learning throughout multiple domains of\napplication. In particular, in our framework, the robustness of a machine\nlearning model to random input corruptions, distributional shifts caused by a\nchanging environment, and adversarial perturbations can be assessed.",
        "link": "http://arxiv.org/abs/2011.04328v1",
        "published": "2020-11-09T10:50:50Z",
        "pdf_url": "http://arxiv.org/pdf/2011.04328v1.pdf",
        "txt_path": "data/txt/machine learning_paper_67.txt",
        "pdf_path": "data/pdfs/machine learning_paper_67.pdf"
    },
    {
        "title": "Adversarial Machine Learning Attacks on Condition-Based Maintenance\n  Capabilities",
        "abstract": "Condition-based maintenance (CBM) strategies exploit machine learning models\nto assess the health status of systems based on the collected data from the\nphysical environment, while machine learning models are vulnerable to\nadversarial attacks. A malicious adversary can manipulate the collected data to\ndeceive the machine learning model and affect the CBM system's performance.\nAdversarial machine learning techniques introduced in the computer vision\ndomain can be used to make stealthy attacks on CBM systems by adding\nperturbation to data to confuse trained models. The stealthy nature causes\ndifficulty and delay in detection of the attacks. In this paper, adversarial\nmachine learning in the domain of CBM is introduced. A case study shows how\nadversarial machine learning can be used to attack CBM capabilities.\nAdversarial samples are crafted using the Fast Gradient Sign method, and the\nperformance of a CBM system under attack is investigated. The obtained results\nreveal that CBM systems are vulnerable to adversarial machine learning attacks\nand defense strategies need to be considered.",
        "link": "http://arxiv.org/abs/2101.12097v1",
        "published": "2021-01-28T16:34:04Z",
        "pdf_url": "http://arxiv.org/pdf/2101.12097v1.pdf",
        "txt_path": "data/txt/machine learning_paper_68.txt",
        "pdf_path": "data/pdfs/machine learning_paper_68.pdf"
    },
    {
        "title": "Confronting Machine Learning With Financial Research",
        "abstract": "This study aims to examine the challenges and applications of machine\nlearning for financial research. Machine learning algorithms have been\ndeveloped for certain data environments which substantially differ from the one\nwe encounter in finance. Not only do difficulties arise due to some of the\nidiosyncrasies of financial markets, there is a fundamental tension between the\nunderlying paradigm of machine learning and the research philosophy in\nfinancial economics. Given the peculiar features of financial markets and the\nempirical framework within social science, various adjustments have to be made\nto the conventional machine learning methodology. We discuss some of the main\nchallenges of machine learning in finance and examine how these could be\naccounted for. Despite some of the challenges, we argue that machine learning\ncould be unified with financial research to become a robust complement to the\neconometrician's toolbox. Moreover, we discuss the various applications of\nmachine learning in the research process such as estimation, empirical\ndiscovery, testing, causal inference and prediction.",
        "link": "http://arxiv.org/abs/2103.00366v2",
        "published": "2021-02-28T01:10:09Z",
        "pdf_url": "http://arxiv.org/pdf/2103.00366v2.pdf",
        "txt_path": "data/txt/machine learning_paper_69.txt",
        "pdf_path": "data/pdfs/machine learning_paper_69.pdf"
    },
    {
        "title": "New Trends in Quantum Machine Learning",
        "abstract": "Here we will give a perspective on new possible interplays between Machine\nLearning and Quantum Physics, including also practical cases and applications.\nWe will explore the ways in which machine learning could benefit from new\nquantum technologies and algorithms to find new ways to speed up their\ncomputations by breakthroughs in physical hardware, as well as to improve\nexisting models or devise new learning schemes in the quantum domain. Moreover,\nthere are lots of experiments in quantum physics that do generate incredible\namounts of data and machine learning would be a great tool to analyze those and\nmake predictions, or even control the experiment itself. On top of that, data\nvisualization techniques and other schemes borrowed from machine learning can\nbe of great use to theoreticians to have better intuition on the structure of\ncomplex manifolds or to make predictions on theoretical models. This new\nresearch field, named as Quantum Machine Learning, is very rapidly growing\nsince it is expected to provide huge advantages over its classical counterpart\nand deeper investigations are timely needed since they can be already tested on\nthe already commercially available quantum machines.",
        "link": "http://arxiv.org/abs/2108.09664v1",
        "published": "2021-08-22T08:23:30Z",
        "pdf_url": "http://arxiv.org/pdf/2108.09664v1.pdf",
        "txt_path": "data/txt/machine learning_paper_70.txt",
        "pdf_path": "data/pdfs/machine learning_paper_70.pdf"
    },
    {
        "title": "Systematic Training and Testing for Machine Learning Using Combinatorial\n  Interaction Testing",
        "abstract": "This paper demonstrates the systematic use of combinatorial coverage for\nselecting and characterizing test and training sets for machine learning\nmodels. The presented work adapts combinatorial interaction testing, which has\nbeen successfully leveraged in identifying faults in software testing, to\ncharacterize data used in machine learning. The MNIST hand-written digits data\nis used to demonstrate that combinatorial coverage can be used to select test\nsets that stress machine learning model performance, to select training sets\nthat lead to robust model performance, and to select data for fine-tuning\nmodels to new domains. Thus, the results posit combinatorial coverage as a\nholistic approach to training and testing for machine learning. In contrast to\nprior work which has focused on the use of coverage in regard to the internal\nof neural networks, this paper considers coverage over simple features derived\nfrom inputs and outputs. Thus, this paper addresses the case where the supplier\nof test and training sets for machine learning models does not have\nintellectual property rights to the models themselves. Finally, the paper\naddresses prior criticism of combinatorial coverage and provides a rebuttal\nwhich advocates the use of coverage metrics in machine learning applications.",
        "link": "http://arxiv.org/abs/2201.12428v1",
        "published": "2022-01-28T21:33:31Z",
        "pdf_url": "http://arxiv.org/pdf/2201.12428v1.pdf",
        "txt_path": "data/txt/machine learning_paper_71.txt",
        "pdf_path": "data/pdfs/machine learning_paper_71.pdf"
    },
    {
        "title": "Software Testing for Machine Learning",
        "abstract": "Machine learning has become prevalent across a wide variety of applications.\nUnfortunately, machine learning has also shown to be susceptible to deception,\nleading to errors, and even fatal failures. This circumstance calls into\nquestion the widespread use of machine learning, especially in safety-critical\napplications, unless we are able to assure its correctness and trustworthiness\nproperties. Software verification and testing are established technique for\nassuring such properties, for example by detecting errors. However, software\ntesting challenges for machine learning are vast and profuse - yet critical to\naddress. This summary talk discusses the current state-of-the-art of software\ntesting for machine learning. More specifically, it discusses six key challenge\nareas for software testing of machine learning systems, examines current\napproaches to these challenges and highlights their limitations. The paper\nprovides a research agenda with elaborated directions for making progress\ntoward advancing the state-of-the-art on testing of machine learning.",
        "link": "http://arxiv.org/abs/2205.00210v1",
        "published": "2022-04-30T08:47:10Z",
        "pdf_url": "http://arxiv.org/pdf/2205.00210v1.pdf",
        "txt_path": "data/txt/machine learning_paper_72.txt",
        "pdf_path": "data/pdfs/machine learning_paper_72.pdf"
    },
    {
        "title": "PSI Draft Specification",
        "abstract": "This document presents the draft specification for delivering machine\nlearning services over HTTP, developed as part of the Protocols and Structures\nfor Inference project, which concluded in 2013. It presents the motivation for\nproviding machine learning as a service, followed by a description of the\nessential and optional components of such a service.",
        "link": "http://arxiv.org/abs/2205.09488v1",
        "published": "2022-05-02T02:42:16Z",
        "pdf_url": "http://arxiv.org/pdf/2205.09488v1.pdf",
        "txt_path": "data/txt/machine learning_paper_73.txt",
        "pdf_path": "data/pdfs/machine learning_paper_73.pdf"
    },
    {
        "title": "Practical Attacks on Machine Learning: A Case Study on Adversarial\n  Windows Malware",
        "abstract": "While machine learning is vulnerable to adversarial examples, it still lacks\nsystematic procedures and tools for evaluating its security in different\napplication contexts. In this article, we discuss how to develop automated and\nscalable security evaluations of machine learning using practical attacks,\nreporting a use case on Windows malware detection.",
        "link": "http://arxiv.org/abs/2207.05548v1",
        "published": "2022-07-12T14:17:58Z",
        "pdf_url": "http://arxiv.org/pdf/2207.05548v1.pdf",
        "txt_path": "data/txt/machine learning_paper_74.txt",
        "pdf_path": "data/pdfs/machine learning_paper_74.pdf"
    },
    {
        "title": "Fairness and Randomness in Machine Learning: Statistical Independence\n  and Relativization",
        "abstract": "Fair Machine Learning endeavors to prevent unfairness arising in the context\nof machine learning applications embedded in society. Despite the variety of\ndefinitions of fairness and proposed \"fair algorithms\", there remain unresolved\nconceptual problems regarding fairness. In this paper, we dissect the role of\nstatistical independence in fairness and randomness notions regularly used in\nmachine learning. Thereby, we are led to a suprising hypothesis: randomness and\nfairness can be considered equivalent concepts in machine learning.\n  In particular, we obtain a relativized notion of randomness expressed as\nstatistical independence by appealing to Von Mises' century-old foundations for\nprobability. This notion turns out to be \"orthogonal\" in an abstract sense to\nthe commonly used i.i.d.-randomness. Using standard fairness notions in machine\nlearning, which are defined via statistical independence, we then link the ex\nante randomness assumptions about the data to the ex post requirements for fair\npredictions. This connection proves fruitful: we use it to argue that\nrandomness and fairness are essentially relative and that both concepts should\nreflect their nature as modeling assumptions in machine learning.",
        "link": "http://arxiv.org/abs/2207.13596v2",
        "published": "2022-07-27T15:55:05Z",
        "pdf_url": "http://arxiv.org/pdf/2207.13596v2.pdf",
        "txt_path": "data/txt/machine learning_paper_75.txt",
        "pdf_path": "data/pdfs/machine learning_paper_75.pdf"
    },
    {
        "title": "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms",
        "abstract": "We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at this https URL",
        "link": "https://www.semanticscholar.org/paper/f9c602cc436a9ea2f9e7db48c77d924e09ce3c32",
        "published": "2017-08-25",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_76.txt",
        "pdf_path": null
    },
    {
        "title": "Physics-informed machine learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/53c9f3c34d8481adaf24df3b25581ccf1bc53f5c",
        "published": "2021-05-24",
        "pdf_url": "https://www.osti.gov/biblio/2282016",
        "txt_path": "data/txt/machine learning_paper_77.txt",
        "pdf_path": null
    },
    {
        "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems",
        "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
        "link": "https://www.semanticscholar.org/paper/9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d",
        "published": "2016-03-14",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_78.txt",
        "pdf_path": null
    },
    {
        "title": "A Survey on Bias and Fairness in Machine Learning",
        "abstract": "With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.",
        "link": "https://www.semanticscholar.org/paper/0090023afc66cd2741568599057f4e82b566137c",
        "published": "2019-08-23",
        "pdf_url": "https://arxiv.org/pdf/1908.09635",
        "txt_path": "data/txt/machine learning_paper_79.txt",
        "pdf_path": "data/pdfs/machine learning_paper_79.pdf"
    },
    {
        "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/bc00ff34ec7772080c7039b17f7069a2f7df0889",
        "published": "2018-11-26",
        "pdf_url": "https://www.nature.com/articles/s42256-019-0048-x.pdf",
        "txt_path": "data/txt/machine learning_paper_80.txt",
        "pdf_path": null
    },
    {
        "title": "Membership Inference Attacks Against Machine Learning Models",
        "abstract": "We quantitatively investigate how machine learning models leak information about the individual data records on which they were trained. We focus on the basic membership inference attack: given a data record and black-box access to a model, determine if the record was in the model's training dataset. To perform membership inference against a target model, we make adversarial use of machine learning and train our own inference model to recognize differences in the target model's predictions on the inputs that it trained on versus the inputs that it did not train on. We empirically evaluate our inference techniques on classification models trained by commercial \"machine learning as a service\" providers such as Google and Amazon. Using realistic datasets and classification tasks, including a hospital discharge dataset whose membership is sensitive from the privacy perspective, we show that these models can be vulnerable to membership inference attacks. We then investigate the factors that influence this leakage and evaluate mitigation strategies.",
        "link": "https://www.semanticscholar.org/paper/f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d",
        "published": "2016-10-18",
        "pdf_url": "https://arxiv.org/pdf/1610.05820",
        "txt_path": "data/txt/machine learning_paper_81.txt",
        "pdf_path": "data/pdfs/machine learning_paper_81.pdf"
    },
    {
        "title": "An Introduction to Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/794b3ffd28d28606230efc975eeec9f0522fb139",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_82.txt",
        "pdf_path": null
    },
    {
        "title": "Towards A Rigorous Science of Interpretable Machine Learning",
        "abstract": "As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.",
        "link": "https://www.semanticscholar.org/paper/5c39e37022661f81f79e481240ed9b175dec6513",
        "published": "2017-02-28",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_83.txt",
        "pdf_path": null
    },
    {
        "title": "Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting",
        "abstract": "The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting.",
        "link": "https://www.semanticscholar.org/paper/f9c990b1b5724e50e5632b94fdb7484ece8a6ce7",
        "published": "2015-06-13",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_84.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning: Algorithms, Real-World Applications and Research Directions",
        "abstract": "In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data, cybersecurity data, mobile data, business data, social media data, health data, etc. To intelligently analyze these data and develop the corresponding smart and automated applications, the knowledge of artificial intelligence (AI), particularly, machine learning (ML) is the key. Various types of machine learning algorithms such as supervised, unsupervised, semi-supervised, and reinforcement learning exist in the area. Besides, the deep learning, which is part of a broader family of machine learning methods, can intelligently analyze the data on a large scale. In this paper, we present a comprehensive view on these machine learning algorithms that can be applied to enhance the intelligence and the capabilities of an application. Thus, this study’s key contribution is explaining the principles of different machine learning techniques and their applicability in various real-world application domains, such as cybersecurity systems, smart cities, healthcare, e-commerce, agriculture, and many more. We also highlight the challenges and potential research directions based on our study. Overall, this paper aims to serve as a reference point for both academia and industry professionals as well as for decision-makers in various real-world situations and application areas, particularly from the technical point of view.",
        "link": "https://www.semanticscholar.org/paper/7872f34e2a164c5cf3c34a7a7433dc3342b6c7ea",
        "published": "2021-03-08",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/s42979-021-00592-x.pdf",
        "txt_path": "data/txt/machine learning_paper_85.txt",
        "pdf_path": null
    },
    {
        "title": "Pattern Recognition And Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/8e3c872076750bcce868808f9d4d7a038f950040",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_86.txt",
        "pdf_path": null
    },
    {
        "title": "Open Graph Benchmark: Datasets for Machine Learning on Graphs",
        "abstract": "We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale (up to 100+ million nodes and 1+ billion edges), encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders, evaluation scripts, baseline code, and leaderboards are publicly available at this https URL .",
        "link": "https://www.semanticscholar.org/paper/597bd2e45427563cdf025e53a3239006aa364cfc",
        "published": "2020-05-02",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_87.txt",
        "pdf_path": null
    },
    {
        "title": "Foundations of Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/9f5b82d9915d0752957602224c5056be7e749c83",
        "published": "2021-10-07",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_88.txt",
        "pdf_path": null
    },
    {
        "title": "Scikit-learn: Machine Learning in Python",
        "abstract": "Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.",
        "link": "https://www.semanticscholar.org/paper/ad4fd2c149f220a62441576af92a8a669fe81246",
        "published": "2011-02-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_89.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning: Trends, perspectives, and prospects",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/d422df8bff4e677a3077635db116679d25142bfc",
        "published": "2015-07-17",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_90.txt",
        "pdf_path": null
    },
    {
        "title": "Practical Black-Box Attacks against Machine Learning",
        "abstract": "Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19% and 88.94%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.",
        "link": "https://www.semanticscholar.org/paper/53b047e503f4c24602f376a774d653f7ed56c024",
        "published": "2016-02-08",
        "pdf_url": "http://arxiv.org/pdf/1602.02697",
        "txt_path": "data/txt/machine learning_paper_91.txt",
        "pdf_path": "data/pdfs/machine learning_paper_91.pdf"
    },
    {
        "title": "C4.5: Programs for Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/807c1f19047f96083e13614f7ce20f2ac98c239a",
        "published": "1992-10-15",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_92.txt",
        "pdf_path": null
    },
    {
        "title": "Data Mining Practical Machine Learning Tools and Techniques",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/730ca170962a58607e092035beb2afc4b5fa6242",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_93.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning - a probabilistic perspective",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/360ca02e6f5a5e1af3dce4866a257aafc2d6d6f5",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_94.txt",
        "pdf_path": null
    },
    {
        "title": "Interpretable Machine Learning",
        "abstract": "Interpretable machine learning has become a popular research direction as deep neural networks (DNNs) have become more powerful and their applications more mainstream, yet DNNs remain difficult to understand. Testing with Concept Activation Vectors, TCAV, (Kim et al. 2017) is an approach to interpreting DNNs in a human-friendly way and has recently received significant attention in the machine learning community. The TCAV algorithm achieves a degree of global interpretability for DNNs through human-defined concepts as explanations. This project introduces Robust TCAV, which builds on TCAV and experimentally determines best practices for this method. The objectives for Robust TCAV are 1) Making TCAV more consistent by reducing variance in the TCAV score distribution and 2) Increasing CAV and TCAV score resistance to perturbations. A difference of means method for CAV generation was determined to be the best practice to achieve both objectives. Many areas of the TCAV process are explored including CAV visualization in low dimensions, negative class selection, and activation perturbation in the direction of a CAV. Finally, a thresholding technique is considered to remove noise in TCAV scores. This project is a step in the direction of making TCAV, an already impactful algorithm in interpretability, more reliable and useful for practitioners.",
        "link": "https://www.semanticscholar.org/paper/b0c34618ffd1154f35863e2ce7250ac6b6f2c424",
        "published": "2019-11-07",
        "pdf_url": "https://openresearch.surrey.ac.uk/view/delivery/44SUR_INST/12184120880002346/13184120870002346",
        "txt_path": "data/txt/machine learning_paper_95.txt",
        "pdf_path": "data/pdfs/machine learning_paper_95.pdf"
    },
    {
        "title": "Optimization Methods for Large-Scale Machine Learning",
        "abstract": "This paper provides a review and commentary on the past, present, and future of numerical optimization algorithms in the context of machine learning applications. Through case studies on text classification and the training of deep neural networks, we discuss how optimization problems arise in machine learning and what makes them challenging. A major theme of our study is that large-scale machine learning represents a distinctive setting in which the stochastic gradient (SG) method has traditionally played a central role while conventional gradient-based nonlinear optimization techniques typically falter. Based on this viewpoint, we present a comprehensive theory of a straightforward, yet versatile SG algorithm, discuss its practical behavior, and highlight opportunities for designing algorithms with improved performance. This leads to a discussion about the next generation of optimization methods for large-scale machine learning, including an investigation of two main streams of research on techniques that diminish noise in the stochastic directions and methods that make use of second-order derivative approximations.",
        "link": "https://www.semanticscholar.org/paper/d21703674ae562bae4a849a75847cdd9ead417df",
        "published": "2016-06-15",
        "pdf_url": "https://arxiv.org/pdf/1606.04838",
        "txt_path": "data/txt/machine learning_paper_96.txt",
        "pdf_path": "data/pdfs/machine learning_paper_96.pdf"
    },
    {
        "title": "Machine Learning Algorithms: A Review",
        "abstract": ".",
        "link": "https://www.semanticscholar.org/paper/56e8863838b4dcc4790108cd1e7e680a104a7c30",
        "published": "2022-08-05",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_97.txt",
        "pdf_path": null
    },
    {
        "title": "Practical Bayesian Optimization of Machine Learning Algorithms",
        "abstract": "The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a \"black art\" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.",
        "link": "https://www.semanticscholar.org/paper/2e2089ae76fe914706e6fa90081a79c8fe01611e",
        "published": "2012-06-13",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_98.txt",
        "pdf_path": null
    },
    {
        "title": "Genetic Algorithms in Search Optimization and Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/2e62d1345b340d5fda3b092c460264b9543bc4b5",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_99.txt",
        "pdf_path": null
    },
    {
        "title": "Pattern Recognition and Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/668b1277fbece28c4841eeab1c97e4ebd0079700",
        "published": "2006-08-01",
        "pdf_url": "http://cds.cern.ch/record/998831/files/9780387310732_TOC.pdf",
        "txt_path": "data/txt/machine learning_paper_100.txt",
        "pdf_path": null
    },
    {
        "title": "This Paper Is Included in the Proceedings of the 12th Usenix Symposium on Operating Systems Design and Implementation (osdi '16). Tensorflow: a System for Large-scale Machine Learning Tensorflow: a System for Large-scale Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/4954fa180728932959997a4768411ff9136aac81",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_101.txt",
        "pdf_path": null
    },
    {
        "title": "On Hyperparameter Optimization of Machine Learning Algorithms: Theory and Practice",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/2e5d2f2dc01b150dffc163a9f457848e9b5b5c38",
        "published": "2020-07-30",
        "pdf_url": "https://arxiv.org/pdf/2007.15745",
        "txt_path": "data/txt/machine learning_paper_102.txt",
        "pdf_path": "data/pdfs/machine learning_paper_102.pdf"
    },
    {
        "title": "ilastik: interactive machine learning for (bio)image analysis",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/5d433da6d0f143f20936379910104d2bb139d4ae",
        "published": "2019-09-30",
        "pdf_url": "http://archiv.ub.uni-heidelberg.de/volltextserver/28283/7/Berg_ilastik_2020.pdf",
        "txt_path": "data/txt/machine learning_paper_103.txt",
        "pdf_path": "data/pdfs/machine learning_paper_103.pdf"
    },
    {
        "title": "Explainable AI: A Review of Machine Learning Interpretability Methods",
        "abstract": "Recent advances in artificial intelligence (AI) have led to its widespread industrial adoption, with machine learning systems demonstrating superhuman performance in a significant number of tasks. However, this surge in performance, has often been achieved through increased model complexity, turning such systems into “black box” approaches and causing uncertainty regarding the way they operate and, ultimately, the way that they come to decisions. This ambiguity has made it problematic for machine learning systems to be adopted in sensitive yet critical domains, where their value could be immense, such as healthcare. As a result, scientific interest in the field of Explainable Artificial Intelligence (XAI), a field that is concerned with the development of new methods that explain and interpret machine learning models, has been tremendously reignited over recent years. This study focuses on machine learning interpretability methods; more specifically, a literature review and taxonomy of these methods are presented, as well as links to their programming implementations, in the hope that this survey would serve as a reference point for both theorists and practitioners.",
        "link": "https://www.semanticscholar.org/paper/f156ecbbb9243522275490d698c6825f4d2e01af",
        "published": "2020-12-25",
        "pdf_url": "https://www.mdpi.com/1099-4300/23/1/18/pdf?version=1609160444",
        "txt_path": "data/txt/machine learning_paper_104.txt",
        "pdf_path": null
    },
    {
        "title": "SoilGrids250m: Global gridded soil information based on machine learning",
        "abstract": "This paper describes the technical development and accuracy assessment of the most recent and improved version of the SoilGrids system at 250m resolution (June 2016 update). SoilGrids provides global predictions for standard numeric soil properties (organic carbon, bulk density, Cation Exchange Capacity (CEC), pH, soil texture fractions and coarse fragments) at seven standard depths (0, 5, 15, 30, 60, 100 and 200 cm), in addition to predictions of depth to bedrock and distribution of soil classes based on the World Reference Base (WRB) and USDA classification systems (ca. 280 raster layers in total). Predictions were based on ca. 150,000 soil profiles used for training and a stack of 158 remote sensing-based soil covariates (primarily derived from MODIS land products, SRTM DEM derivatives, climatic images and global landform and lithology maps), which were used to fit an ensemble of machine learning methods—random forest and gradient boosting and/or multinomial logistic regression—as implemented in the R packages ranger, xgboost, nnet and caret. The results of 10–fold cross-validation show that the ensemble models explain between 56% (coarse fragments) and 83% (pH) of variation with an overall average of 61%. Improvements in the relative accuracy considering the amount of variation explained, in comparison to the previous version of SoilGrids at 1 km spatial resolution, range from 60 to 230%. Improvements can be attributed to: (1) the use of machine learning instead of linear regression, (2) to considerable investments in preparing finer resolution covariate layers and (3) to insertion of additional soil profiles. Further development of SoilGrids could include refinement of methods to incorporate input uncertainties and derivation of posterior probability distributions (per pixel), and further automation of spatial modeling so that soil maps can be generated for potentially hundreds of soil variables. Another area of future research is the development of methods for multiscale merging of SoilGrids predictions with local and/or national gridded soil products (e.g. up to 50 m spatial resolution) so that increasingly more accurate, complete and consistent global soil information can be produced. SoilGrids are available under the Open Data Base License.",
        "link": "https://www.semanticscholar.org/paper/9e27190f2d9b2167d4a66b88696def4585072fd5",
        "published": "2017-02-16",
        "pdf_url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0169748&type=printable",
        "txt_path": "data/txt/machine learning_paper_105.txt",
        "pdf_path": "data/pdfs/machine learning_paper_105.pdf"
    },
    {
        "title": "Machine learning for molecular and materials science",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/c292e473b3825eeb9db03c70b2e1c033aea190d5",
        "published": "2018-07-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_106.txt",
        "pdf_path": null
    },
    {
        "title": "Practical Secure Aggregation for Privacy-Preserving Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/db0cc2f21b20cbc0ab8946090967399c25709614",
        "published": "2017-10-30",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_107.txt",
        "pdf_path": null
    },
    {
        "title": "Thumbs up? Sentiment Classification using Machine Learning Techniques",
        "abstract": "We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.",
        "link": "https://www.semanticscholar.org/paper/12d0353ce8b41b7e5409e5a4a611110aee33c7bc",
        "published": "2002-05-27",
        "pdf_url": "https://dl.acm.org/doi/pdf/10.3115/1118693.1118704",
        "txt_path": "data/txt/machine learning_paper_108.txt",
        "pdf_path": null
    },
    {
        "title": "Multimodal Machine Learning: A Survey and Taxonomy",
        "abstract": "Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.",
        "link": "https://www.semanticscholar.org/paper/6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91",
        "published": "2017-05-26",
        "pdf_url": "http://arxiv.org/pdf/1705.09406",
        "txt_path": "data/txt/machine learning_paper_109.txt",
        "pdf_path": "data/pdfs/machine learning_paper_109.pdf"
    },
    {
        "title": "The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web]",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/46f74231b9afeb0c290d6d550043c55045284e5f",
        "published": "2012-10-18",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_110.txt",
        "pdf_path": null
    },
    {
        "title": "Double/Debiased Machine Learning for Treatment and Structural Parameters",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/f75b70c9d7078724b592ec3e21de705e7b6ff73f",
        "published": "2017-06-01",
        "pdf_url": "https://academic.oup.com/ectj/article-pdf/21/1/C1/27684918/ectj00c1.pdf",
        "txt_path": "data/txt/machine learning_paper_111.txt",
        "pdf_path": null
    },
    {
        "title": "Large-Scale Machine Learning with Stochastic Gradient Descent",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/fbc6562814e08e416e28a268ce7beeaa3d0708c8",
        "published": null,
        "pdf_url": "http://leon.bottou.org/publications/pdf/compstat-2010.pdf",
        "txt_path": "data/txt/machine learning_paper_112.txt",
        "pdf_path": "data/pdfs/machine learning_paper_112.pdf"
    },
    {
        "title": "Adversarial Machine Learning at Scale",
        "abstract": "Adversarial examples are malicious inputs designed to fool machine learning models. They often transfer from one model to another, allowing attackers to mount black box attacks without knowledge of the target model's parameters. Adversarial training is the process of explicitly training a model on adversarial examples, in order to make it more robust to attack or to reduce its test error on clean inputs. So far, adversarial training has primarily been applied to small problems. In this research, we apply adversarial training to ImageNet. Our contributions include: (1) recommendations for how to succesfully scale adversarial training to large models and datasets, (2) the observation that adversarial training confers robustness to single-step attack methods, (3) the finding that multi-step attack methods are somewhat less transferable than single-step attack methods, so single-step attacks are the best for mounting black-box attacks, and (4) resolution of a \"label leaking\" effect that causes adversarially trained models to perform better on adversarial examples than on clean examples, because the adversarial example construction process uses the true label and the model can learn to exploit regularities in the construction process.",
        "link": "https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827",
        "published": "2016-11-03",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_113.txt",
        "pdf_path": null
    },
    {
        "title": "UCI Repository of machine learning databases",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/e068be31ded63600aea068eacd12931efd2a1029",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_114.txt",
        "pdf_path": null
    },
    {
        "title": "Applications of machine learning to machine fault diagnosis: A review and roadmap",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/7ae2783a9196fb4bc2a610ae812d19722daddce5",
        "published": "2020-04-01",
        "pdf_url": "http://bura.brunel.ac.uk/bitstream/2438/20040/1/FullText.pdf",
        "txt_path": "data/txt/machine learning_paper_115.txt",
        "pdf_path": "data/pdfs/machine learning_paper_115.pdf"
    },
    {
        "title": "Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/2936cbd6a90d7153a9fa34e8e4fd947907fe7f6c",
        "published": "2017-04-18",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_116.txt",
        "pdf_path": null
    },
    {
        "title": "Programs for Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/7feb0fc888cd55360949554db032d7d1cba9e947",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_117.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning in automated text categorization",
        "abstract": "The automated categorization (or classification) of texts into predefined categories has witnessed a booming interest in the last 10 years, due to the increased availability of documents in digital form and the ensuing need to organize them. In the research community the dominant approach to this problem is based on machine learning techniques: a general inductive process automatically builds a classifier by learning, from a set of preclassified documents, the characteristics of the categories. The advantages of this approach over the knowledge engineering approach (consisting in the manual definition of a classifier by domain experts) are a very good effectiveness, considerable savings in terms of expert labor power, and straightforward portability to different domains. This survey discusses the main approaches to text categorization that fall within the machine learning paradigm. We will discuss in detail issues pertaining to three different problems, namely, document representation, classifier construction, and classifier evaluation.",
        "link": "https://www.semanticscholar.org/paper/6b20af22b0734757d9ead382b201a65f9dd637cc",
        "published": "2001-10-26",
        "pdf_url": "http://arxiv.org/pdf/cs/0110053",
        "txt_path": "data/txt/machine learning_paper_118.txt",
        "pdf_path": "data/pdfs/machine learning_paper_118.pdf"
    },
    {
        "title": "Understanding of Machine Learning with Deep Learning: Architectures, Workflow, Applications and Future Directions",
        "abstract": "In recent years, deep learning (DL) has been the most popular computational approach in the field of machine learning (ML), achieving exceptional results on a variety of complex cognitive tasks, matching or even surpassing human performance. Deep learning technology, which grew out of artificial neural networks (ANN), has become a big deal in computing because it can learn from data. The ability to learn enormous volumes of data is one of the benefits of deep learning. In the past few years, the field of deep learning has grown quickly, and it has been used successfully in a wide range of traditional fields. In numerous disciplines, including cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, deep learning has outperformed well-known machine learning approaches. In order to provide a more ideal starting point from which to create a comprehensive understanding of deep learning, also, this article aims to provide a more detailed overview of the most significant facets of deep learning, including the most current developments in the field. Moreover, this paper discusses the significance of deep learning and the various deep learning techniques and networks. Additionally, it provides an overview of real-world application areas where deep learning techniques can be utilised. We conclude by identifying possible characteristics for future generations of deep learning modelling and providing research suggestions. On the same hand, this article intends to provide a comprehensive overview of deep learning modelling that can serve as a resource for academics and industry people alike. Lastly, we provide additional issues and recommended solutions to assist researchers in comprehending the existing research gaps. Various approaches, deep learning architectures, strategies, and applications are discussed in this work.",
        "link": "https://www.semanticscholar.org/paper/df70977e0347b76fb049c17c3956f643bcb43a55",
        "published": "2023-04-25",
        "pdf_url": "https://www.mdpi.com/2073-431X/12/5/91/pdf?version=1682405138",
        "txt_path": "data/txt/machine learning_paper_119.txt",
        "pdf_path": null
    },
    {
        "title": "Small data machine learning in materials science",
        "abstract": "This review discussed the dilemma of small data faced by materials machine learning. First, we analyzed the limitations brought by small data. Then, the workflow of materials machine learning has been introduced. Next, the methods of dealing with small data were introduced, including data extraction from publications, materials database construction, high-throughput computations and experiments from the data source level; modeling algorithms for small data and imbalanced learning from the algorithm level; active learning and transfer learning from the machine learning strategy level. Finally, the future directions for small data machine learning in materials science were proposed.",
        "link": "https://www.semanticscholar.org/paper/35b1d79993f0e4fbfcb3b86c5013c5e2a7e3117c",
        "published": "2023-03-25",
        "pdf_url": "https://www.nature.com/articles/s41524-023-01000-z.pdf",
        "txt_path": "data/txt/machine learning_paper_120.txt",
        "pdf_path": "data/pdfs/machine learning_paper_120.pdf"
    },
    {
        "title": "Understanding Machine Learning - From Theory to Algorithms",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/20f63033e8775cbab0692aed92d38da7e725d64e",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_121.txt",
        "pdf_path": null
    },
    {
        "title": "Federated Machine Learning",
        "abstract": "Today’s artificial intelligence still faces two major challenges. One is that, in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security. We propose a possible solution to these challenges: secure federated learning. Beyond the federated-learning framework first proposed by Google in 2016, we introduce a comprehensive secure federated-learning framework, which includes horizontal federated learning, vertical federated learning, and federated transfer learning. We provide definitions, architectures, and applications for the federated-learning framework, and provide a comprehensive survey of existing works on this subject. In addition, we propose building data networks among organizations based on federated mechanisms as an effective solution to allowing knowledge to be shared without compromising user privacy.",
        "link": "https://www.semanticscholar.org/paper/62ccd99a65bfc7c735ae1f33b75b107665de95df",
        "published": "2019-01-28",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_122.txt",
        "pdf_path": null
    },
    {
        "title": "Neural Machine Translation by Jointly Learning to Align and Translate",
        "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
        "link": "https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
        "published": "2014-09-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_123.txt",
        "pdf_path": null
    },
    {
        "title": "Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation",
        "abstract": "In this paper, we propose a novel neural network model called RNN Encoder‐ Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder‐Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
        "link": "https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e",
        "published": "2014-06-03",
        "pdf_url": "https://aclanthology.org/D14-1179.pdf",
        "txt_path": "data/txt/machine learning_paper_124.txt",
        "pdf_path": "data/pdfs/machine learning_paper_124.pdf"
    },
    {
        "title": "Machine Learning for High-Speed Corner Detection",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/e0408181bccb7e3754dd5e6785ec47d8beb8b6bd",
        "published": "2006-05-07",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/11744023_34.pdf",
        "txt_path": "data/txt/machine learning_paper_125.txt",
        "pdf_path": "data/pdfs/machine learning_paper_125.pdf"
    },
    {
        "title": "Machine Learning for Fluid Mechanics",
        "abstract": "The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from experiments, field measurements, and large-scale simulations at multiple spatiotemporal scales. Machine learning (ML) offers a wealth of techniques to extract information from data that can be translated into knowledge about the underlying fluid mechanics. Moreover, ML algorithms can augment domain knowledge and automate tasks related to flow control and optimization. This article presents an overview of past history, current developments, and emerging opportunities of ML for fluid mechanics. We outline fundamental ML methodologies and discuss their uses for understanding, modeling, optimizing, and controlling fluid flows. The strengths and limitations of these methods are addressed from the perspective of scientific inquiry that considers data as an inherent part of modeling, experiments, and simulations. ML provides a powerful information-processing framework that can augment, and possibly even transform, current lines of fluid mechanics research and industrial applications.",
        "link": "https://www.semanticscholar.org/paper/4087e84fc695bb6433d0104ee94f9d7e9f4b7da5",
        "published": "2019-05-27",
        "pdf_url": "https://arxiv.org/pdf/1905.11075",
        "txt_path": "data/txt/machine learning_paper_126.txt",
        "pdf_path": "data/pdfs/machine learning_paper_126.pdf"
    },
    {
        "title": "Machine learning–accelerated computational fluid dynamics",
        "abstract": "Significance Accurate simulation of fluids is important for many science and engineering problems but is very computationally demanding. In contrast, machine-learning models can approximate physics very quickly but at the cost of accuracy. Here we show that using machine learning inside traditional fluid simulations can improve both accuracy and speed, even on examples very different from the training data. Our approach opens the door to applying machine learning to large-scale physical modeling tasks like airplane design and climate prediction. Numerical simulation of fluids plays an essential role in modeling many physical phenomena, such as weather, climate, aerodynamics, and plasma physics. Fluids are well described by the Navier–Stokes equations, but solving these equations at scale remains daunting, limited by the computational cost of resolving the smallest spatiotemporal features. This leads to unfavorable trade-offs between accuracy and tractability. Here we use end-to-end deep learning to improve approximations inside computational fluid dynamics for modeling two-dimensional turbulent flows. For both direct numerical simulation of turbulence and large-eddy simulation, our results are as accurate as baseline solvers with 8 to 10× finer resolution in each spatial dimension, resulting in 40- to 80-fold computational speedups. Our method remains stable during long simulations and generalizes to forcing functions and Reynolds numbers outside of the flows where it is trained, in contrast to black-box machine-learning approaches. Our approach exemplifies how scientific computing can leverage machine learning and hardware accelerators to improve simulations without sacrificing accuracy or generalization.",
        "link": "https://www.semanticscholar.org/paper/2afa490dde7a8c582d889530c7f8b042fef6a8b7",
        "published": "2021-01-28",
        "pdf_url": "https://doi.org/10.1073/pnas.2101784118",
        "txt_path": "data/txt/machine learning_paper_127.txt",
        "pdf_path": null
    },
    {
        "title": "Classification Based on Decision Tree Algorithm for Machine Learning",
        "abstract": "Decision tree classifiers are regarded to be a standout of the most well-known methods to data classification representation of classifiers. Different researchers from various fields and backgrounds have considered the problem of extending a decision tree from available data, such as machine study, pattern recognition, and statistics. In various fields such as medical disease analysis, text classification, user smartphone classification, images, and many more the employment of Decision tree classifiers has been proposed in many ways. This paper provides a detailed approach to the decision trees. Furthermore, paper specifics, such as algorithms/approaches used, datasets, and outcomes achieved, are evaluated and outlined comprehensively. In addition, all of the approaches analyzed were discussed to illustrate the themes of the authors and identify the most accurate classifiers. As a result, the uses of different types of datasets are discussed and their findings are analyzed.",
        "link": "https://www.semanticscholar.org/paper/0d6ef817813d04a3b3ec6c3ce008e104fb3e587a",
        "published": "2021-03-24",
        "pdf_url": "https://www.jastt.org/index.php/jasttpath/article/download/65/24",
        "txt_path": "data/txt/machine learning_paper_128.txt",
        "pdf_path": "data/pdfs/machine learning_paper_128.pdf"
    },
    {
        "title": "Federated Learning: Collaborative Machine Learning without\nCentralized Training Data",
        "abstract": "Federated learning (also known as collaborative learning) is a machine learning technique that trains\nan algorithm without transferring data samples across numerous decentralized edge devices or\nservers. This strategy differs from standard centralized machine learning techniques in which all local\ndatasets are uploaded to a single server, as well as more traditional decentralized alternatives, which\nfrequently presume that local data samples are uniformly distributed.\nFederated learning allows several actors to collaborate on the development of a single, robust\nmachine learning model without sharing data, allowing crucial issues such as data privacy, data\nsecurity, data access rights, and access to heterogeneous data to be addressed. Defence,\ntelecommunications, internet of things, and pharmaceutical industries are just a few of the sectors\nwhere it has applications.",
        "link": "https://www.semanticscholar.org/paper/6a6ad9eb495739f4c80e7c09598720c3d5c5dff7",
        "published": "2022-09-28",
        "pdf_url": "https://doi.org/10.46647/ijetms.2022.v06i05.052",
        "txt_path": "data/txt/machine learning_paper_129.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning and deep learning",
        "abstract": "Today, intelligent systems that offer artificial intelligence capabilities often rely on machine learning. Machine learning describes the capacity of systems to learn from problem-specific training data to automate the process of analytical model building and solve associated tasks. Deep learning is a machine learning concept based on artificial neural networks. For many applications, deep learning models outperform shallow machine learning models and traditional data analysis approaches. In this article, we summarize the fundamentals of machine learning and deep learning to generate a broader understanding of the methodical underpinning of current intelligent systems. In particular, we provide a conceptual distinction between relevant terms and concepts, explain the process of automated analytical model building through machine learning and deep learning, and discuss the challenges that arise when implementing such intelligent systems in the field of electronic markets and networked business. These naturally go beyond technological aspects and highlight issues in human-machine interaction and artificial intelligence servitization.",
        "link": "https://www.semanticscholar.org/paper/a0f303b6e22ef52943355993f57d65938997066a",
        "published": "2021-04-08",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/s12525-021-00475-2.pdf",
        "txt_path": "data/txt/machine learning_paper_130.txt",
        "pdf_path": "data/pdfs/machine learning_paper_130.pdf"
    },
    {
        "title": "A Review on Fairness in Machine Learning",
        "abstract": "An increasing number of decisions regarding the daily lives of human beings are being controlled by artificial intelligence and machine learning (ML) algorithms in spheres ranging from healthcare, transportation, and education to college admissions, recruitment, provision of loans, and many more realms. Since they now touch on many aspects of our lives, it is crucial to develop ML algorithms that are not only accurate but also objective and fair. Recent studies have shown that algorithmic decision making may be inherently prone to unfairness, even when there is no intention for it. This article presents an overview of the main concepts of identifying, measuring, and improving algorithmic fairness when using ML algorithms, focusing primarily on classification tasks. The article begins by discussing the causes of algorithmic bias and unfairness and the common definitions and measures for fairness. Fairness-enhancing mechanisms are then reviewed and divided into pre-process, in-process, and post-process mechanisms. A comprehensive comparison of the mechanisms is then conducted, toward a better understanding of which mechanisms should be used in different scenarios. The article ends by reviewing several emerging research sub-fields of algorithmic fairness, beyond classification.",
        "link": "https://www.semanticscholar.org/paper/f64670a5f54fcce339a916497a001cbf02a9a04f",
        "published": "2022-02-03",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_131.txt",
        "pdf_path": null
    },
    {
        "title": "Correlation-based Feature Selection for Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/6bc43977fb11cceed0b9aa55b23c6dd29dd9a132",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_132.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/9583ac53a19cdf0db81fef6eb0b63e66adbe2324",
        "published": "2017-12-04",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_133.txt",
        "pdf_path": null
    },
    {
        "title": "A guide to machine learning for biologists",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/80d9f0eb47b712988d19cbe29a7bfa63f2a175d0",
        "published": "2021-09-13",
        "pdf_url": "https://discovery.ucl.ac.uk/10134478/1/NRMCB-review-accepted-forRPS.pdf",
        "txt_path": "data/txt/machine learning_paper_134.txt",
        "pdf_path": "data/pdfs/machine learning_paper_134.pdf"
    },
    {
        "title": "CrypTen: Secure Multi-Party Computation Meets Machine Learning",
        "abstract": "Secure multi-party computation (MPC) allows parties to perform computations on data while keeping that data private. This capability has great potential for machine-learning applications: it facilitates training of machine-learning models on private data sets owned by different parties, evaluation of one party's private model using another party's private data, etc. Although a range of studies implement machine-learning models via secure MPC, such implementations are not yet mainstream. Adoption of secure MPC is hampered by the absence of flexible software frameworks that\"speak the language\"of machine-learning researchers and engineers. To foster adoption of secure MPC in machine learning, we present CrypTen: a software framework that exposes popular secure MPC primitives via abstractions that are common in modern machine-learning frameworks, such as tensor computations, automatic differentiation, and modular neural networks. This paper describes the design of CrypTen and measure its performance on state-of-the-art models for text classification, speech recognition, and image classification. Our benchmarks show that CrypTen's GPU support and high-performance communication between (an arbitrary number of) parties allows it to perform efficient private evaluation of modern machine-learning models under a semi-honest threat model. For example, two parties using CrypTen can securely predict phonemes in speech recordings using Wav2Letter faster than real-time. We hope that CrypTen will spur adoption of secure MPC in the machine-learning community.",
        "link": "https://www.semanticscholar.org/paper/7eb733c8ac1b3d1dd8b50e066ddae10769e3b46e",
        "published": "2021-09-02",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_135.txt",
        "pdf_path": null
    },
    {
        "title": "Supervised Machine Learning: A Review of Classification Techniques",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/f1b962fb4070fedd46758e334db3ba4f00ddc3ec",
        "published": "2007-06-10",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_136.txt",
        "pdf_path": null
    },
    {
        "title": "The use of the area under the ROC curve in the evaluation of machine learning algorithms",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/48ddd9101a90fe65e3061de69626741b843ff5e4",
        "published": "1997-07-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_137.txt",
        "pdf_path": null
    },
    {
        "title": "Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/8ca86e941da7254613a5d03dd7a6c36886fadc1d",
        "published": "2005-12-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_138.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning With Python",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/eb9e0da8b7170e3ca4364f2f9010599c2d2556f1",
        "published": "2019-05-08",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_139.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning-aided engineering of hydrolases for PET depolymerization",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/8fedd23c1604dfeed02b75f8d38c1d7e33beee3a",
        "published": "2022-04-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_140.txt",
        "pdf_path": null
    },
    {
        "title": "Educational data mining: prediction of students' academic performance using machine learning algorithms",
        "abstract": "Educational data mining has become an effective tool for exploring the hidden relationships in educational data and predicting students' academic achievements. This study proposes a new model based on machine learning algorithms to predict the final exam grades of undergraduate students, taking their midterm exam grades as the source data. The performances of the random forests, nearest neighbour, support vector machines, logistic regression, Naïve Bayes, and k-nearest neighbour algorithms, which are among the machine learning algorithms, were calculated and compared to predict the final exam grades of the students. The dataset consisted of the academic achievement grades of 1854 students who took the Turkish Language-I course in a state University in Turkey during the fall semester of 2019–2020. The results show that the proposed model achieved a classification accuracy of 70–75%. The predictions were made using only three types of parameters; midterm exam grades, Department data and Faculty data. Such data-driven studies are very important in terms of establishing a learning analysis framework in higher education and contributing to the decision-making processes. Finally, this study presents a contribution to the early prediction of students at high risk of failure and determines the most effective machine learning methods.",
        "link": "https://www.semanticscholar.org/paper/0ad4189bdddfa32ecf7b1c9122eba57c8d8bbc7f",
        "published": "2022-03-03",
        "pdf_url": "https://slejournal.springeropen.com/track/pdf/10.1186/s40561-022-00192-z",
        "txt_path": "data/txt/machine learning_paper_141.txt",
        "pdf_path": "data/pdfs/machine learning_paper_141.pdf"
    },
    {
        "title": "A Review of Feature Selection Methods for Machine Learning-Based Disease Risk Prediction",
        "abstract": "Machine learning has shown utility in detecting patterns within large, unstructured, and complex datasets. One of the promising applications of machine learning is in precision medicine, where disease risk is predicted using patient genetic data. However, creating an accurate prediction model based on genotype data remains challenging due to the so-called “curse of dimensionality” (i.e., extensively larger number of features compared to the number of samples). Therefore, the generalizability of machine learning models benefits from feature selection, which aims to extract only the most “informative” features and remove noisy “non-informative,” irrelevant and redundant features. In this article, we provide a general overview of the different feature selection methods, their advantages, disadvantages, and use cases, focusing on the detection of relevant features (i.e., SNPs) for disease risk prediction.",
        "link": "https://www.semanticscholar.org/paper/911fbaec109f72130815e05e2633ec879590382c",
        "published": "2022-06-27",
        "pdf_url": "https://www.frontiersin.org/articles/10.3389/fbinf.2022.927312/pdf",
        "txt_path": "data/txt/machine learning_paper_142.txt",
        "pdf_path": "data/pdfs/machine learning_paper_142.pdf"
    },
    {
        "title": "Human-in-the-loop machine learning: a state of the art",
        "abstract": "Researchers are defining new types of interactions between humans and machine learning algorithms generically called human-in-the-loop machine learning. Depending on who is in control of the learning process, we can identify: active learning, in which the system remains in control; interactive machine learning, in which there is a closer interaction between users and learning systems; and machine teaching, where human domain experts have control over the learning process. Aside from control, humans can also be involved in the learning process in other ways. In curriculum learning human domain experts try to impose some structure on the examples presented to improve the learning; in explainable AI the focus is on the ability of the model to explain to humans why a given solution was chosen. This collaboration between AI models and humans should not be limited only to the learning process; if we go further, we can see other terms that arise such as Usable and Useful AI. In this paper we review the state of the art of the techniques involved in the new forms of relationship between humans and ML algorithms. Our contribution is not merely listing the different approaches, but to provide definitions clarifying confusing, varied and sometimes contradictory terms; to elucidate and determine the boundaries between the different methods; and to correlate all the techniques searching for the connections and influences between them.",
        "link": "https://www.semanticscholar.org/paper/62cadbc4fcc73204a72847300cb2214f4401efad",
        "published": "2022-08-17",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10462-022-10246-w.pdf",
        "txt_path": "data/txt/machine learning_paper_143.txt",
        "pdf_path": "data/pdfs/machine learning_paper_143.pdf"
    },
    {
        "title": "Challenges and opportunities in quantum machine learning",
        "abstract": "At the intersection of machine learning and quantum computing, quantum machine learning has the potential of accelerating data analysis, especially for quantum data, with applications for quantum materials, biochemistry and high-energy physics. Nevertheless, challenges remain regarding the trainability of quantum machine learning models. Here we review current methods and applications for quantum machine learning. We highlight differences between quantum and classical machine learning, with a focus on quantum neural networks and quantum deep learning. Finally, we discuss opportunities for quantum advantage with quantum machine learning. Quantum machine learning has become an essential tool to process and analyze the increased amount of quantum data. Despite recent progress, there are still many challenges to be addressed and myriad future avenues of research.",
        "link": "https://www.semanticscholar.org/paper/ab06951251e0abfdb866694f9a23a79c72784317",
        "published": "2022-09-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_144.txt",
        "pdf_path": null
    },
    {
        "title": "SecureML: A System for Scalable Privacy-Preserving Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/2b7f9117eb6608a58be4c078ca3d69c0e5ccb875",
        "published": "2017-05-22",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_145.txt",
        "pdf_path": null
    },
    {
        "title": "MoleculeNet: a benchmark for molecular machine learning",
        "abstract": "A large scale benchmark for molecular machine learning consisting of multiple public datasets, metrics, featurizations and learning algorithms.",
        "link": "https://www.semanticscholar.org/paper/d0ab11de3077490c80a08abd0fb8827bac84c454",
        "published": "2017-03-02",
        "pdf_url": "https://pubs.rsc.org/en/content/articlepdf/2018/sc/c7sc02664a",
        "txt_path": "data/txt/machine learning_paper_146.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning for Electrocatalyst and Photocatalyst Design and Discovery.",
        "abstract": "Electrocatalysts and photocatalysts are key to a sustainable future, generating clean fuels, reducing the impact of global warming, and providing solutions to environmental pollution. Improved processes for catalyst design and a better understanding of electro/photocatalytic processes are essential for improving catalyst effectiveness. Recent advances in data science and artificial intelligence have great potential to accelerate electrocatalysis and photocatalysis research, particularly the rapid exploration of large materials chemistry spaces through machine learning. Here a comprehensive introduction to, and critical review of, machine learning techniques used in electrocatalysis and photocatalysis research are provided. Sources of electro/photocatalyst data and current approaches to representing these materials by mathematical features are described, the most commonly used machine learning methods summarized, and the quality and utility of electro/photocatalyst models evaluated. Illustrations of how machine learning models are applied to novel electro/photocatalyst discovery and used to elucidate electrocatalytic or photocatalytic reaction mechanisms are provided. The review offers a guide for materials scientists on the selection of machine learning methods for electrocatalysis and photocatalysis research. The application of machine learning to catalysis science represents a paradigm shift in the way advanced, next-generation catalysts will be designed and synthesized.",
        "link": "https://www.semanticscholar.org/paper/89e5b63ade995059cf3dfd9580a59b2291e63564",
        "published": "2022-07-21",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_147.txt",
        "pdf_path": null
    },
    {
        "title": "The Shapley Value in Machine Learning",
        "abstract": "Over the last few years, the Shapley value, a solution concept from cooperative game theory, has found numerous applications in machine learning. In this paper, we first discuss fundamental concepts of cooperative game theory and axiomatic properties of the Shapley value. Then we give an overview of the most important applications of the Shapley value in machine learning: feature selection, explainability, multi-agent reinforcement learning, ensemble pruning, and data valuation. We examine the most crucial limitations of the Shapley value and point out directions for future research.",
        "link": "https://www.semanticscholar.org/paper/09c72d9d46f6750e487afdb5f7cae7693ffccc10",
        "published": "2022-02-11",
        "pdf_url": "https://www.ijcai.org/proceedings/2022/0778.pdf",
        "txt_path": "data/txt/machine learning_paper_148.txt",
        "pdf_path": "data/pdfs/machine learning_paper_148.pdf"
    },
    {
        "title": "Interpretable machine learning for knowledge generation in heterogeneous catalysis",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/db5ca8699d5a3a0cbd72e7118072e41c3d6b621e",
        "published": "2022-03-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_149.txt",
        "pdf_path": null
    },
    {
        "title": "Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning",
        "abstract": "Imbalanced-learn is an open-source python toolbox aiming at providing a wide range of methods to cope with the problem of imbalanced dataset frequently encountered in machine learning and pattern recognition. The implemented state-of-the-art methods can be categorized into 4 groups: (i) under-sampling, (ii) over-sampling, (iii) combination of over- and under-sampling, and (iv) ensemble learning methods. The proposed toolbox only depends on numpy, scipy, and scikit-learn and is distributed under MIT license. Furthermore, it is fully compatible with scikit-learn and is part of the scikit-learn-contrib supported project. Documentation, unit tests as well as integration tests are provided to ease usage and contribution. The toolbox is publicly available in GitHub: this https URL.",
        "link": "https://www.semanticscholar.org/paper/05c5b732fb92546c7d6eeabfadb5c14610d07373",
        "published": "2016-09-21",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_150.txt",
        "pdf_path": null
    },
    {
        "title": "Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges",
        "abstract": "Interpretability in machine learning (ML) is crucial for high stakes decisions and troubleshooting. In this work, we provide fundamental principles for interpretable ML, and dispel common misunderstandings that dilute the importance of this crucial topic. We also identify 10 technical challenge areas in interpretable machine learning and provide history and background on each problem. Some of these problems are classically important, and some are recent problems that have arisen in the last few years. These problems are: (1) Optimizing sparse logical models such as decision trees; (2) Optimization of scoring systems; (3) Placing constraints into generalized additive models to encourage sparsity and better interpretability; (4) Modern case-based reasoning, including neural networks and matching for causal inference; (5) Complete supervised disentanglement of neural networks; (6) Complete or even partial unsupervised disentanglement of neural networks; (7) Dimensionality reduction for data visualization; (8) Machine learning models that can incorporate physics and other generative or causal constraints; (9) Characterization of the\"Rashomon set\"of good models; and (10) Interpretable reinforcement learning. This survey is suitable as a starting point for statisticians and computer scientists interested in working in interpretable machine learning.",
        "link": "https://www.semanticscholar.org/paper/256db9dba1978f004a67c86ffc321563b1aee79a",
        "published": "2021-03-20",
        "pdf_url": "https://projecteuclid.org/journals/statistics-surveys/volume-16/issue-none/Interpretable-machine-learning-Fundamental-principles-and-10-grand-challenges/10.1214/21-SS133.pdf",
        "txt_path": "data/txt/machine learning_paper_151.txt",
        "pdf_path": null
    },
    {
        "title": "MRI-Based Brain Tumor Classification Using Ensemble of Deep Features and Machine Learning Classifiers",
        "abstract": "Brain tumor classification plays an important role in clinical diagnosis and effective treatment. In this work, we propose a method for brain tumor classification using an ensemble of deep features and machine learning classifiers. In our proposed framework, we adopt the concept of transfer learning and uses several pre-trained deep convolutional neural networks to extract deep features from brain magnetic resonance (MR) images. The extracted deep features are then evaluated by several machine learning classifiers. The top three deep features which perform well on several machine learning classifiers are selected and concatenated as an ensemble of deep features which is then fed into several machine learning classifiers to predict the final output. To evaluate the different kinds of pre-trained models as a deep feature extractor, machine learning classifiers, and the effectiveness of an ensemble of deep feature for brain tumor classification, we use three different brain magnetic resonance imaging (MRI) datasets that are openly accessible from the web. Experimental results demonstrate that an ensemble of deep features can help improving performance significantly, and in most cases, support vector machine (SVM) with radial basis function (RBF) kernel outperforms other machine learning classifiers, especially for large datasets.",
        "link": "https://www.semanticscholar.org/paper/4d8f0ae904779a50b2e18fec49e51a5661a98d8a",
        "published": "2021-03-01",
        "pdf_url": "https://www.mdpi.com/1424-8220/21/6/2222/pdf?version=1616574103",
        "txt_path": "data/txt/machine learning_paper_152.txt",
        "pdf_path": null
    },
    {
        "title": "Swarm Learning for decentralized and confidential clinical machine learning",
        "abstract": "Fast and reliable detection of patients with severe and heterogeneous illnesses is a major goal of precision medicine1,2. Patients with leukaemia can be identified using machine learning on the basis of their blood transcriptomes3. However, there is an increasing divide between what is technically possible and what is allowed, because of privacy legislation4,5. Here, to facilitate the integration of any medical data from any data owner worldwide without violating privacy laws, we introduce Swarm Learning—a decentralized machine-learning approach that unites edge computing, blockchain-based peer-to-peer networking and coordination while maintaining confidentiality without the need for a central coordinator, thereby going beyond federated learning. To illustrate the feasibility of using Swarm Learning to develop disease classifiers using distributed data, we chose four use cases of heterogeneous diseases (COVID-19, tuberculosis, leukaemia and lung pathologies). With more than 16,400 blood transcriptomes derived from 127 clinical studies with non-uniform distributions of cases and controls and substantial study biases, as well as more than 95,000 chest X-ray images, we show that Swarm Learning classifiers outperform those developed at individual sites. In addition, Swarm Learning completely fulfils local confidentiality regulations by design. We believe that this approach will notably accelerate the introduction of precision medicine. Swarm Learning is a decentralized machine learning approach that outperforms classifiers developed at individual sites for COVID-19 and other diseases while preserving confidentiality and privacy.",
        "link": "https://www.semanticscholar.org/paper/24d21ecaeb2d2ecc20e26a5e3f5128247704ccfe",
        "published": "2021-05-26",
        "pdf_url": "https://www.nature.com/articles/s41586-021-03583-3.pdf",
        "txt_path": "data/txt/machine learning_paper_153.txt",
        "pdf_path": "data/pdfs/machine learning_paper_153.pdf"
    },
    {
        "title": "Predicting the Future - Big Data, Machine Learning, and Clinical Medicine.",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/4d1fdd81f033cd58f3723bfc61e7d12079647a7a",
        "published": "2016-09-28",
        "pdf_url": "https://europepmc.org/articles/pmc5070532?pdf=render",
        "txt_path": "data/txt/machine learning_paper_154.txt",
        "pdf_path": "data/pdfs/machine learning_paper_154.pdf"
    },
    {
        "title": "Empirical Asset Pricing Via Machine Learning",
        "abstract": "\n We perform a comparative analysis of machine learning methods for the canonical problem of empirical asset pricing: measuring asset risk premiums. We demonstrate large economic gains to investors using machine learning forecasts, in some cases doubling the performance of leading regression-based strategies from the literature. We identify the best-performing methods (trees and neural networks) and trace their predictive gains to allowing nonlinear predictor interactions missed by other methods. All methods agree on the same set of dominant predictive signals, a set that includes variations on momentum, liquidity, and volatility.\n Authors have furnished an Internet Appendix, which is available on the Oxford University Press Web site next to the link to the final published paper online.",
        "link": "https://www.semanticscholar.org/paper/caf9e0fa2c340fb07cef8d547ea8849508e5c358",
        "published": "2018-12-01",
        "pdf_url": "http://www.nber.org/papers/w25398.pdf",
        "txt_path": "data/txt/machine learning_paper_155.txt",
        "pdf_path": "data/pdfs/machine learning_paper_155.pdf"
    },
    {
        "title": "Reconciling modern machine-learning practice and the classical bias–variance trade-off",
        "abstract": "Significance While breakthroughs in machine learning and artificial intelligence are changing society, our fundamental understanding has lagged behind. It is traditionally believed that fitting models to the training data exactly is to be avoided as it leads to poor performance on unseen data. However, powerful modern classifiers frequently have near-perfect fit in training, a disconnect that spurred recent intensive research and controversy on whether theory provides practical insights. In this work, we show how classical theory and modern practice can be reconciled within a single unified performance curve and propose a mechanism underlying its emergence. We believe this previously unknown pattern connecting the structure and performance of learning architectures will help shape design and understanding of learning algorithms. Breakthroughs in machine learning are rapidly changing science and society, yet our fundamental understanding of this technology has lagged far behind. Indeed, one of the central tenets of the field, the bias–variance trade-off, appears to be at odds with the observed behavior of methods used in modern machine-learning practice. The bias–variance trade-off implies that a model should balance underfitting and overfitting: Rich enough to express underlying structure in data and simple enough to avoid fitting spurious patterns. However, in modern practice, very rich models such as neural networks are trained to exactly fit (i.e., interpolate) the data. Classically, such models would be considered overfitted, and yet they often obtain high accuracy on test data. This apparent contradiction has raised questions about the mathematical foundations of machine learning and their relevance to practitioners. In this paper, we reconcile the classical understanding and the modern practice within a unified performance curve. This “double-descent” curve subsumes the textbook U-shaped bias–variance trade-off curve by showing how increasing model capacity beyond the point of interpolation results in improved performance. We provide evidence for the existence and ubiquity of double descent for a wide spectrum of models and datasets, and we posit a mechanism for its emergence. This connection between the performance and the structure of machine-learning models delineates the limits of classical analyses and has implications for both the theory and the practice of machine learning.",
        "link": "https://www.semanticscholar.org/paper/f86f1748d1b6d22870f4347fd5d65314ba800583",
        "published": "2018-12-28",
        "pdf_url": "https://www.pnas.org/content/pnas/116/32/15849.full.pdf",
        "txt_path": "data/txt/machine learning_paper_156.txt",
        "pdf_path": null
    },
    {
        "title": "Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods",
        "abstract": "The notion of uncertainty is of major importance in machine learning and constitutes a key element of machine learning methodology. In line with the statistical tradition, uncertainty has long been perceived as almost synonymous with standard probability and probabilistic predictions. Yet, due to the steadily increasing relevance of machine learning for practical applications and related issues such as safety requirements, new problems and challenges have recently been identified by machine learning scholars, and these problems may call for new methodological developments. In particular, this includes the importance of distinguishing between (at least) two different types of uncertainty, often referred to as aleatoric and epistemic. In this paper, we provide an introduction to the topic of uncertainty in machine learning as well as an overview of attempts so far at handling uncertainty in general and formalizing this distinction in particular.",
        "link": "https://www.semanticscholar.org/paper/b631ba962b4403a9c0fd9cce446ef3b1e21ea059",
        "published": "2019-10-21",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10994-021-05946-3.pdf",
        "txt_path": "data/txt/machine learning_paper_157.txt",
        "pdf_path": "data/pdfs/machine learning_paper_157.pdf"
    },
    {
        "title": "Power of data in quantum machine learning",
        "abstract": "The use of quantum computing for machine learning is among the most exciting prospective applications of quantum technologies. However, machine learning tasks where data is provided can be considerably different than commonly studied computational tasks. In this work, we show that some problems that are classically hard to compute can be easily predicted by classical machines learning from data. Using rigorous prediction error bounds as a foundation, we develop a methodology for assessing potential quantum advantage in learning tasks. The bounds are tight asymptotically and empirically predictive for a wide range of learning models. These constructions explain numerical results showing that with the help of data, classical machine learning models can be competitive with quantum models even if they are tailored to quantum problems. We then propose a projected quantum model that provides a simple and rigorous quantum speed-up for a learning problem in the fault-tolerant regime. For near-term implementations, we demonstrate a significant prediction advantage over some classical models on engineered data sets designed to demonstrate a maximal quantum advantage in one of the largest numerical tests for gate-based quantum machine learning to date, up to 30 qubits. Expectations for quantum machine learning are high, but there is currently a lack of rigorous results on which scenarios would actually exhibit a quantum advantage. Here, the authors show how to tell, for a given dataset, whether a quantum model would give any prediction advantage over a classical one.",
        "link": "https://www.semanticscholar.org/paper/57e6cca1479a4642f867e69b4dee93d14259dc3d",
        "published": "2020-11-03",
        "pdf_url": "https://www.nature.com/articles/s41467-021-22539-9.pdf",
        "txt_path": "data/txt/machine learning_paper_158.txt",
        "pdf_path": "data/pdfs/machine learning_paper_158.pdf"
    },
    {
        "title": "FedML: A Research Library and Benchmark for Federated Machine Learning",
        "abstract": "Federated learning is a rapidly growing research field in the machine learning domain. Although considerable research efforts have been made, existing libraries cannot adequately support diverse algorithmic development (e.g., diverse topology and flexible message exchange), and inconsistent dataset and model usage in experiments make fair comparisons difficult. In this work, we introduce FedML, an open research library and benchmark that facilitates the development of new federated learning algorithms and fair performance comparisons. FedML supports three computing paradigms (distributed training, mobile on-device training, and standalone simulation) for users to conduct experiments in different system environments. FedML also promotes diverse algorithmic research with flexible and generic API design and reference baseline implementations. A curated and comprehensive benchmark dataset for the non-I.I.D setting aims at making a fair comparison. We believe FedML can provide an efficient and reproducible means of developing and evaluating algorithms for the federated learning research community. We maintain the source code, documents, and user community at this https URL.",
        "link": "https://www.semanticscholar.org/paper/c5c4142a01981787a71bf6ebcb791520c458ab5d",
        "published": "2020-07-27",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_159.txt",
        "pdf_path": null
    },
    {
        "title": "Universal Differential Equations for Scientific Machine Learning",
        "abstract": "\n In the context of science, the well-known adage “a picture is worth a thousand words” might well be “a model is worth a thousand datasets.” Scientific models, such as Newtonian physics or biological gene regulatory networks, are human-driven simplifications of complex phenomena that serve as surrogates for the countless experiments that validated the models. Recently, machine learning has been able to overcome the inaccuracies of approximate modeling by directly learning the entire set of nonlinear interactions from data. However, without any predetermined structure from the scientific basis behind the problem, machine learning approaches are flexible but data-expensive, requiring large databases of homogeneous labeled training data. A central challenge is reconciling data that is at odds with simplified models without requiring \"big data\". In this work demonstrate how a mathematical object, which we denote universal differential equations (UDEs), can be utilized as a theoretical underpinning to a diverse array of problems in scientific machine learning to yield efficient algorithms and generalized approaches. The UDE model augments scientific models with machine-learnable structures for scientifically-based learning. We show how UDEs can be utilized to discover previously unknown governing equations, accurately extrapolate beyond the original data, and accelerate model simulation, all in a time and data-efficient manner. This advance is coupled with open-source software that allows for training UDEs which incorporate physical constraints, delayed interactions, implicitly-defined events, and intrinsic stochasticity in the model. Our examples show how a diverse set of computationally-difficult modeling issues across scientific disciplines, from automatically discovering biological mechanisms to accelerating the training of physics-informed neural networks and large-eddy simulations, can all be transformed into UDE training problems that are efficiently solved by a single software methodology.",
        "link": "https://www.semanticscholar.org/paper/696b388ee6221c6dbcfd647a06883b2bfee773d9",
        "published": "2020-01-13",
        "pdf_url": "https://www.researchsquare.com/article/rs-55125/v1.pdf?c=1631854486000",
        "txt_path": "data/txt/machine learning_paper_160.txt",
        "pdf_path": "data/pdfs/machine learning_paper_160.pdf"
    },
    {
        "title": "Fairness in Machine Learning: A Survey",
        "abstract": "When Machine Learning technologies are used in contexts that affect citizens, companies as well as researchers need to be confident that there will not be any unexpected social implications, such as bias towards gender, ethnicity, and/or people with disabilities. There is significant literature on approaches to mitigate bias and promote fairness, yet the area is complex and hard to penetrate for newcomers to the domain. This article seeks to provide an overview of the different schools of thought and approaches that aim to increase the fairness of Machine Learning. It organizes approaches into the widely accepted framework of pre-processing, in-processing, and post-processing methods, subcategorizing into a further 11 method areas. Although much of the literature emphasizes binary classification, a discussion of fairness in regression, recommender systems, and unsupervised learning is also provided along with a selection of currently available open source libraries. The article concludes by summarizing open challenges articulated as five dilemmas for fairness research.",
        "link": "https://www.semanticscholar.org/paper/fee8f63972906214b77f16cfeca0b93ee8f36ba2",
        "published": "2020-10-04",
        "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3616865",
        "txt_path": "data/txt/machine learning_paper_161.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Interpretability: A Survey on Methods and Metrics",
        "abstract": "Machine learning systems are becoming increasingly ubiquitous. These systems’s adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate decision support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their predictions. Moreover, new regulations and highly regulated domains have made the audit and verifiability of decisions mandatory, increasing the demand for the ability to question, understand, and trust machine learning systems, for which interpretability is indispensable. The research community has recognized this interpretability problem and focused on developing both interpretable models and explanation methods over the past few years. However, the emergence of these methods shows there is no consensus on how to assess the explanation quality. Which are the most suitable metrics to assess the quality of an explanation? The aim of this article is to provide a review of the current state of the research field on machine learning interpretability while focusing on the societal impact and on the developed methods and metrics. Furthermore, a complete literature review is presented in order to identify future directions of work on this field.",
        "link": "https://www.semanticscholar.org/paper/46c266b3d1274dacd7fce27ee8cb4d587f087a58",
        "published": "2019-07-26",
        "pdf_url": "https://www.mdpi.com/2079-9292/8/8/832/pdf?version=1564134847",
        "txt_path": "data/txt/machine learning_paper_162.txt",
        "pdf_path": null
    },
    {
        "title": "Adversarial machine learning",
        "abstract": "In this paper (expanded from an invited talk at AISEC 2010), we discuss an emerging field of study: adversarial machine learning---the study of effective machine learning techniques against an adversarial opponent. In this paper, we: give a taxonomy for classifying attacks against online machine learning algorithms; discuss application-specific factors that limit an adversary's capabilities; introduce two models for modeling an adversary's capabilities; explore the limits of an adversary's knowledge about the algorithm, feature space, training, and input data; explore vulnerabilities in machine learning algorithms; discuss countermeasures against attacks; introduce the evasion challenge; and discuss privacy-preserving learning techniques.",
        "link": "https://www.semanticscholar.org/paper/e24b8a9531573d284647239affc6c855505b0de4",
        "published": "2019-02-01",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/74B5A8002ED9DDF469BF51E789FB0EB5/9781107338548c2_p20-28_CBO.pdf/background_and_notation.pdf",
        "txt_path": "data/txt/machine learning_paper_163.txt",
        "pdf_path": null
    },
    {
        "title": "Stable learning establishes some common ground between causal inference and machine learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/a8d76d84408c1fe6b1543084e6cec3dfc4ede429",
        "published": "2022-02-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_164.txt",
        "pdf_path": null
    },
    {
        "title": "Heart Disease Prediction using Machine Learning Techniques",
        "abstract": "Heart disease, alternatively known as cardiovascular disease, encases various conditions that impact the heart and is the primary basis of death worldwide over the span of the past few decades. It associates many risk factors in heart disease and a need of the time to get accurate, reliable, and sensible approaches to make an early diagnosis to achieve prompt management of the disease. Data mining is a commonly used technique for processing enormous data in the healthcare domain. Researchers apply several data mining and machine learning techniques to analyse huge complex medical data, helping healthcare professionals to predict heart disease. This research paper presents various attributes related to heart disease, and the model on basis of supervised learning algorithms as Naïve Bayes, decision tree, K-nearest neighbor, and random forest algorithm. It uses the existing dataset from the Cleveland database of UCI repository of heart disease patients. The dataset comprises 303 instances and 76 attributes. Of these 76 attributes, only 14 attributes are considered for testing, important to substantiate the performance of different algorithms. This research paper aims to envision the probability of developing heart disease in the patients. The results portray that the highest accuracy score is achieved with K-nearest neighbor.",
        "link": "https://www.semanticscholar.org/paper/e6b733b960cc1800487203af61de1c58b6299d5a",
        "published": "2020-03-10",
        "pdf_url": "https://doi.org/10.35940/ijitee.e2862.039520",
        "txt_path": "data/txt/machine learning_paper_165.txt",
        "pdf_path": null
    },
    {
        "title": "Counterfactual Explanations for Machine Learning: A Review",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/6068d39e92aef1bb0e1291e9931894c35692a85e",
        "published": "2020-10-20",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_166.txt",
        "pdf_path": null
    },
    {
        "title": "MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems",
        "abstract": "MXNet is a multi-language machine learning (ML) library to ease the development of ML algorithms, especially for deep neural networks. Embedded in the host language, it blends declarative symbolic expression with imperative tensor computation. It offers auto differentiation to derive gradients. MXNet is computation and memory efficient and runs on various heterogeneous systems, ranging from mobile devices to distributed GPU clusters. \nThis paper describes both the API design and the system implementation of MXNet, and explains how embedding of both symbolic expression and tensor operation is handled in a unified fashion. Our preliminary experiments reveal promising results on large scale deep neural network applications using multiple GPU machines.",
        "link": "https://www.semanticscholar.org/paper/62df84d6a4d26f95e4714796c2337c9848cc13b5",
        "published": "2015-12-03",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_167.txt",
        "pdf_path": null
    },
    {
        "title": "Hyperparameter Optimization for Machine Learning Models Based on Bayesian Optimization",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/ec6200bdcc23b79a71555962cde50306c4029f1a",
        "published": "2019-03-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_168.txt",
        "pdf_path": null
    },
    {
        "title": "Definitions, methods, and applications in interpretable machine learning",
        "abstract": "Significance The recent surge in interpretability research has led to confusion on numerous fronts. In particular, it is unclear what it means to be interpretable and how to select, evaluate, or even discuss methods for producing interpretations of machine-learning models. We aim to clarify these concerns by defining interpretable machine learning and constructing a unifying framework for existing methods which highlights the underappreciated role played by human audiences. Within this framework, methods are organized into 2 classes: model based and post hoc. To provide guidance in selecting and evaluating interpretation methods, we introduce 3 desiderata: predictive accuracy, descriptive accuracy, and relevancy. Using our framework, we review existing work, grounded in real-world studies which exemplify our desiderata, and suggest directions for future work. Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods.",
        "link": "https://www.semanticscholar.org/paper/b9518627db25f05930e931f56497602363a75491",
        "published": "2019-01-14",
        "pdf_url": "https://www.pnas.org/content/pnas/116/44/22071.full.pdf",
        "txt_path": "data/txt/machine learning_paper_169.txt",
        "pdf_path": null
    },
    {
        "title": "Gaussian Processes in Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/7649af7bf6e9d277ed045930fc08d79247e02375",
        "published": "2003-02-02",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_170.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning and the physical sciences",
        "abstract": "Machine learning (ML) encompasses a broad range of algorithms and modeling tools used for a vast array of data processing tasks, which has entered most scientific disciplines in recent years. This article reviews in a selective way the recent research on the interface between machine learning and the physical sciences. This includes conceptual developments in ML motivated by physical insights, applications of machine learning techniques to several domains in physics, and cross fertilization between the two fields. After giving a basic notion of machine learning methods and principles, examples are described of how statistical physics is used to understand methods in ML. This review then describes applications of ML methods in particle physics and cosmology, quantum many-body physics, quantum computing, and chemical and material physics. Research and development into novel computing architectures aimed at accelerating ML are also highlighted. Each of the sections describe recent successes as well as domain-specific methodology and challenges.",
        "link": "https://www.semanticscholar.org/paper/a9cbbef8f4426329d0687025b34287c35bdd8b38",
        "published": "2019-03-25",
        "pdf_url": "https://arxiv.org/pdf/1903.10563",
        "txt_path": "data/txt/machine learning_paper_171.txt",
        "pdf_path": "data/pdfs/machine learning_paper_171.pdf"
    },
    {
        "title": "Applications of machine learning in drug discovery and development",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/b5904cd5dbf73b8d5ff13517de490c292d877ee0",
        "published": "2019-04-11",
        "pdf_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6552674",
        "txt_path": "data/txt/machine learning_paper_172.txt",
        "pdf_path": null
    },
    {
        "title": "Quantum machine learning",
        "abstract": "Fuelled by increasing computer power and algorithmic advances, machine learning techniques have become powerful tools for finding patterns in data. Quantum systems produce atypical patterns that classical systems are thought not to produce efficiently, so it is reasonable to postulate that quantum computers may outperform classical computers on machine learning tasks. The field of quantum machine learning explores how to devise and implement quantum software that could enable machine learning that is faster than that of classical computers. Recent work has produced quantum algorithms that could act as the building blocks of machine learning programs, but the hardware and software challenges are still considerable.",
        "link": "https://www.semanticscholar.org/paper/15eded04386a8982ccd5627bd1efe70bbf624c02",
        "published": "2016-11-28",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_173.txt",
        "pdf_path": null
    },
    {
        "title": "Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning",
        "abstract": "Accurate reporting of energy and carbon usage is essential for understanding the potential climate impacts of machine learning research. We introduce a framework that makes this easier by providing a simple interface for tracking realtime energy consumption and carbon emissions, as well as generating standardized online appendices. Utilizing this framework, we create a leaderboard for energy efficient reinforcement learning algorithms to incentivize responsible research in this area as an example for other areas of machine learning. Finally, based on case studies using our framework, we propose strategies for mitigation of carbon emissions and reduction of energy consumption. By making accounting easier, we hope to further the sustainable development of machine learning experiments and spur more research into energy efficient algorithms.",
        "link": "https://www.semanticscholar.org/paper/74b4f16c5ac91e3e7c88ae81cc8c91416b71d151",
        "published": "2020-01-31",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_174.txt",
        "pdf_path": null
    },
    {
        "title": "Recent advances and applications of machine learning in solid-state materials science",
        "abstract": "One of the most exciting tools that have entered the material science toolbox in recent years is machine learning. This collection of statistical methods has already proved to be capable of considerably speeding up both fundamental and applied research. At present, we are witnessing an explosion of works that develop and apply machine learning to solid-state systems. We provide a comprehensive overview and analysis of the most recent research in this topic. As a starting point, we introduce machine learning principles, algorithms, descriptors, and databases in materials science. We continue with the description of different machine learning approaches for the discovery of stable materials and the prediction of their crystal structure. Then we discuss research in numerous quantitative structure–property relationships and various approaches for the replacement of first-principle methods by machine learning. We review how active learning and surrogate-based optimization can be applied to improve the rational design process and related examples of applications. Two major questions are always the interpretability of and the physical understanding gained from machine learning models. We consider therefore the different facets of interpretability and their importance in materials science. Finally, we propose solutions and future research paths for various challenges in computational materials science.",
        "link": "https://www.semanticscholar.org/paper/0273507eb05f1135f3a05f9c7adc9a56f12c7c5c",
        "published": "2019-08-08",
        "pdf_url": "https://www.nature.com/articles/s41524-019-0221-0.pdf",
        "txt_path": "data/txt/machine learning_paper_175.txt",
        "pdf_path": "data/pdfs/machine learning_paper_175.pdf"
    },
    {
        "title": "A survey on missing data in machine learning",
        "abstract": "Machine learning has been the corner stone in analysing and extracting information from data and often a problem of missing values is encountered. Missing values occur because of various factors like missing completely at random, missing at random or missing not at random. All these may result from system malfunction during data collection or human error during data pre-processing. Nevertheless, it is important to deal with missing values before analysing data since ignoring or omitting missing values may result in biased or misinformed analysis. In literature there have been several proposals for handling missing values. In this paper, we aggregate some of the literature on missing data particularly focusing on machine learning techniques. We also give insight on how the machine learning approaches work by highlighting the key features of missing values imputation techniques, how they perform, their limitations and the kind of data they are most suitable for. We propose and evaluate two methods, the k nearest neighbor and an iterative imputation method (missForest) based on the random forest algorithm. Evaluation is performed on the Iris and novel power plant fan data with induced missing values at missingness rate of 5% to 20%. We show that both missForest and the k nearest neighbor can successfully handle missing values and offer some possible future research direction.",
        "link": "https://www.semanticscholar.org/paper/e2e8ea9bcdb83deb2787ce89db1b51f7ccb1bd1e",
        "published": "2021-06-17",
        "pdf_url": "https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-021-00516-9",
        "txt_path": "data/txt/machine learning_paper_176.txt",
        "pdf_path": "data/pdfs/machine learning_paper_176.pdf"
    },
    {
        "title": "Perspectives in machine learning for wildlife conservation",
        "abstract": "Inexpensive and accessible sensors are accelerating data acquisition in animal ecology. These technologies hold great potential for large-scale ecological understanding, but are limited by current processing approaches which inefficiently distill data into relevant information. We argue that animal ecologists can capitalize on large datasets generated by modern sensors by combining machine learning approaches with domain knowledge. Incorporating machine learning into ecological workflows could improve inputs for ecological models and lead to integrated hybrid modeling tools. This approach will require close interdisciplinary collaboration to ensure the quality of novel approaches and train a new generation of data scientists in ecology and conservation. Animal ecologists are increasingly limited by constraints in data processing. Here, Tuia and colleagues discuss how collaboration between ecologists and data scientists can harness machine learning to capitalize on the data generated from technological advances and lead to novel modeling approaches.",
        "link": "https://www.semanticscholar.org/paper/d9b34c6b616f75485856794478bfbeab1ea93b81",
        "published": "2021-10-25",
        "pdf_url": "https://www.nature.com/articles/s41467-022-27980-y.pdf",
        "txt_path": "data/txt/machine learning_paper_177.txt",
        "pdf_path": "data/pdfs/machine learning_paper_177.pdf"
    },
    {
        "title": "Prediction of Heart Disease Using a Combination of Machine Learning and Deep Learning",
        "abstract": "The correct prediction of heart disease can prevent life threats, and incorrect prediction can prove to be fatal at the same time. In this paper different machine learning algorithms and deep learning are applied to compare the results and analysis of the UCI Machine Learning Heart Disease dataset. The dataset consists of 14 main attributes used for performing the analysis. Various promising results are achieved and are validated using accuracy and confusion matrix. The dataset consists of some irrelevant features which are handled using Isolation Forest, and data are also normalized for getting better results. And how this study can be combined with some multimedia technology like mobile devices is also discussed. Using deep learning approach, 94.2% accuracy was obtained.",
        "link": "https://www.semanticscholar.org/paper/31cf4c96c5dd4ac5a6bbb4ac7b6bab763651624a",
        "published": "2021-07-01",
        "pdf_url": "https://downloads.hindawi.com/journals/cin/2021/8387680.pdf",
        "txt_path": "data/txt/machine learning_paper_178.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in Agriculture: A Comprehensive Updated Review",
        "abstract": "The digital transformation of agriculture has evolved various aspects of management into artificial intelligent systems for the sake of making value from the ever-increasing data originated from numerous sources. A subset of artificial intelligence, namely machine learning, has a considerable potential to handle numerous challenges in the establishment of knowledge-based farming systems. The present study aims at shedding light on machine learning in agriculture by thoroughly reviewing the recent scholarly literature based on keywords’ combinations of “machine learning” along with “crop management”, “water management”, “soil management”, and “livestock management”, and in accordance with PRISMA guidelines. Only journal papers were considered eligible that were published within 2018–2020. The results indicated that this topic pertains to different disciplines that favour convergence research at the international level. Furthermore, crop management was observed to be at the centre of attention. A plethora of machine learning algorithms were used, with those belonging to Artificial Neural Networks being more efficient. In addition, maize and wheat as well as cattle and sheep were the most investigated crops and animals, respectively. Finally, a variety of sensors, attached on satellites and unmanned ground and aerial vehicles, have been utilized as a means of getting reliable input data for the data analyses. It is anticipated that this study will constitute a beneficial guide to all stakeholders towards enhancing awareness of the potential advantages of using machine learning in agriculture and contributing to a more systematic research on this topic.",
        "link": "https://www.semanticscholar.org/paper/b415e836d447ea9efb7629a1de67cd2a6f9e7ba8",
        "published": "2021-05-28",
        "pdf_url": "https://www.mdpi.com/1424-8220/21/11/3758/pdf?version=1622446805",
        "txt_path": "data/txt/machine learning_paper_179.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Basics",
        "abstract": "coined in 1959 by Arthur Samuel [Samuel 1959], Tom Mitchell [Mitchell 1997] provided a more formal definition: “A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.” ML has be applied to many real-world problems or tasks, like medical diagno­ sis, robotics, recommendation systems, facial recognition, stock prices prediction, and sentiment analysis, with great success. We can divide ML algorithms into three main categories (see Figure 4.1): Machine Learning Basics",
        "link": "https://www.semanticscholar.org/paper/287ba5bf00d96af1596aaf80c178392a9c4fcc28",
        "published": "2021-02-23",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_180.txt",
        "pdf_path": null
    },
    {
        "title": "All-optical machine learning using diffractive deep neural networks",
        "abstract": "All-optical deep learning Deep learning uses multilayered artificial neural networks to learn digitally from large datasets. It then performs advanced identification and classification tasks. To date, these multilayered neural networks have been implemented on a computer. Lin et al. demonstrate all-optical machine learning that uses passive optical components that can be patterned and fabricated with 3D-printing. Their hardware approach comprises stacked layers of diffractive optical elements analogous to an artificial neural network that can be trained to execute complex functions at the speed of light. Science, this issue p. 1004 All-optical deep learning can be implemented with 3D-printed passive optical components. Deep learning has been transforming our ability to execute advanced inference tasks using computers. Here we introduce a physical mechanism to perform machine learning by demonstrating an all-optical diffractive deep neural network (D2NN) architecture that can implement various functions following the deep learning–based design of passive diffractive layers that work collectively. We created 3D-printed D2NNs that implement classification of images of handwritten digits and fashion products, as well as the function of an imaging lens at a terahertz spectrum. Our all-optical deep learning framework can perform, at the speed of light, various complex functions that computer-based neural networks can execute; will find applications in all-optical image analysis, feature detection, and object classification; and will also enable new camera designs and optical components that perform distinctive tasks using D2NNs.",
        "link": "https://www.semanticscholar.org/paper/5c7e5248d9eb7f373f10277410bf8506160907ea",
        "published": "2018-04-14",
        "pdf_url": "http://arxiv.org/pdf/1804.08711",
        "txt_path": "data/txt/machine learning_paper_181.txt",
        "pdf_path": "data/pdfs/machine learning_paper_181.pdf"
    },
    {
        "title": "Dlib-ml: A Machine Learning Toolkit",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/2ea6a93199c9227fa0c1c7de13725f918c9be3a4",
        "published": "2009-12-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_182.txt",
        "pdf_path": null
    },
    {
        "title": "A Survey on the Explainability of Supervised Machine Learning",
        "abstract": "Predictions obtained by, e.g., artificial neural networks have a high accuracy but humans often perceive the models as black boxes. Insights about the decision making are mostly opaque for humans. Particularly understanding the decision making in highly sensitive areas such as healthcare or finance, is of paramount importance. The decision-making behind the black boxes requires it to be more transparent, accountable, and understandable for humans. This survey paper provides essential definitions, an overview of the different principles and methodologies of explainable Supervised Machine Learning (SML). We conduct a state-of-the-art survey that reviews past and recent explainable SML approaches and classifies them according to the introduced definitions. Finally, we illustrate principles by means of an explanatory case study and discuss important future directions.",
        "link": "https://www.semanticscholar.org/paper/5fca8bbec714e403fa0f95a56b355c8ca835bcc0",
        "published": "2020-11-16",
        "pdf_url": "https://jair.org/index.php/jair/article/download/12228/26647",
        "txt_path": "data/txt/machine learning_paper_183.txt",
        "pdf_path": null
    },
    {
        "title": "Enhancing computational fluid dynamics with machine learning",
        "abstract": "Machine learning is rapidly becoming a core technology for scientific computing, with numerous opportunities to advance the field of computational fluid dynamics. Here we highlight some of the areas of highest potential impact, including to accelerate direct numerical simulations, to improve turbulence closure modeling and to develop enhanced reduced-order models. We also discuss emerging areas of machine learning that are promising for computational fluid dynamics, as well as some potential limitations that should be taken into account. Machine learning has been used to accelerate the simulation of fluid dynamics. However, despite the recent developments in this field, there are still challenges to be addressed by the community, a fact that creates research opportunities.",
        "link": "https://www.semanticscholar.org/paper/f8ec29fb9933219e0949c59ddd7220fd1e2a1b89",
        "published": "2021-10-05",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_184.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in Drug Discovery: A Review",
        "abstract": "This review provides the feasible literature on drug discovery through ML tools and techniques that are enforced in every phase of drug development to accelerate the research process and deduce the risk and expenditure in clinical trials. Machine learning techniques improve the decision-making in pharmaceutical data across various applications like QSAR analysis, hit discoveries, de novo drug architectures to retrieve accurate outcomes. Target validation, prognostic biomarkers, digital pathology are considered under problem statements in this review. ML challenges must be applicable for the main cause of inadequacy in interpretability outcomes that may restrict the applications in drug discovery. In clinical trials, absolute and methodological data must be generated to tackle many puzzles in validating ML techniques, improving decision-making, promoting awareness in ML approaches, and deducing risk failures in drug discovery.",
        "link": "https://www.semanticscholar.org/paper/3a191f45f6c0e8ecc598dc349022b253a652b7f2",
        "published": "2021-08-11",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10462-021-10058-4.pdf",
        "txt_path": "data/txt/machine learning_paper_185.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning pipeline for battery state-of-health estimation",
        "abstract": "Lithium-ion batteries are ubiquitous in applications ranging from portable electronics to electric vehicles. Irrespective of the application, reliable real-time estimation of battery state of health (SOH) by on-board computers is crucial to the safe operation of the battery, ultimately safeguarding asset integrity. In this Article, we design and evaluate a machine learning pipeline for estimation of battery capacity fade—a metric of battery health—on 179 cells cycled under various conditions. The pipeline estimates battery SOH with an associated confidence interval by using two parametric and two non-parametric algorithms. Using segments of charge voltage and current curves, the pipeline engineers 30 features, performs automatic feature selection and calibrates the algorithms. When deployed on cells operated under the fast-charging protocol, the best model achieves a root-mean-squared error of 0.45%. This work provides insights into the design of scalable data-driven models for battery SOH estimation, emphasizing the value of confidence bounds around the prediction. The pipeline methodology combines experimental data with machine learning modelling and could be applied to other critical components that require real-time estimation of SOH. Rechargeable lithium-ion batteries play a crucial role in many modern-day applications, including portable electronics and electric vehicles, but they degrade over time. To ensure safe operation, a battery’s ‘state of health’ should be monitored in real time, and this machine learning pipeline, tested on a variety of charging conditions, can provide such an online estimation of battery state of health.",
        "link": "https://www.semanticscholar.org/paper/f1664bbaddedea8c250873e7610ab07e53fa7132",
        "published": "2021-02-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_186.txt",
        "pdf_path": null
    },
    {
        "title": "Automated Machine Learning - Methods, Systems, Challenges",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/b55e490637babd50dab3cdaaa3a60a2be6eb1cbb",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_187.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in Agriculture: A Review",
        "abstract": "Machine learning has emerged with big data technologies and high-performance computing to create new opportunities for data intensive science in the multi-disciplinary agri-technologies domain. In this paper, we present a comprehensive review of research dedicated to applications of machine learning in agricultural production systems. The works analyzed were categorized in (a) crop management, including applications on yield prediction, disease detection, weed detection crop quality, and species recognition; (b) livestock management, including applications on animal welfare and livestock production; (c) water management; and (d) soil management. The filtering and classification of the presented articles demonstrate how agriculture will benefit from machine learning technologies. By applying machine learning to sensor data, farm management systems are evolving into real time artificial intelligence enabled programs that provide rich recommendations and insights for farmer decision support and action.",
        "link": "https://www.semanticscholar.org/paper/6e23398447a022fb9495c44fa80e9de593a574bc",
        "published": "2018-08-01",
        "pdf_url": "https://www.mdpi.com/1424-8220/18/8/2674/pdf?version=1534247979",
        "txt_path": "data/txt/machine learning_paper_188.txt",
        "pdf_path": null
    },
    {
        "title": "Combining Machine Learning and Computational Chemistry for Predictive Insights Into Chemical Systems",
        "abstract": "Machine learning models are poised to make a transformative impact on chemical sciences by dramatically accelerating computational algorithms and amplifying insights available from computational chemistry methods. However, achieving this requires a confluence and coaction of expertise in computer science and physical sciences. This Review is written for new and experienced researchers working at the intersection of both fields. We first provide concise tutorials of computational chemistry and machine learning methods, showing how insights involving both can be achieved. We follow with a critical review of noteworthy applications that demonstrate how computational chemistry and machine learning can be used together to provide insightful (and useful) predictions in molecular and materials modeling, retrosyntheses, catalysis, and drug design.",
        "link": "https://www.semanticscholar.org/paper/a453ce8a3de86a170c79a1082ef358c3adf4e612",
        "published": "2021-02-12",
        "pdf_url": "https://doi.org/10.1021/acs.chemrev.1c00107",
        "txt_path": "data/txt/machine learning_paper_189.txt",
        "pdf_path": null
    },
    {
        "title": "Common pitfalls and recommendations for using machine learning to detect and prognosticate for COVID-19 using chest radiographs and CT scans",
        "abstract": "Machine learning methods offer great promise for fast and accurate detection and prognostication of coronavirus disease 2019 (COVID-19) from standard-of-care chest radiographs (CXR) and chest computed tomography (CT) images. Many articles have been published in 2020 describing new machine learning-based models for both of these tasks, but it is unclear which are of potential clinical utility. In this systematic review, we consider all published papers and preprints, for the period from 1 January 2020 to 3 October 2020, which describe new machine learning models for the diagnosis or prognosis of COVID-19 from CXR or CT images. All manuscripts uploaded to bioRxiv, medRxiv and arXiv along with all entries in EMBASE and MEDLINE in this timeframe are considered. Our search identified 2,212 studies, of which 415 were included after initial screening and, after quality screening, 62 studies were included in this systematic review. Our review finds that none of the models identified are of potential clinical use due to methodological flaws and/or underlying biases. This is a major weakness, given the urgency with which validated COVID-19 models are needed. To address this, we give many recommendations which, if followed, will solve these issues and lead to higher-quality model development and well-documented manuscripts. Many machine learning-based approaches have been developed for the prognosis and diagnosis of COVID-19 from medical images and this Analysis identifies over 2,200 relevant published papers and preprints in this area. After initial screening, 62 studies are analysed and the authors find they all have methodological flaws standing in the way of clinical utility. The authors have several recommendations to address these issues.",
        "link": "https://www.semanticscholar.org/paper/69d49a06f09cf934310ccbf3bb2a360fa719272d",
        "published": "2020-08-14",
        "pdf_url": "https://doi.org/10.1038/s42256-021-00307-0",
        "txt_path": "data/txt/machine learning_paper_190.txt",
        "pdf_path": null
    },
    {
        "title": "Amnesiac Machine Learning",
        "abstract": "The Right to be Forgotten is part of the recently enacted General Data Protection Regulation (GDPR) law that affects any data holder that has data on European Union residents. It gives EU residents the ability to request deletion of their personal data, including training records used to train machine learning models. Unfortunately, Deep Neural Network models are vulnerable to information leaking attacks such as model inversion attacks which extract class information from a trained model and membership inference attacks which determine the presence of an example in a model's training data. If a malicious party can mount an attack and learn private information that was meant to be removed, then it implies that the model owner has not properly protected their user's rights and their models may not be compliant with the GDPR law. In this paper, we present two efficient methods that address this question of how a model owner or data holder may delete personal data from models in such a way that they may not be vulnerable to model inversion and membership inference attacks while maintaining model efficacy. We start by presenting a real-world threat model that shows that simply removing training data is insufficient to protect users. We follow that up with two data removal methods, namely Unlearning and Amnesiac Unlearning, that enable model owners to protect themselves against such attacks while being compliant with regulations. We provide extensive empirical analysis that show that these methods are indeed efficient, safe to apply, effectively remove learned information about sensitive data from trained models while maintaining model efficacy.",
        "link": "https://www.semanticscholar.org/paper/09227e0251dad7b972878720131ddaecfec6c47f",
        "published": "2020-10-21",
        "pdf_url": "https://ojs.aaai.org/index.php/AAAI/article/download/17371/17178",
        "txt_path": "data/txt/machine learning_paper_191.txt",
        "pdf_path": null
    },
    {
        "title": "Bayesian Optimization is Superior to Random Search for Machine Learning Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020",
        "abstract": "This paper presents the results and insights from the black-box optimization (BBO) challenge at NeurIPS 2020 which ran from July-October, 2020. The challenge emphasized the importance of evaluating derivative-free optimizers for tuning the hyperparameters of machine learning models. This was the first black-box optimization challenge with a machine learning emphasis. It was based on tuning (validation set) performance of standard machine learning models on real datasets. This competition has widespread impact as black-box optimization (e.g., Bayesian optimization) is relevant for hyperparameter tuning in almost every machine learning project as well as many applications outside of machine learning. The final leaderboard was determined using the optimization performance on held-out (hidden) objective functions, where the optimizers ran without human intervention. Baselines were set using the default settings of several open-source black-box optimization packages as well as random search.",
        "link": "https://www.semanticscholar.org/paper/4afa7d8e2de43b0b67366b1bce8768f5a246d153",
        "published": "2021-04-20",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_192.txt",
        "pdf_path": null
    },
    {
        "title": "An open source machine learning framework for efficient and transparent systematic reviews",
        "abstract": "To help researchers conduct a systematic review or meta-analysis as efficiently and transparently as possible, we designed a tool to accelerate the step of screening titles and abstracts. For many tasks—including but not limited to systematic reviews and meta-analyses—the scientific literature needs to be checked systematically. Scholars and practitioners currently screen thousands of studies by hand to determine which studies to include in their review or meta-analysis. This is error prone and inefficient because of extremely imbalanced data: only a fraction of the screened studies is relevant. The future of systematic reviewing will be an interaction with machine learning algorithms to deal with the enormous increase of available text. We therefore developed an open source machine learning-aided pipeline applying active learning: ASReview. We demonstrate by means of simulation studies that active learning can yield far more efficient reviewing than manual reviewing while providing high quality. Furthermore, we describe the options of the free and open source research software and present the results from user experience tests. We invite the community to contribute to open source projects such as our own that provide measurable and reproducible improvements over current practice. It is a challenging task for any research field to screen the literature and determine what needs to be included in a systematic review in a transparent way. A new open source machine learning framework called ASReview, which employs active learning and offers a range of machine learning models, can check the literature efficiently and systemically.",
        "link": "https://www.semanticscholar.org/paper/223846b7b56e250e1b6f521997b4c1b809cc0da7",
        "published": "2020-06-22",
        "pdf_url": "https://www.nature.com/articles/s42256-020-00287-7.pdf",
        "txt_path": "data/txt/machine learning_paper_193.txt",
        "pdf_path": "data/pdfs/machine learning_paper_193.pdf"
    },
    {
        "title": "Fairness in Machine Learning",
        "abstract": "Machine learning based systems are reaching society at large and in many aspects of everyday life. This phenomenon has been accompanied by concerns about the ethical issues that may arise from the adoption of these technologies. ML fairness is a recently established area of machine learning that studies how to ensure that biases in the data and model inaccuracies do not lead to models that treat individuals unfavorably on the basis of characteristics such as e.g. race, gender, disabilities, and sexual or political orientation. In this manuscript, we discuss some of the limitations present in the current reasoning about fairness and in methods that deal with it, and describe some work done by the authors to address them. More specifically, we show how causal Bayesian networks can play an important role to reason about and deal with fairness, especially in complex unfairness scenarios. We describe how optimal transport theory can be leveraged to develop methods that impose constraints on the full shapes of distributions corresponding to different sensitive attributes, overcoming the limitation of most approaches that approximate fairness desiderata by imposing constraints on the lower order moments or other functions of those distributions. We present a unified framework that encompasses methods that can deal with different settings and fairness criteria, and that enjoys strong theoretical guarantees. We introduce an approach to learn fair representations that can generalize to unseen tasks. Finally, we describe a technique that accounts for legal restrictions about the use of sensitive attributes.",
        "link": "https://www.semanticscholar.org/paper/97ac11e5a6440eccb70ae7146392ac138c36fa6c",
        "published": "2020-12-31",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_194.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning for alloys",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/d3f9a39e49abfdf084da558e305be5473c8740e5",
        "published": "2021-07-20",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_195.txt",
        "pdf_path": null
    },
    {
        "title": "From distributed machine learning to federated learning: a survey",
        "abstract": "In recent years, data and computing resources are typically distributed in the devices of end users, various regions or organizations. Because of laws or regulations, the distributed data and computing resources cannot be aggregated or directly shared among different regions or organizations for machine learning tasks. Federated learning emerges as an efficient approach to exploit distributed data and computing resources, so as to collaboratively train machine learning models. At the same time, federated learning obeys the laws and regulations and ensures data security and data privacy. In this paper, we provide a comprehensive survey of existing works for federated learning. First, we propose a functional architecture of federated learning systems and a taxonomy of related techniques. Second, we explain the federated learning systems from four aspects: diverse types of parallelism, aggregation algorithms, data communication, and the security of federated learning systems. Third, we present four widely used federated systems based on the functional architecture. Finally, we summarize the limitations and propose future research directions.",
        "link": "https://www.semanticscholar.org/paper/f938cffd498ffb81ee9d66b4cd473e82c2e12c72",
        "published": "2021-04-29",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_196.txt",
        "pdf_path": null
    },
    {
        "title": "Quantum embeddings for machine learning",
        "abstract": "Quantum classifiers are trainable quantum circuits used as machine learning models. The first part of the circuit implements a quantum feature map that encodes classical inputs into quantum states, embedding the data in a high-dimensional Hilbert space; the second part of the circuit executes a quantum measurement interpreted as the output of the model. Usually, the measurement is trained to distinguish quantum-embedded data. We propose to instead train the first part of the circuit---the embedding---with the objective of maximally separating data classes in Hilbert space, a strategy we call quantum metric learning. As a result, the measurement minimizing a linear classification loss is already known and depends on the metric used: for embeddings separating data using the l1 or trace distance, this is the Helstrom measurement, while for the l2 or Hilbert-Schmidt distance, it is a simple overlap measurement. This approach provides a powerful analytic framework for quantum machine learning and eliminates a major component in current models, freeing up more precious resources to best leverage the capabilities of near-term quantum information processors.",
        "link": "https://www.semanticscholar.org/paper/4a7eea3ec3080ecb277bfe466afce4822a1071d7",
        "published": "2020-01-10",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_197.txt",
        "pdf_path": null
    },
    {
        "title": "Best practices in machine learning for chemistry",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/0c8c500cec9b74ebc7be44c52b79d2bd78234605",
        "published": "2021-05-31",
        "pdf_url": "https://hal.archives-ouvertes.fr/hal-03243917/file/revised.pdf",
        "txt_path": "data/txt/machine learning_paper_198.txt",
        "pdf_path": "data/pdfs/machine learning_paper_198.pdf"
    },
    {
        "title": "Mathematics for Machine Learning",
        "abstract": "Machine learning is a way to study the algorithm and statistical model that is used by computer to perform a specific task through pattern and deduction [1]. It builds a mathematical model from a sample data which may come under either supervised or unsupervised learning. It is closely\n related to computational statistics which is an interface between statistics and computer science. Also, linear algebra and probability theory are two tools of mathematics which form the basis of machine learning. In general, statistics is a science concerned with collecting, analysing, interpreting\n the data. Data are the facts and figure that can be classified as either quantitative or qualitative. From the given set of data, we can predict the expected observation, difference between the outcome of two observations and how data look like which can help in better decision making process\n [2]. Descriptive and inferential statistics are the two methods of data analysis. Descriptive statistics summarize the raw data into information through which common expectation and variation of data can be taken. It also provides graphical methods that can be used to visualize the sample\n of data and qualitative understanding of observation whereas inferential statistics refers to drawing conclusions from data. Inferences are made under the framework of probability theory. So, understanding of data and interpretation of result are two important aspects of machine learning.\n In this paper, we have reviewed the different methods of ML, mathematics behind ML, its application in day to day life and future aspects.",
        "link": "https://www.semanticscholar.org/paper/4f97e87512eb8bf48ce695443e958725c54908b6",
        "published": "2020-02-01",
        "pdf_url": "https://mml-book.github.io/book/mml-book.pdf",
        "txt_path": "data/txt/machine learning_paper_199.txt",
        "pdf_path": "data/pdfs/machine learning_paper_199.pdf"
    },
    {
        "title": "Coronavirus disease (COVID-19) cases analysis using machine-learning applications",
        "abstract": "Today world thinks about coronavirus disease that which means all even this pandemic disease is not unique. The purpose of this study is to detect the role of machine-learning applications and algorithms in investigating and various purposes that deals with COVID-19. Review of the studies that had been published during 2020 and were related to this topic by seeking in Science Direct, Springer, Hindawi, and MDPI using COVID-19, machine learning, supervised learning, and unsupervised learning as keywords. The total articles obtained were 16,306 overall but after limitation; only 14 researches of these articles were included in this study. Our findings show that machine learning can produce an important role in COVID-19 investigations, prediction, and discrimination. In conclusion, machine learning can be involved in the health provider programs and plans to assess and triage the COVID-19 cases. Supervised learning showed better results than other Unsupervised learning algorithms by having 92.9% testing accuracy. In the future recurrent supervised learning can be utilized for superior accuracy.",
        "link": "https://www.semanticscholar.org/paper/f381c53aeb7742e4047d06d84f9e0c4f523231a3",
        "published": "2021-05-21",
        "pdf_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8138510",
        "txt_path": "data/txt/machine learning_paper_200.txt",
        "pdf_path": null
    },
    {
        "title": "Implementation of machine-learning classification in remote sensing: an applied review",
        "abstract": "ABSTRACT Machine learning offers the potential for effective and efficient classification of remotely sensed imagery. The strengths of machine learning include the capacity to handle data of high dimensionality and to map classes with very complex characteristics. Nevertheless, implementing a machine-learning classification is not straightforward, and the literature provides conflicting advice regarding many key issues. This article therefore provides an overview of machine learning from an applied perspective. We focus on the relatively mature methods of support vector machines, single decision trees (DTs), Random Forests, boosted DTs, artificial neural networks, and k-nearest neighbours (k-NN). Issues considered include the choice of algorithm, training data requirements, user-defined parameter selection and optimization, feature space impacts and reduction, and computational costs. We illustrate these issues through applying machine-learning classification to two publically available remotely sensed data sets.",
        "link": "https://www.semanticscholar.org/paper/b3de1062d8a462dfdc2938558258f8884abe9f4e",
        "published": "2018-02-02",
        "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/01431161.2018.1433343?needAccess=true",
        "txt_path": "data/txt/machine learning_paper_201.txt",
        "pdf_path": null
    },
    {
        "title": "Stealing Machine Learning Models via Prediction APIs",
        "abstract": "Machine learning (ML) models may be deemed confidential due to their sensitive training data, commercial value, or use in security applications. Increasingly often, confidential ML models are being deployed with publicly accessible query interfaces. ML-as-a-service (\"predictive analytics\") systems are an example: Some allow users to train models on potentially sensitive data and charge others for access on a pay-per-query basis. \nThe tension between model confidentiality and public access motivates our investigation of model extraction attacks. In such attacks, an adversary with black-box access, but no prior knowledge of an ML model's parameters or training data, aims to duplicate the functionality of (i.e., \"steal\") the model. Unlike in classical learning theory settings, ML-as-a-service offerings may accept partial feature vectors as inputs and include confidence values with predictions. Given these practices, we show simple, efficient attacks that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, neural networks, and decision trees. We demonstrate these attacks against the online services of BigML and Amazon Machine Learning. We further show that the natural countermeasure of omitting confidence values from model outputs still admits potentially harmful model extraction attacks. Our results highlight the need for careful ML model deployment and new model extraction countermeasures.",
        "link": "https://www.semanticscholar.org/paper/8a95423d0059f7c5b1422f0ef1aa60b9e26aab7e",
        "published": "2016-08-10",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_202.txt",
        "pdf_path": null
    },
    {
        "title": "Some Studies in Machine Learning Using the Game of Checkers",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/e9e6bb5f2a04ae30d8ecc9287f8b702eedd7b772",
        "published": "1995-10-31",
        "pdf_url": "http://www.cs.virginia.edu/~evans/greatworks/samuel1959.pdf",
        "txt_path": "data/txt/machine learning_paper_203.txt",
        "pdf_path": "data/pdfs/machine learning_paper_203.pdf"
    },
    {
        "title": "Machine Learning in Healthcare",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/74bc39003e65119eaa6ba339a61b45b417a638b7",
        "published": "2022-01-18",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_204.txt",
        "pdf_path": null
    },
    {
        "title": "The Machine‐Learning Approach",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/d1e701665e73faa648cb15473952576f40e8e122",
        "published": "2020-02-20",
        "pdf_url": "http://cbio.ensmp.fr/~jvert/svn/bibli/local/Zhou2004Recognizing.pdf",
        "txt_path": "data/txt/machine learning_paper_205.txt",
        "pdf_path": null
    },
    {
        "title": "Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting",
        "abstract": "Machine learning algorithms, when applied to sensitive data, pose a distinct threat to privacy. A growing body of prior work demonstrates that models produced by these algorithms may leak specific private information in the training data to an attacker, either through the models' structure or their observable behavior. However, the underlying cause of this privacy risk is not well understood beyond a handful of anecdotal accounts that suggest overfitting and influence might play a role. This paper examines the effect that overfitting and influence have on the ability of an attacker to learn information about the training data from machine learning models, either through training set membership inference or attribute inference attacks. Using both formal and empirical analyses, we illustrate a clear relationship between these factors and the privacy risk that arises in several popular machine learning algorithms. We find that overfitting is sufficient to allow an attacker to perform membership inference and, when the target attribute meets certain conditions about its influence, attribute inference attacks. Interestingly, our formal analysis also shows that overfitting is not necessary for these attacks and begins to shed light on what other factors may be in play. Finally, we explore the connection between membership inference and attribute inference, showing that there are deep connections between the two that lead to effective new attacks.",
        "link": "https://www.semanticscholar.org/paper/c8f216f663660ff3bc195ecd3a8ad61f0ed1d9d7",
        "published": "2017-09-05",
        "pdf_url": "https://arxiv.org/pdf/1709.01604",
        "txt_path": "data/txt/machine learning_paper_206.txt",
        "pdf_path": "data/pdfs/machine learning_paper_206.pdf"
    },
    {
        "title": "Extreme learning machine: Theory and applications",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/f2df0c1026ffa474f603a535e48e5c115d3d8629",
        "published": "2006-12-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_207.txt",
        "pdf_path": null
    },
    {
        "title": "Explainable machine-learning predictions for the prevention of hypoxaemia during surgery",
        "abstract": "Although anaesthesiologists strive to avoid hypoxaemia during surgery, reliably predicting future intraoperative hypoxaemia is not possible at present. Here, we report the development and testing of a machine-learning-based system that predicts the risk of hypoxaemia and provides explanations of the risk factors in real time during general anaesthesia. The system, which was trained on minute-by-minute data from the electronic medical records of over 50,000 surgeries, improved the performance of anaesthesiologists by providing interpretable hypoxaemia risks and contributing factors. The explanations for the predictions are broadly consistent with the literature and with prior knowledge from anaesthesiologists. Our results suggest that if anaesthesiologists currently anticipate 15% of hypoxaemia events, with the assistance of this system they could anticipate 30%, a large portion of which may benefit from early intervention because they are associated with modifiable factors. The system can help improve the clinical understanding of hypoxaemia risk during anaesthesia care by providing general insights into the exact changes in risk induced by certain characteristics of the patient or procedure. An alert system based on machine learning and trained on surgical data from electronic medical records helps anaesthesiologists prevent hypoxaemia during surgery by providing interpretable real-time predictions.",
        "link": "https://www.semanticscholar.org/paper/53eef24a59b12107e6188e121c85f85fa8a78100",
        "published": "2018-10-01",
        "pdf_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6467492",
        "txt_path": "data/txt/machine learning_paper_208.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in Medicine",
        "abstract": "Machine Learning in Medicine In this view of the future of medicine, patient–provider interactions are informed and supported by massive amounts of data from interactions with similar patients. The...",
        "link": "https://www.semanticscholar.org/paper/21dfbc88b21b27fe8a245ab1df98edd45f655ae7",
        "published": "2019-04-03",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_209.txt",
        "pdf_path": null
    },
    {
        "title": "Understanding Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/bb0cec8f2d34cfb9dbf8bffd1a5de499311ae098",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_210.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/8ca9fb628f7d8e0099b2d0f9b9e87d5fc3adb23c",
        "published": "2023-03-23",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_211.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning for Chemical Reactions.",
        "abstract": "Machine learning (ML) techniques applied to chemical reactions have a long history. The present contribution discusses applications ranging from small molecule reaction dynamics to computational platforms for reaction planning. ML-based techniques can be particularly relevant for problems involving both computation and experiments. For one, Bayesian inference is a powerful approach to develop models consistent with knowledge from experiments. Second, ML-based methods can also be used to handle problems that are formally intractable using conventional approaches, such as exhaustive characterization of state-to-state information in reactive collisions. Finally, the explicit simulation of reactive networks as they occur in combustion has become possible using machine-learned neural network potentials. This review provides an overview of the questions that can and have been addressed using machine learning techniques, and an outlook discusses challenges in this diverse and stimulating field. It is concluded that ML applied to chemistry problems as practiced and conceived today has the potential to transform the way with which the field approaches problems involving chemical reactions, in both research and academic teaching.",
        "link": "https://www.semanticscholar.org/paper/2a41589895b84f6225bba43d928355eb2fd52c1d",
        "published": "2021-06-07",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_212.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Force Fields",
        "abstract": "In recent years, the use of machine learning (ML) in computational chemistry has enabled numerous advances previously out of reach due to the computational complexity of traditional electronic-structure methods. One of the most promising applications is the construction of ML-based force fields (FFs), with the aim to narrow the gap between the accuracy of ab initio methods and the efficiency of classical FFs. The key idea is to learn the statistical relation between chemical structure and potential energy without relying on a preconceived notion of fixed chemical bonds or knowledge about the relevant interactions. Such universal ML approximations are in principle only limited by the quality and quantity of the reference data used to train them. This review gives an overview of applications of ML-FFs and the chemical insights that can be obtained from them. The core concepts underlying ML-FFs are described in detail, and a step-by-step guide for constructing and testing them from scratch is given. The text concludes with a discussion of the challenges that remain to be overcome by the next generation of ML-FFs.",
        "link": "https://www.semanticscholar.org/paper/a1f57b760b7d4c44490f0bb86ee5462c3e7c7272",
        "published": "2020-10-14",
        "pdf_url": "https://doi.org/10.1021/acs.chemrev.0c01111",
        "txt_path": "data/txt/machine learning_paper_213.txt",
        "pdf_path": null
    },
    {
        "title": "Extreme Learning Machine for Regression and Multiclass Classification",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/739769f4862753fc80057194456d758d2a148ee3",
        "published": "2012-04-01",
        "pdf_url": "http://www.ntu.edu.sg/home/egbhuang/pdf/ELM-Unified-Learning.pdf",
        "txt_path": "data/txt/machine learning_paper_214.txt",
        "pdf_path": null
    },
    {
        "title": "A study of the behavior of several methods for balancing machine learning training data",
        "abstract": "There are several aspects that might influence the performance achieved by existing learning systems. It has been reported that one of these aspects is related to class imbalance in which examples in training data belonging to one class heavily outnumber the examples in the other class. In this situation, which is found in real world data describing an infrequent but important event, the learning system may have difficulties to learn the concept related to the minority class. In this work we perform a broad experimental evaluation involving ten methods, three of them proposed by the authors, to deal with the class imbalance problem in thirteen UCI data sets. Our experiments provide evidence that class imbalance does not systematically hinder the performance of learning systems. In fact, the problem seems to be related to learning with too few minority class examples in the presence of other complicating factors, such as class overlapping. Two of our proposed methods deal with these conditions directly, allying a known over-sampling method with data cleaning methods in order to produce better-defined class clusters. Our comparative experiments show that, in general, over-sampling methods provide more accurate results than under-sampling methods considering the area under the ROC curve (AUC). This result seems to contradict results previously published in the literature. Two of our proposed methods, Smote + Tomek and Smote + ENN, presented very good results for data sets with a small number of positive examples. Moreover, Random over-sampling, a very simple over-sampling method, is very competitive to more complex over-sampling methods. Since the over-sampling methods provided very good performance results, we also measured the syntactic complexity of the decision trees induced from over-sampled data. Our results show that these trees are usually more complex then the ones induced from original data. Random over-sampling usually produced the smallest increase in the mean number of induced rules and Smote + ENN the smallest increase in the mean number of conditions per rule, when compared among the investigated over-sampling methods.",
        "link": "https://www.semanticscholar.org/paper/6aae0dc122102693e8136856ffc8b72df7f78386",
        "published": "2004-06-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_215.txt",
        "pdf_path": null
    },
    {
        "title": "Underspecification Presents Challenges for Credibility in Modern Machine Learning",
        "abstract": "ML models often exhibit unexpectedly poor behavior when they are deployed in real-world domains. We identify underspecification as a key reason for these failures. An ML pipeline is underspecified when it can return many predictors with equivalently strong held-out performance in the training domain. Underspecification is common in modern ML pipelines, such as those based on deep learning. Predictors returned by underspecified pipelines are often treated as equivalent based on their training domain performance, but we show here that such predictors can behave very differently in deployment domains. This ambiguity can lead to instability and poor model behavior in practice, and is a distinct failure mode from previously identified issues arising from structural mismatch between training and deployment domains. We show that this problem appears in a wide variety of practical ML pipelines, using examples from computer vision, medical imaging, natural language processing, clinical risk prediction based on electronic health records, and medical genomics. Our results show the need to explicitly account for underspecification in modeling pipelines that are intended for real-world deployment in any domain.",
        "link": "https://www.semanticscholar.org/paper/71a85e735a3686bef8cce3725ae5ba82e2cabb1b",
        "published": "2020-11-06",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_216.txt",
        "pdf_path": null
    },
    {
        "title": "A Review on Linear Regression Comprehensive in Machine Learning",
        "abstract": "Perhaps one of the most common and comprehensive statistical and machine learning algorithms are linear regression. Linear regression is used to find a linear relationship between one or more predictors. The linear regression has two types: simple regression and multiple regression (MLR). This paper discusses various works by different researchers on linear regression and polynomial regression and compares their performance using the best approach to optimize prediction and precision. Almost all of the articles analyzed in this review is focused on datasets; in order to determine a model's efficiency, it must be correlated with the actual values obtained for the explanatory variables.",
        "link": "https://www.semanticscholar.org/paper/99afa67e28780754907b19b688bf2b35eb22e578",
        "published": null,
        "pdf_url": "https://jastt.org/index.php/jasttpath/article/download/57/20",
        "txt_path": "data/txt/machine learning_paper_217.txt",
        "pdf_path": "data/pdfs/machine learning_paper_217.pdf"
    },
    {
        "title": "A Survey of Human-in-the-loop for Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/102ebe229df18c8733ea1b8def56cd79996e2178",
        "published": "2021-08-02",
        "pdf_url": "https://arxiv.org/pdf/2108.00941",
        "txt_path": "data/txt/machine learning_paper_218.txt",
        "pdf_path": "data/pdfs/machine learning_paper_218.pdf"
    },
    {
        "title": "Secure, privacy-preserving and federated machine learning in medical imaging",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/5123717445799d8137327f4041e8d5a5a2c91379",
        "published": "2020-06-01",
        "pdf_url": "https://www.nature.com/articles/s42256-020-0186-1.pdf",
        "txt_path": "data/txt/machine learning_paper_219.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning and data mining in manufacturing",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/430f3c265935abb45bc84f3ae81c570ef778aac0",
        "published": "2021-03-15",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_220.txt",
        "pdf_path": null
    },
    {
        "title": "Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models",
        "abstract": "Many machine learning algorithms are vulnerable to almost imperceptible perturbations of their inputs. So far it was unclear how much risk adversarial perturbations carry for the safety of real-world machine learning applications because most methods used to generate such perturbations rely either on detailed model information (gradient-based attacks) or on confidence scores such as class probabilities (score-based attacks), neither of which are available in most real-world scenarios. In many such cases one currently needs to retreat to transfer-based attacks which rely on cumbersome substitute models, need access to the training data and can be defended against. Here we emphasise the importance of attacks which solely rely on the final model decision. Such decision-based attacks are (1) applicable to real-world black-box models such as autonomous cars, (2) need less knowledge and are easier to apply than transfer-based attacks and (3) are more robust to simple defences than gradient- or score-based attacks. Previous attacks in this category were limited to simple models or simple datasets. Here we introduce the Boundary Attack, a decision-based attack that starts from a large adversarial perturbation and then seeks to reduce the perturbation while staying adversarial. The attack is conceptually simple, requires close to no hyperparameter tuning, does not rely on substitute models and is competitive with the best gradient-based attacks in standard computer vision tasks like ImageNet. We apply the attack on two black-box algorithms from Clarifai.com. The Boundary Attack in particular and the class of decision-based attacks in general open new avenues to study the robustness of machine learning models and raise new questions regarding the safety of deployed machine learning systems. An implementation of the attack is available as part of Foolbox at this https URL .",
        "link": "https://www.semanticscholar.org/paper/1b225474e7a5794f98cdfbde8b12ccbc56799409",
        "published": "2017-12-12",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_221.txt",
        "pdf_path": null
    },
    {
        "title": "Automatic differentiation in machine learning: a survey",
        "abstract": "Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD), also called algorithmic differentiation or simply “auto-diff”, is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational fluid dynamics, atmospheric sciences, and engineering design optimization. Until \nvery recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other’s results. Despite its \nrelevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names “dynamic computational \ngraphs” and “differentiable programming”. We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main imple- \nmentation techniques. By precisely defining the main differentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms “autodiff”, “automatic differentiation”, and “symbolic differentiation” as these are encountered more and more in machine learning settings.",
        "link": "https://www.semanticscholar.org/paper/643da4c4de1954daeac571a82367241db012a8bf",
        "published": "2015-02-20",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_222.txt",
        "pdf_path": null
    },
    {
        "title": "Introduction to Machine Learning, Neural Networks, and Deep Learning",
        "abstract": "Purpose To present an overview of current machine learning methods and their use in medical research, focusing on select machine learning techniques, best practices, and deep learning. Methods A systematic literature search in PubMed was performed for articles pertinent to the topic of artificial intelligence methods used in medicine with an emphasis on ophthalmology. Results A review of machine learning and deep learning methodology for the audience without an extensive technical computer programming background. Conclusions Artificial intelligence has a promising future in medicine; however, many challenges remain. Translational Relevance The aim of this review article is to provide the nontechnical readers a layman's explanation of the machine learning methods being used in medicine today. The goal is to provide the reader a better understanding of the potential and challenges of artificial intelligence within the field of medicine.",
        "link": "https://www.semanticscholar.org/paper/6b67e38e488cdb6a5af8ae44fdbb2c069c9cea0e",
        "published": "2020-01-28",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_223.txt",
        "pdf_path": null
    },
    {
        "title": "Big Data and Machine Learning in Health Care.",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/efca2a32ce9c7a808c2c3efcc2c3dac032dfc8ea",
        "published": "2018-04-03",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_224.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/31a61d009442436d04b9d4e1c5beee37172289ae",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_225.txt",
        "pdf_path": null
    },
    {
        "title": "Principles and Practice of Explainable Machine Learning",
        "abstract": "Artificial intelligence (AI) provides many opportunities to improve private and public life. Discovering patterns and structures in large troves of data in an automated manner is a core component of data science, and currently drives applications in diverse areas such as computational biology, law and finance. However, such a highly positive impact is coupled with a significant challenge: how do we understand the decisions suggested by these systems in order that we can trust them? In this report, we focus specifically on data-driven methods—machine learning (ML) and pattern recognition models in particular—so as to survey and distill the results and observations from the literature. The purpose of this report can be especially appreciated by noting that ML models are increasingly deployed in a wide range of businesses. However, with the increasing prevalence and complexity of methods, business stakeholders in the very least have a growing number of concerns about the drawbacks of models, data-specific biases, and so on. Analogously, data science practitioners are often not aware about approaches emerging from the academic literature or may struggle to appreciate the differences between different methods, so end up using industry standards such as SHAP. Here, we have undertaken a survey to help industry practitioners (but also data scientists more broadly) understand the field of explainable machine learning better and apply the right tools. Our latter sections build a narrative around a putative data scientist, and discuss how she might go about explaining her models by asking the right questions. From an organization viewpoint, after motivating the area broadly, we discuss the main developments, including the principles that allow us to study transparent models vs. opaque models, as well as model-specific or model-agnostic post-hoc explainability approaches. We also briefly reflect on deep learning models, and conclude with a discussion about future research directions.",
        "link": "https://www.semanticscholar.org/paper/b5b98051b65da6b1b3b579862b0407d48c5bef48",
        "published": "2020-09-18",
        "pdf_url": "https://www.frontiersin.org/articles/10.3389/fdata.2021.688969/pdf",
        "txt_path": "data/txt/machine learning_paper_226.txt",
        "pdf_path": "data/pdfs/machine learning_paper_226.pdf"
    },
    {
        "title": "Tslearn, A Machine Learning Toolkit for Time Series Data",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/80c3c1cb86eeb9f2ab0934d6f914918889d34db7",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_227.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence",
        "abstract": "Smarter applications are making better use of the insights gleaned from data, having an impact on every industry and research discipline. At the core of this revolution lies the tools and the methods that are driving it, from processing the massive piles of data generated each day to learning from and taking useful action. Deep neural networks, along with advancements in classical machine learning and scalable general-purpose graphics processing unit (GPU) computing, have become critical components of artificial intelligence, enabling many of these astounding breakthroughs and lowering the barrier to adoption. Python continues to be the most preferred language for scientific computing, data science, and machine learning, boosting both performance and productivity by enabling the use of low-level libraries and clean high-level APIs. This survey offers insight into the field of machine learning with Python, taking a tour through important topics to identify some of the core hardware and software paradigms that have enabled it. We cover widely-used libraries and concepts, collected together for holistic comparison, with the goal of educating the reader and driving the field of Python machine learning forward.",
        "link": "https://www.semanticscholar.org/paper/72d3ddf1f7210d7e70144bbc09f770ec411fe909",
        "published": "2020-02-12",
        "pdf_url": "https://www.mdpi.com/2078-2489/11/4/193/pdf?version=1587379966",
        "txt_path": "data/txt/machine learning_paper_228.txt",
        "pdf_path": null
    },
    {
        "title": "Predicting the state of charge and health of batteries using data-driven machine learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/86788a38467e1f2f1df713f5d5694bfee9f8ae29",
        "published": "2020-03-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_229.txt",
        "pdf_path": null
    },
    {
        "title": "What Role Does Hydrological Science Play in the Age of Machine Learning?",
        "abstract": "This paper is derived from a keynote talk given at the Google's 2020 Flood Forecasting Meets Machine Learning Workshop. Recent experiments applying deep learning to rainfall‐runoff simulation indicate that there is significantly more information in large‐scale hydrological data sets than hydrologists have been able to translate into theory or models. While there is a growing interest in machine learning in the hydrological sciences community, in many ways, our community still holds deeply subjective and nonevidence‐based preferences for models based on a certain type of “process understanding” that has historically not translated into accurate theory, models, or predictions. This commentary is a call to action for the hydrology community to focus on developing a quantitative understanding of where and when hydrological process understanding is valuable in a modeling discipline increasingly dominated by machine learning. We offer some potential perspectives and preliminary examples about how this might be accomplished.",
        "link": "https://www.semanticscholar.org/paper/62d4aaaf562df94c4bdb116ee1e5cc2843c88bec",
        "published": "2020-02-11",
        "pdf_url": "https://eartharxiv.org/repository/object/422/download/3646/",
        "txt_path": "data/txt/machine learning_paper_230.txt",
        "pdf_path": "data/pdfs/machine learning_paper_230.pdf"
    },
    {
        "title": "Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program)",
        "abstract": "One of the challenges in machine learning research is to ensure that presented and published results are sound and reliable. Reproducibility, that is obtaining similar results as presented in a paper or talk, using the same code and data (when available), is a necessary step to verify the reliability of research findings. Reproducibility is also an important step to promote open and accessible research, thereby allowing the scientific community to quickly integrate new findings and convert ideas to practice. Reproducibility also promotes the use of robust experimental workflows, which potentially reduce unintentional errors. In 2019, the Neural Information Processing Systems (NeurIPS) conference, the premier international conference for research in machine learning, introduced a reproducibility program, designed to improve the standards across the community for how we conduct, communicate, and evaluate machine learning research. The program contained three components: a code submission policy, a community-wide reproducibility challenge, and the inclusion of the Machine Learning Reproducibility checklist as part of the paper submission process. In this paper, we describe each of these components, how it was deployed, as well as what we were able to learn from this initiative.",
        "link": "https://www.semanticscholar.org/paper/5e331bf7887e2e634bf5b12788849d2d2b74bc7f",
        "published": "2020-03-27",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_231.txt",
        "pdf_path": null
    },
    {
        "title": "Challenges in Deploying Machine Learning: A Survey of Case Studies",
        "abstract": "In recent years, machine learning has transitioned from a field of academic research interest to a field capable of solving real-world business problems. However, the deployment of machine learning models in production systems can present a number of issues and concerns. This survey reviews published reports of deploying machine learning solutions in a variety of use cases, industries, and applications and extracts practical considerations corresponding to stages of the machine learning deployment workflow. By mapping found challenges to the steps of the machine learning deployment workflow, we show that practitioners face issues at each stage of the deployment process. The goal of this article is to lay out a research agenda to explore approaches addressing these challenges.",
        "link": "https://www.semanticscholar.org/paper/b1f574c47d0b6e3032246770b9cbebb9c7bd0c7f",
        "published": "2020-11-18",
        "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3533378",
        "txt_path": "data/txt/machine learning_paper_232.txt",
        "pdf_path": null
    },
    {
        "title": "Advancing Biosensors with Machine Learning.",
        "abstract": "Chemometrics play a critical role in biosensors-based detection, analysis, and diagnosis. Nowadays, as a branch of artificial intelligence (AI), machine learning (ML) have achieved impressive advances. However, novel advanced ML methods, especially deep learning, which is famous for image analysis, facial recognition, and speech recognition, has remained relatively elusive to the biosensor community. Herein, how ML can be beneficial to biosensors is systematically discussed. The advantages and drawbacks of most popular ML algorithms are summarized on the basis of sensing data analysis. Specially, deep learning methods such as convolutional neural network (CNN) and recurrent neural network (RNN) are emphasized. Diverse ML-assisted electrochemical biosensors, wearable electronics, SERS and other spectra-based biosensors, fluorescence biosensors and colorimetric biosensors are comprehensively discussed. Furthermore, biosensor networks and multibiosensor data fusion are introduced. This review will nicely bridge ML with biosensors, and greatly expand chemometrics for detection, analysis, and diagnosis.",
        "link": "https://www.semanticscholar.org/paper/6f803c1729ed818ef6a5ee28cf23b3c6ca9e4291",
        "published": "2020-11-13",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_233.txt",
        "pdf_path": null
    },
    {
        "title": "A Comprehensive Survey of Loss Functions in Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/89998030721e58ade6349b9426cc8c8d81103028",
        "published": "2020-04-12",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_234.txt",
        "pdf_path": null
    },
    {
        "title": "Explaining Explanations: An Overview of Interpretability of Machine Learning",
        "abstract": "There has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we describe foundational concepts of explainability and show how they can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence.",
        "link": "https://www.semanticscholar.org/paper/d7701e78e0bfc92b03a89582e80cfb751ac03f26",
        "published": "2018-05-31",
        "pdf_url": "http://arxiv.org/pdf/1806.00069",
        "txt_path": "data/txt/machine learning_paper_235.txt",
        "pdf_path": "data/pdfs/machine learning_paper_235.pdf"
    },
    {
        "title": "Applications of machine learning to diagnosis and treatment of neurodegenerative diseases",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/c0bc4ef587b4cbebd5839baeed95274fbf26c43a",
        "published": "2020-07-15",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_236.txt",
        "pdf_path": null
    },
    {
        "title": "Ethical Machine Learning in Health Care",
        "abstract": "The use of machine learning (ML) in healthcare raises numerous ethical concerns, especially as models can amplify existing health inequities. Here, we outline ethical considerations for equitable ML in the advancement of healthcare. Specifically, we frame ethics of ML in healthcare through the lens of social justice. We describe ongoing efforts and outline challenges in a proposed pipeline of ethical ML in health, ranging from problem selection to postdeployment considerations. We close by summarizing recommendations to address these challenges.",
        "link": "https://www.semanticscholar.org/paper/e8d330f11df9c69f38b78a7cc4b1333ebecf7c55",
        "published": "2020-09-22",
        "pdf_url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-biodatasci-092820-114757",
        "txt_path": "data/txt/machine learning_paper_237.txt",
        "pdf_path": null
    },
    {
        "title": "Inverse molecular design using machine learning: Generative models for matter engineering",
        "abstract": "The discovery of new materials can bring enormous societal and technological progress. In this context, exploring completely the large space of potential materials is computationally intractable. Here, we review methods for achieving inverse design, which aims to discover tailored materials from the starting point of a particular desired functionality. Recent advances from the rapidly growing field of artificial intelligence, mostly from the subfield of machine learning, have resulted in a fertile exchange of ideas, where approaches to inverse molecular design are being proposed and employed at a rapid pace. Among these, deep generative models have been applied to numerous classes of materials: rational design of prospective drugs, synthetic routes to organic compounds, and optimization of photovoltaics and redox flow batteries, as well as a variety of other solid-state materials.",
        "link": "https://www.semanticscholar.org/paper/175e37bca3762b3a52c6a0e153060b98a251d061",
        "published": "2018-07-27",
        "pdf_url": "https://science.sciencemag.org/content/sci/361/6400/360.full.pdf",
        "txt_path": "data/txt/machine learning_paper_238.txt",
        "pdf_path": null
    },
    {
        "title": "Edge Machine Learning for AI-Enabled IoT Devices: A Review",
        "abstract": "In a few years, the world will be populated by billions of connected devices that will be placed in our homes, cities, vehicles, and industries. Devices with limited resources will interact with the surrounding environment and users. Many of these devices will be based on machine learning models to decode meaning and behavior behind sensors’ data, to implement accurate predictions and make decisions. The bottleneck will be the high level of connected things that could congest the network. Hence, the need to incorporate intelligence on end devices using machine learning algorithms. Deploying machine learning on such edge devices improves the network congestion by allowing computations to be performed close to the data sources. The aim of this work is to provide a review of the main techniques that guarantee the execution of machine learning models on hardware with low performances in the Internet of Things paradigm, paving the way to the Internet of Conscious Things. In this work, a detailed review on models, architecture, and requirements on solutions that implement edge machine learning on Internet of Things devices is presented, with the main goal to define the state of the art and envisioning development requirements. Furthermore, an example of edge machine learning implementation on a microcontroller will be provided, commonly regarded as the machine learning “Hello World”.",
        "link": "https://www.semanticscholar.org/paper/821fde6dc36d1264c765d249d4247ea66daff55f",
        "published": "2020-04-29",
        "pdf_url": "https://www.mdpi.com/1424-8220/20/9/2533/pdf?version=1589338738",
        "txt_path": "data/txt/machine learning_paper_239.txt",
        "pdf_path": null
    },
    {
        "title": "Integrating Physics-Based Modeling with Machine Learning: A Survey",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/6965bc6d26fc910a6387cd6d423b35fd9e1d358b",
        "published": "2020-03-10",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_240.txt",
        "pdf_path": null
    },
    {
        "title": "Quantum Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/ff8eea01cbb5de505672cf9bbda3a6a91624cf52",
        "published": "2018-03-07",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_241.txt",
        "pdf_path": null
    },
    {
        "title": "Trainable Weka Segmentation: a machine learning tool for microscopy pixel classification",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/8b27e2fafbe24cf9ce24f308a7e746489ff0dfb8",
        "published": "2017-08-01",
        "pdf_url": "https://academic.oup.com/bioinformatics/article-pdf/33/15/2424/25157856/btx180.pdf",
        "txt_path": "data/txt/machine learning_paper_242.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in Additive Manufacturing: A Review",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/5c41630a3b2faace172f49e990bb71af9e12c66c",
        "published": "2020-04-17",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_243.txt",
        "pdf_path": null
    },
    {
        "title": "Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples",
        "abstract": "Many machine learning models are vulnerable to adversarial examples: inputs that are specially crafted to cause a machine learning model to produce an incorrect output. Adversarial examples that affect one model often affect another model, even if the two models have different architectures or were trained on different training sets, so long as both models were trained to perform the same task. An attacker may therefore train their own substitute model, craft adversarial examples against the substitute, and transfer them to a victim model, with very little information about the victim. Recent work has further developed a technique that uses the victim model as an oracle to label a synthetic training set for the substitute, so the attacker need not even collect a training set to mount the attack. We extend these recent techniques using reservoir sampling to greatly enhance the efficiency of the training procedure for the substitute model. We introduce new transferability attacks between previously unexplored (substitute, victim) pairs of machine learning model classes, most notably SVMs and decision trees. We demonstrate our attacks on two commercial machine learning classification systems from Amazon (96.19% misclassification rate) and Google (88.94%) using only 800 queries of the victim model, thereby showing that existing machine learning approaches are in general vulnerable to systematic black-box attacks regardless of their structure.",
        "link": "https://www.semanticscholar.org/paper/78aa018ee7d52360e15d103390ea1cdb3a0beb41",
        "published": "2016-05-24",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_244.txt",
        "pdf_path": null
    },
    {
        "title": "Federated Optimization: Distributed Machine Learning for On-Device Intelligence",
        "abstract": "We introduce a new and increasingly relevant setting for distributed optimization in machine learning, where the data defining the optimization are unevenly distributed over an extremely large number of nodes. The goal is to train a high-quality centralized model. We refer to this setting as Federated Optimization. In this setting, communication efficiency is of the utmost importance and minimizing the number of rounds of communication is the principal goal. \nA motivating example arises when we keep the training data locally on users' mobile devices instead of logging it to a data center for training. In federated optimziation, the devices are used as compute nodes performing computation on their local data in order to update a global model. We suppose that we have extremely large number of devices in the network --- as many as the number of users of a given service, each of which has only a tiny fraction of the total data available. In particular, we expect the number of data points available locally to be much smaller than the number of devices. Additionally, since different users generate data with different patterns, it is reasonable to assume that no device has a representative sample of the overall distribution. \nWe show that existing algorithms are not suitable for this setting, and propose a new algorithm which shows encouraging experimental results for sparse convex problems. This work also sets a path for future research needed in the context of \\federated optimization.",
        "link": "https://www.semanticscholar.org/paper/561269a24f2f2a06409109723a8ab93a01696efc",
        "published": "2016-10-08",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_245.txt",
        "pdf_path": null
    },
    {
        "title": "Darts: User-Friendly Modern Machine Learning for Time Series",
        "abstract": "We present Darts, a Python machine learning library for time series, with a focus on forecasting. Darts offers a variety of models, from classics such as ARIMA to state-of-the-art deep neural networks. The emphasis of the library is on offering modern machine learning functionalities, such as supporting multidimensional series, meta-learning on multiple series, training on large datasets, incorporating external data, ensembling models, and providing a rich support for probabilistic forecasting. At the same time, great care goes into the API design to make it user-friendly and easy to use. For instance, all models can be used using fit()/predict(), similar to scikit-learn.",
        "link": "https://www.semanticscholar.org/paper/22733aac53e89446aed76dd1983bf2d74567ba88",
        "published": "2021-10-07",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_246.txt",
        "pdf_path": null
    },
    {
        "title": "Data Shapley: Equitable Valuation of Data for Machine Learning",
        "abstract": "As data becomes the fuel driving technological and economic growth, a fundamental challenge is how to quantify the value of data in algorithmic predictions and decisions. For example, in healthcare and consumer markets, it has been suggested that individuals should be compensated for the data that they generate, but it is not clear what is an equitable valuation for individual data. In this work, we develop a principled framework to address data valuation in the context of supervised machine learning. Given a learning algorithm trained on $n$ data points to produce a predictor, we propose data Shapley as a metric to quantify the value of each training datum to the predictor performance. Data Shapley value uniquely satisfies several natural properties of equitable data valuation. We develop Monte Carlo and gradient-based methods to efficiently estimate data Shapley values in practical settings where complex learning algorithms, including neural networks, are trained on large datasets. In addition to being equitable, extensive experiments across biomedical, image and synthetic data demonstrate that data Shapley has several other benefits: 1) it is more powerful than the popular leave-one-out or leverage score in providing insight on what data is more valuable for a given learning task; 2) low Shapley value data effectively capture outliers and corruptions; 3) high Shapley value data inform what type of new data to acquire to improve the predictor.",
        "link": "https://www.semanticscholar.org/paper/b7a717233ec3ff37385ab1b06816d0ca375f5bb3",
        "published": "2019-04-05",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_247.txt",
        "pdf_path": null
    },
    {
        "title": "Electronic skins and machine learning for intelligent soft robots",
        "abstract": "Developments in e-skins and machine learning may achieve tactile sensing and proprioception for autonomous, deployable soft robots. Soft robots have garnered interest for real-world applications because of their intrinsic safety embedded at the material level. These robots use deformable materials capable of shape and behavioral changes and allow conformable physical contact for manipulation. Yet, with the introduction of soft and stretchable materials to robotic systems comes a myriad of challenges for sensor integration, including multimodal sensing capable of stretching, embedment of high-resolution but large-area sensor arrays, and sensor fusion with an increasing volume of data. This Review explores the emerging confluence of e-skins and machine learning, with a focus on how roboticists can combine recent developments from the two fields to build autonomous, deployable soft robots, integrated with capabilities for informative touch and proprioception to stand up to the challenges of real-world environments.",
        "link": "https://www.semanticscholar.org/paper/feaeda74182d7f9890a6ff5a1733ee21a288cbd3",
        "published": "2020-04-22",
        "pdf_url": "https://robotics.sciencemag.org/content/robotics/5/41/eaaz9239.full.pdf",
        "txt_path": "data/txt/machine learning_paper_248.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning for Precision Medicine.",
        "abstract": "Precision medicine is an emerging approach to clinical research and patient care that focuses on understanding and treating disease by integrating multimodal or 'multi-omics' data from an individual to make patient-tailored decisions. With the large and complex datasets generated using precision medicine diagnostic approaches, novel techniques to process and understand these complex data were needed. At the same time, computer science has progressed rapidly to develop techniques that enable the storage, processing, and analysis of these complex datasets, a feat that traditional statistics and early computing technologies could not accomplish. Machine learning, a branch of artificial intelligence, is a computer science methodology that aims to identify complex patterns in data that can be used to make predictions or classifications on new unseen data or for advanced exploratory data analysis. Machine learning analysis of precision medicine's multimodal data allows for broad analysis of large datasets and ultimately a greater understanding of human health and disease. This review focuses on machine learning utilization for precision medicine's \"big data\", in the context of genetics, genomics, and beyond.",
        "link": "https://www.semanticscholar.org/paper/bc386debfedf3b16101b6c3274485cea78ad6bb7",
        "published": "2020-10-22",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_249.txt",
        "pdf_path": null
    },
    {
        "title": "Opportunities and Challenges for Machine Learning in Materials Science",
        "abstract": "Advances in machine learning have impacted myriad areas of materials science, such as the discovery of novel materials and the improvement of molecular simulations, with likely many more important developments to come. Given the rapid changes in this field, it is challenging to understand both the breadth of opportunities and the best practices for their use. In this review, we address aspects of both problems by providing an overview of the areas in which machine learning has recently had significant impact in materials science, and then we provide a more detailed discussion on determining the accuracy and domain of applicability of some common types of machine learning models. Finally, we discuss some opportunities and challenges for the materials community to fully utilize the capabilities of machine learning.",
        "link": "https://www.semanticscholar.org/paper/ede72940ae0246a292d644bd3c7e0ebf1e12a01a",
        "published": "2020-06-25",
        "pdf_url": "https://arxiv.org/pdf/2006.14604",
        "txt_path": "data/txt/machine learning_paper_250.txt",
        "pdf_path": "data/pdfs/machine learning_paper_250.pdf"
    },
    {
        "title": "Reproducibility in machine learning for health research: Still a ways to go",
        "abstract": "Machine learning applied to health falls short on several reproducibility metrics compared to other machine learning subfields. Machine learning for health must be reproducible to ensure reliable clinical use. We evaluated 511 scientific papers across several machine learning subfields and found that machine learning for health compared poorly to other areas regarding reproducibility metrics, such as dataset and code accessibility. We propose recommendations to address this problem.",
        "link": "https://www.semanticscholar.org/paper/2abdca069a95add94f5c0c540c09efb7adeee230",
        "published": "2021-03-24",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_251.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning for Combinatorial Optimization: a Methodological Tour d'Horizon",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/3f13a5148f7caa51ea946193d261d4f8ed32d81a",
        "published": "2018-11-15",
        "pdf_url": "https://arxiv.org/pdf/1811.06128",
        "txt_path": "data/txt/machine learning_paper_252.txt",
        "pdf_path": "data/pdfs/machine learning_paper_252.pdf"
    },
    {
        "title": "DOME: recommendations for supervised machine learning validation in biology",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/c370197b15fcd382094132bde4daa2c248b7cedf",
        "published": "2021-07-27",
        "pdf_url": "https://www.nature.com/articles/s41592-021-01205-4.pdf",
        "txt_path": "data/txt/machine learning_paper_253.txt",
        "pdf_path": "data/pdfs/machine learning_paper_253.pdf"
    },
    {
        "title": "Accounting for Variance in Machine Learning Benchmarks",
        "abstract": "Strong empirical evidence that one machine-learning algorithm A outperforms another one B ideally calls for multiple trials optimizing the learning pipeline over sources of variation such as data sampling, data augmentation, parameter initialization, and hyperparameters choices. This is prohibitively expensive, and corners are cut to reach conclusions. We model the whole benchmarking process, revealing that variance due to data sampling, parameter initialization and hyperparameter choice impact markedly the results. We analyze the predominant comparison methods used today in the light of this variance. We show a counter-intuitive result that adding more sources of variation to an imperfect estimator approaches better the ideal estimator at a 51 times reduction in compute cost. Building on these results, we study the error rate of detecting improvements, on five different deep-learning tasks/architectures. This study leads us to propose recommendations for performance comparisons.",
        "link": "https://www.semanticscholar.org/paper/9ceae85a0bd4231cd2efe14884c40b7bc04d3dac",
        "published": "2021-03-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_254.txt",
        "pdf_path": null
    },
    {
        "title": "Software Engineering for Machine Learning: A Case Study",
        "abstract": "Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components - models may be \"entangled\" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.",
        "link": "https://www.semanticscholar.org/paper/f70b2f20be241f445a61f33c4b8e76e554760340",
        "published": "2019-05-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_255.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in Medicine",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/2346d121f38fc19c77e0b062415519843f478163",
        "published": "2015-11-17",
        "pdf_url": "https://europepmc.org/articles/pmc5831252?pdf=render",
        "txt_path": "data/txt/machine learning_paper_256.txt",
        "pdf_path": "data/pdfs/machine learning_paper_256.pdf"
    },
    {
        "title": "Quantum Machine Learning in Feature Hilbert Spaces.",
        "abstract": "A basic idea of quantum computing is surprisingly similar to that of kernel methods in machine learning, namely, to efficiently perform computations in an intractably large Hilbert space. In this Letter we explore some theoretical foundations of this link and show how it opens up a new avenue for the design of quantum machine learning algorithms. We interpret the process of encoding inputs in a quantum state as a nonlinear feature map that maps data to quantum Hilbert space. A quantum computer can now analyze the input data in this feature space. Based on this link, we discuss two approaches for building a quantum model for classification. In the first approach, the quantum device estimates inner products of quantum states to compute a classically intractable kernel. The kernel can be fed into any classical kernel method such as a support vector machine. In the second approach, we use a variational quantum circuit as a linear model that classifies data explicitly in Hilbert space. We illustrate these ideas with a feature map based on squeezing in a continuous-variable system, and visualize the working principle with two-dimensional minibenchmark datasets.",
        "link": "https://www.semanticscholar.org/paper/7e7eb0f93c9550d7336f4bbfad5fe89604295705",
        "published": "2018-03-19",
        "pdf_url": "https://arxiv.org/pdf/1803.07128",
        "txt_path": "data/txt/machine learning_paper_257.txt",
        "pdf_path": "data/pdfs/machine learning_paper_257.pdf"
    },
    {
        "title": "Introduction to Machine Learning with Python",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/e3c221ee33f9082d8d47a363ed763d62044b60f6",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_258.txt",
        "pdf_path": null
    },
    {
        "title": "How the machine ‘thinks’: Understanding opacity in machine learning algorithms",
        "abstract": "This article considers the issue of opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring. These mechanisms of classification all frequently rely on computational algorithms, and in many cases on machine learning algorithms to do this work. In this article, I draw a distinction between three forms of opacity: (1) opacity as intentional corporate or state secrecy, (2) opacity as technical illiteracy, and (3) an opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully. The analysis in this article gets inside the algorithms themselves. I cite existing literatures in computer science, known industry practices (as they are publicly presented), and do some testing and manipulation of code as a form of lightweight code audit. I argue that recognizing the distinct forms of opacity that may be coming into play in a given application is a key to determining which of a variety of technical and non-technical solutions could help to prevent harm.",
        "link": "https://www.semanticscholar.org/paper/98a0ea52ccc31bacbb59c2e26ece9f7389abb00f",
        "published": "2016-01-05",
        "pdf_url": "https://journals.sagepub.com/doi/pdf/10.1177/2053951715622512",
        "txt_path": "data/txt/machine learning_paper_259.txt",
        "pdf_path": null
    },
    {
        "title": "Effective Heart Disease Prediction Using Hybrid Machine Learning Techniques",
        "abstract": "Heart disease is one of the most significant causes of mortality in the world today. Prediction of cardiovascular disease is a critical challenge in the area of clinical data analysis. Machine learning (ML) has been shown to be effective in assisting in making decisions and predictions from the large quantity of data produced by the healthcare industry. We have also seen ML techniques being used in recent developments in different areas of the Internet of Things (IoT). Various studies give only a glimpse into predicting heart disease with ML techniques. In this paper, we propose a novel method that aims at finding significant features by applying machine learning techniques resulting in improving the accuracy in the prediction of cardiovascular disease. The prediction model is introduced with different combinations of features and several known classification techniques. We produce an enhanced performance level with an accuracy level of 88.7% through the prediction model for heart disease with the hybrid random forest with a linear model (HRFLM).",
        "link": "https://www.semanticscholar.org/paper/2bc3644ce4de7fce5812c1455e056649a47c1bbf",
        "published": "2019-06-19",
        "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08740989.pdf",
        "txt_path": "data/txt/machine learning_paper_260.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning with a Reject Option: A survey",
        "abstract": "Machine learning models always make a prediction, even when it is likely to be inaccurate. This behavior should be avoided in many decision support applications, where mistakes can have severe consequences. Albeit already studied in 1970, machine learning with rejection recently gained interest. This machine learning subfield enables machine learning models to abstain from making a prediction when likely to make a mistake. This survey aims to provide an overview on machine learning with rejection. We introduce the conditions leading to two types of rejection, ambiguity and novelty rejection, which we carefully formalize. Moreover, we review and categorize strategies to evaluate a model's predictive and rejective quality. Additionally, we define the existing architectures for models with rejection and describe the standard techniques for learning such models. Finally, we provide examples of relevant application domains and show how machine learning with rejection relates to other machine learning research areas.",
        "link": "https://www.semanticscholar.org/paper/24864a7f899718477c04ede9c0bea906c5dc2667",
        "published": "2021-07-23",
        "pdf_url": "https://arxiv.org/pdf/2107.11277",
        "txt_path": "data/txt/machine learning_paper_261.txt",
        "pdf_path": "data/pdfs/machine learning_paper_261.pdf"
    },
    {
        "title": "Feature selection in machine learning: A new perspective",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/f6d9106b0e169204a506eb1deec2b85e0f296e4a",
        "published": "2018-07-01",
        "pdf_url": "http://manuscript.elsevier.com/S0925231218302911/pdf/S0925231218302911.pdf",
        "txt_path": "data/txt/machine learning_paper_262.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning and algorithmic fairness in public and population health",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/d3992c3d89e5ec05e0a6c96c4956f2ff9f7da023",
        "published": "2021-07-29",
        "pdf_url": "https://www.nature.com/articles/s42256-021-00373-4.pdf",
        "txt_path": "data/txt/machine learning_paper_263.txt",
        "pdf_path": null
    },
    {
        "title": "A survey on machine learning for data fusion",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/cf15c1898c81594165d74de465605aa9f559c769",
        "published": "2020-05-01",
        "pdf_url": "https://research.aalto.fi/files/40174084/ELEC_Meng_Survey_on_Machine_InFFUS.pdf",
        "txt_path": "data/txt/machine learning_paper_264.txt",
        "pdf_path": null
    },
    {
        "title": "When Machine Learning Meets Privacy",
        "abstract": "The newly emerged machine learning (e.g., deep learning) methods have become a strong driving force to revolutionize a wide range of industries, such as smart healthcare, financial technology, and surveillance systems. Meanwhile, privacy has emerged as a big concern in this machine learning-based artificial intelligence era. It is important to note that the problem of privacy preservation in the context of machine learning is quite different from that in traditional data privacy protection, as machine learning can act as both friend and foe. Currently, the work on the preservation of privacy and machine learning are still in an infancy stage, as most existing solutions only focus on privacy problems during the machine learning process. Therefore, a comprehensive study on the privacy preservation problems and machine learning is required. This article surveys the state of the art in privacy issues and solutions for machine learning. The survey covers three categories of interactions between privacy and machine learning: (i) private machine learning, (ii) machine learning-aided privacy protection, and (iii) machine learning-based privacy attack and corresponding protection schemes. The current research progress in each category is reviewed and the key challenges are identified. Finally, based on our in-depth analysis of the area of privacy and machine learning, we point out future research directions in this field.",
        "link": "https://www.semanticscholar.org/paper/b293e4659e20815bcf0b6d31ce46b8bd9437c1fa",
        "published": "2020-11-24",
        "pdf_url": "https://opus.lib.uts.edu.au/bitstream/10453/146941/2/Privacy_and_machine_learning_survey_accepted%20version.pdf",
        "txt_path": "data/txt/machine learning_paper_265.txt",
        "pdf_path": "data/pdfs/machine learning_paper_265.pdf"
    },
    {
        "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
        "abstract": "Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks.",
        "link": "https://www.semanticscholar.org/paper/3c8a456509e6c0805354bd40a35e3f2dbf8069b1",
        "published": "2019-12-03",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_266.txt",
        "pdf_path": null
    },
    {
        "title": "Efficient and Robust Automated Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/775a4e375cc79b53b94e37fa3eedff481823e4a6",
        "published": "2015-12-07",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_267.txt",
        "pdf_path": null
    },
    {
        "title": "Data Mining Practical Machine Learning Tools And Techniques With Java Implementations",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/528ecb0f88a9ea6110ba309b98cc2f0678f257c9",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_268.txt",
        "pdf_path": null
    },
    {
        "title": "Statistical Learning Theory",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/4c75b748911ddcd888c5122f7672f69caa5d661f",
        "published": "2021-10-31",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_269.txt",
        "pdf_path": null
    },
    {
        "title": "Supervised Machine Learning: A Brief Primer.",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/df0e4a76513636a05f0530e55ffe4991e4957478",
        "published": "2020-05-16",
        "pdf_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7431677",
        "txt_path": "data/txt/machine learning_paper_270.txt",
        "pdf_path": null
    },
    {
        "title": "Comparing different supervised machine learning algorithms for disease prediction",
        "abstract": "BackgroundSupervised machine learning algorithms have been a dominant method in the data mining field. Disease prediction using health data has recently shown a potential application area for these methods. This study ai7ms to identify the key trends among different types of supervised machine learning algorithms, and their performance and usage for disease risk prediction.MethodsIn this study, extensive research efforts were made to identify those studies that applied more than one supervised machine learning algorithm on single disease prediction. Two databases (i.e., Scopus and PubMed) were searched for different types of search items. Thus, we selected 48 articles in total for the comparison among variants supervised machine learning algorithms for disease prediction.ResultsWe found that the Support Vector Machine (SVM) algorithm is applied most frequently (in 29 studies) followed by the Naïve Bayes algorithm (in 23 studies). However, the Random Forest (RF) algorithm showed superior accuracy comparatively. Of the 17 studies where it was applied, RF showed the highest accuracy in 9 of them, i.e., 53%. This was followed by SVM which topped in 41% of the studies it was considered.ConclusionThis study provides a wide overview of the relative performance of different variants of supervised machine learning algorithms for disease prediction. This important information of relative performance can be used to aid researchers in the selection of an appropriate supervised machine learning algorithm for their studies.",
        "link": "https://www.semanticscholar.org/paper/c8ac6060d34179871b81ecd19621c63360347f8e",
        "published": "2019-12-01",
        "pdf_url": "https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/s12911-019-1004-8",
        "txt_path": "data/txt/machine learning_paper_271.txt",
        "pdf_path": "data/pdfs/machine learning_paper_271.pdf"
    },
    {
        "title": "ABY3: A Mixed Protocol Framework for Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/61306b52c2d292928f7cbb2f2ef5711d15a2566c",
        "published": "2018-10-08",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_272.txt",
        "pdf_path": null
    },
    {
        "title": "A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/d7d9107de19eba8228bc599f53f013245760caee",
        "published": "2017-04-13",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_273.txt",
        "pdf_path": null
    },
    {
        "title": "Parameterized quantum circuits as machine learning models",
        "abstract": "Hybrid quantum–classical systems make it possible to utilize existing quantum computers to their fullest extent. Within this framework, parameterized quantum circuits can be regarded as machine learning models with remarkable expressive power. This Review presents the components of these models and discusses their application to a variety of data-driven tasks, such as supervised learning and generative modeling. With an increasing number of experimental demonstrations carried out on actual quantum hardware and with software being actively developed, this rapidly growing field is poised to have a broad spectrum of real-world applications.",
        "link": "https://www.semanticscholar.org/paper/638e41912f314c74436205aa8d332dca963ab1dc",
        "published": "2019-06-18",
        "pdf_url": "https://iopscience.iop.org/article/10.1088/2058-9565/ab4eb5/pdf",
        "txt_path": "data/txt/machine learning_paper_274.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning on Graphs: A Model and Comprehensive Taxonomy",
        "abstract": "There has been a surge of recent interest in learning representations for graph-structured data. Graph representation learning methods have generally fallen into three main categories, based on the availability of labeled data. The first, network embedding (such as shallow graph embedding or graph auto-encoders), focuses on learning unsupervised representations of relational structure. The second, graph regularized neural networks, leverages graphs to augment neural network losses with a regularization objective for semi-supervised learning. The third, graph neural networks, aims to learn differentiable functions over discrete topologies with arbitrary structure. However, despite the popularity of these areas there has been surprisingly little work on unifying the three paradigms. Here, we aim to bridge the gap between graph neural networks, network embedding and graph regularization models. We propose a comprehensive taxonomy of representation learning methods for graph-structured data, aiming to unify several disparate bodies of work. Specifically, we propose a Graph Encoder Decoder Model (GRAPHEDM), which generalizes popular algorithms for semi-supervised learning on graphs (e.g. GraphSage, Graph Convolutional Networks, Graph Attention Networks), and unsupervised learning of graph representations (e.g. DeepWalk, node2vec, etc) into a single consistent approach. To illustrate the generality of this approach, we fit over thirty existing methods into this framework. We believe that this unifying view both provides a solid foundation for understanding the intuition behind these methods, and enables future research in the area.",
        "link": "https://www.semanticscholar.org/paper/83e89d56d0d0e1dfd8b52213e6cc2e191aaaf34b",
        "published": "2020-05-07",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_275.txt",
        "pdf_path": null
    },
    {
        "title": "Quantifying the Carbon Emissions of Machine Learning",
        "abstract": "From an environmental standpoint, there are a few crucial aspects of training a neural network that have a major impact on the quantity of carbon that it emits. These factors include: the location of the server used for training and the energy grid that it uses, the length of the training procedure, and even the make and model of hardware on which the training takes place. In order to approximate these emissions, we present our Machine Learning Emissions Calculator, a tool for our community to better understand the environmental impact of training ML models. We accompany this tool with an explanation of the factors cited above, as well as concrete actions that individual practitioners and organizations can take to mitigate their carbon emissions.",
        "link": "https://www.semanticscholar.org/paper/b3ea2d9c8e5ea3b87ace121f0bece71565abc187",
        "published": "2019-10-21",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_276.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Testing: Survey, Landscapes and Horizons",
        "abstract": "This paper provides a comprehensive survey of techniques for testing machine learning systems; Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing.",
        "link": "https://www.semanticscholar.org/paper/218062f45c15f39bc8f4fb2c930ddf20b5809b11",
        "published": "2019-06-19",
        "pdf_url": "https://arxiv.org/pdf/1906.10742",
        "txt_path": "data/txt/machine learning_paper_277.txt",
        "pdf_path": "data/pdfs/machine learning_paper_277.pdf"
    },
    {
        "title": "Machine learning and applications in ultrafast photonics",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/e8aa24d9c64f1215a97e8118905fad0189a53b97",
        "published": "2020-11-30",
        "pdf_url": "https://publications.aston.ac.uk/id/eprint/42145/1/20404_3_art_file_208064_qgnykn.pdf",
        "txt_path": "data/txt/machine learning_paper_278.txt",
        "pdf_path": "data/pdfs/machine learning_paper_278.pdf"
    },
    {
        "title": "A few useful things to know about machine learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/1696cbf7da0ee845c50591843993e6605adec177",
        "published": "2012-10-01",
        "pdf_url": "http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf",
        "txt_path": "data/txt/machine learning_paper_279.txt",
        "pdf_path": "data/pdfs/machine learning_paper_279.pdf"
    },
    {
        "title": "Certified Data Removal from Machine Learning Models",
        "abstract": "Good data stewardship requires removal of data at the request of the data's owner. This raises the question if and how a trained machine-learning model, which implicitly stores information about its training data, should be affected by such a removal request. Is it possible to \"remove\" data from a machine-learning model? We study this problem by defining certified removal: a very strong theoretical guarantee that a model from which data is removed cannot be distinguished from a model that never observed the data to begin with. We develop a certified-removal mechanism for linear classifiers and empirically study learning settings in which this mechanism is practical.",
        "link": "https://www.semanticscholar.org/paper/2bac6b71d252f93c4841e325ca111f2752109931",
        "published": "2019-11-08",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_280.txt",
        "pdf_path": null
    },
    {
        "title": "AutoML-Zero: Evolving Machine Learning Algorithms From Scratch",
        "abstract": "Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.",
        "link": "https://www.semanticscholar.org/paper/6bf623e772d5634e33a035a3586dbab41e29c78b",
        "published": "2020-03-06",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_281.txt",
        "pdf_path": null
    },
    {
        "title": "A Review of Android Malware Detection Approaches Based on Machine Learning",
        "abstract": "Android applications are developing rapidly across the mobile ecosystem, but Android malware is also emerging in an endless stream. Many researchers have studied the problem of Android malware detection and have put forward theories and methods from different perspectives. Existing research suggests that machine learning is an effective and promising way to detect Android malware. Notwithstanding, there exist reviews that have surveyed different issues related to Android malware detection based on machine learning. We believe our work complements the previous reviews by surveying a wider range of aspects of the topic. This paper presents a comprehensive survey of Android malware detection approaches based on machine learning. We briefly introduce some background on Android applications, including the Android system architecture, security mechanisms, and classification of Android malware. Then, taking machine learning as the focus, we analyze and summarize the research status from key perspectives such as sample acquisition, data preprocessing, feature selection, machine learning models, algorithms, and the evaluation of detection effectiveness. Finally, we assess the future prospects for research into Android malware detection based on machine learning. This review will help academics gain a full picture of Android malware detection based on machine learning. It could then serve as a basis for subsequent researchers to start new work and help to guide research in the field more generally.",
        "link": "https://www.semanticscholar.org/paper/4eabb5b4cf137c27917a8b91c471a6a2b9407469",
        "published": "2020-07-01",
        "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/8948470/09130686.pdf",
        "txt_path": "data/txt/machine learning_paper_282.txt",
        "pdf_path": null
    },
    {
        "title": "DeltaGrad: Rapid retraining of machine learning models",
        "abstract": "Machine learning models are not static and may need to be retrained on slightly changed datasets, for instance, with the addition or deletion of a set of data points. This has many applications, including privacy, robustness, bias reduction, and uncertainty quantifcation. However, it is expensive to retrain models from scratch. To address this problem, we propose the DeltaGrad algorithm for rapid retraining machine learning models based on information cached during the training phase. We provide both theoretical and empirical support for the effectiveness of DeltaGrad, and show that it compares favorably to the state of the art.",
        "link": "https://www.semanticscholar.org/paper/bd9ecc05a12563445a2ef4fe758a39d7f2bcda0d",
        "published": "2020-06-26",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_283.txt",
        "pdf_path": null
    },
    {
        "title": "River: machine learning for streaming data in Python",
        "abstract": "River is a machine learning library for dynamic data streams and continual learning. It provides multiple state-of-the-art learning methods, data generators/transformers, performance metrics and evaluators for different stream learning problems. It is the result from the merger of the two most popular packages for stream learning in Python: Creme and scikit-multiflow. River introduces a revamped architecture based on the lessons learnt from the seminal packages. River's ambition is to be the go-to library for doing machine learning on streaming data. Additionally, this open source package brings under the same umbrella a large community of practitioners and researchers. The source code is available at https://github.com/online-ml/river.",
        "link": "https://www.semanticscholar.org/paper/e7924a71ff89f37f66298a6b42bcd26fa7c0f33b",
        "published": "2020-12-08",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_284.txt",
        "pdf_path": null
    },
    {
        "title": "Towards CRISP-ML(Q): A Machine Learning Process Model with Quality Assurance Methodology",
        "abstract": "Machine learning is an established and frequently used technique in industry and academia, but a standard process model to improve success and efficiency of machine learning applications is still missing. Project organizations and machine learning practitioners face manifold challenges and risks when developing machine learning applications and have a need for guidance to meet business expectations. This paper therefore proposes a process model for the development of machine learning applications, covering six phases from defining the scope to maintaining the deployed machine learning application. Business and data understanding are executed simultaneously in the first phase, as both have considerable impact on the feasibility of the project. The next phases are comprised of data preparation, modeling, evaluation, and deployment. Special focus is applied to the last phase, as a model running in changing real-time environments requires close monitoring and maintenance to reduce the risk of performance degradation over time. With each task of the process, this work proposes quality assurance methodology that is suitable to address challenges in machine learning development that are identified in the form of risks. The methodology is drawn from practical experience and scientific literature, and has proven to be general and stable. The process model expands on CRISP-DM, a data mining process model that enjoys strong industry support, but fails to address machine learning specific tasks. The presented work proposes an industry- and application-neutral process model tailored for machine learning applications with a focus on technical tasks for quality assurance.",
        "link": "https://www.semanticscholar.org/paper/3fc9cff6ad55986de180204b98613af42f8ac37d",
        "published": "2020-03-11",
        "pdf_url": "https://www.mdpi.com/2504-4990/3/2/20/pdf?version=1619340878",
        "txt_path": "data/txt/machine learning_paper_285.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning: An Applied Econometric Approach",
        "abstract": "Machines are increasingly doing “intelligent” things. Face recognition algorithms use a large dataset of photos labeled as having a face or not to estimate a function that predicts the presence y of a face from pixels x. This similarity to econometrics raises questions: How do these new empirical tools fit with what we know? As empirical economists, how can we use them? We present a way of thinking about machine learning that gives it its own place in the econometric toolbox. Machine learning not only provides new tools, it solves a different problem. Specifically, machine learning revolves around the problem of prediction, while many economic applications revolve around parameter estimation. So applying machine learning to economics requires finding relevant tasks. Machine learning algorithms are now technically easy to use: you can download convenient packages in R or Python. This also raises the risk that the algorithms are applied naively or their output is misinterpreted. We hope to make them conceptually easier to use by providing a crisper understanding of how these algorithms work, where they excel, and where they can stumble—and thus where they can be most usefully applied.",
        "link": "https://www.semanticscholar.org/paper/9d75cc322a4e06d0a3a868cb91b04219a289c12c",
        "published": "2017-05-01",
        "pdf_url": "https://www.aeaweb.org/articles/pdf/doi/10.1257/jep.31.2.87",
        "txt_path": "data/txt/machine learning_paper_286.txt",
        "pdf_path": null
    },
    {
        "title": "Choosing Prediction Over Explanation in Psychology: Lessons From Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/7c63a6e6d3b31b14ae4236bfbd574ea37cab18a7",
        "published": "2017-08-25",
        "pdf_url": "https://europepmc.org/articles/pmc6603289?pdf=render",
        "txt_path": "data/txt/machine learning_paper_287.txt",
        "pdf_path": "data/pdfs/machine learning_paper_287.pdf"
    },
    {
        "title": "Evaluating Differentially Private Machine Learning in Practice",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/8f8542a6aa8c76e8a4441d1ca722e230aa5d6c9e",
        "published": "2019-02-24",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_288.txt",
        "pdf_path": null
    },
    {
        "title": "InterpretML: A Unified Framework for Machine Learning Interpretability",
        "abstract": "InterpretML is an open-source Python package which exposes machine learning interpretability algorithms to practitioners and researchers. InterpretML exposes two types of interpretability - glassbox models, which are machine learning models designed for interpretability (ex: linear models, rule lists, generalized additive models), and blackbox explainability techniques for explaining existing systems (ex: Partial Dependence, LIME). The package enables practitioners to easily compare interpretability algorithms by exposing multiple methods under a unified API, and by having a built-in, extensible visualization platform. InterpretML also includes the first implementation of the Explainable Boosting Machine, a powerful, interpretable, glassbox model that can be as accurate as many blackbox models. The MIT licensed source code can be downloaded from github.com/microsoft/interpret.",
        "link": "https://www.semanticscholar.org/paper/60baa46784e8e9a30a57e1875907d008fbdc817b",
        "published": "2019-09-19",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_289.txt",
        "pdf_path": null
    },
    {
        "title": "Plans and Situated Actions: The Problem of Human-Machine Communication (Learning in Doing: Social,",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/5416463537f8c6be1199951b4fd6f8d5dae14920",
        "published": "1987-12-15",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_290.txt",
        "pdf_path": null
    },
    {
        "title": "The Non-IID Data Quagmire of Decentralized Machine Learning",
        "abstract": "Many large-scale machine learning (ML) applications need to perform decentralized learning over datasets generated at different devices and locations. Such datasets pose a significant challenge to decentralized learning because their different contexts result in significant data distribution skew across devices/locations. In this paper, we take a step toward better understanding this challenge by presenting a detailed experimental study of decentralized DNN training on a common type of data skew: skewed distribution of data labels across devices/locations. Our study shows that: (i) skewed data labels are a fundamental and pervasive problem for decentralized learning, causing significant accuracy loss across many ML applications, DNN models, training datasets, and decentralized learning algorithms; (ii) the problem is particularly challenging for DNN models with batch normalization; and (iii) the degree of data skew is a key determinant of the difficulty of the problem. Based on these findings, we present SkewScout, a system-level approach that adapts the communication frequency of decentralized learning algorithms to the (skew-induced) accuracy loss between data partitions. We also show that group normalization can recover much of the accuracy loss of batch normalization.",
        "link": "https://www.semanticscholar.org/paper/206261db1196e4e391ca42077f6fca6b3ece34d0",
        "published": "2019-10-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_291.txt",
        "pdf_path": null
    },
    {
        "title": "Combining satellite imagery and machine learning to predict poverty",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/4f975da00a5b2a2f7236e34edcb7274e5fdab937",
        "published": "2016-08-19",
        "pdf_url": "https://science.sciencemag.org/content/sci/353/6301/790.full.pdf",
        "txt_path": "data/txt/machine learning_paper_292.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Methods in Drug Discovery",
        "abstract": "The advancements of information technology and related processing techniques have created a fertile base for progress in many scientific fields and industries. In the fields of drug discovery and development, machine learning techniques have been used for the development of novel drug candidates. The methods for designing drug targets and novel drug discovery now routinely combine machine learning and deep learning algorithms to enhance the efficiency, efficacy, and quality of developed outputs. The generation and incorporation of big data, through technologies such as high-throughput screening and high through-put computational analysis of databases used for both lead and target discovery, has increased the reliability of the machine learning and deep learning incorporated techniques. The use of these virtual screening and encompassing online information has also been highlighted in developing lead synthesis pathways. In this review, machine learning and deep learning algorithms utilized in drug discovery and associated techniques will be discussed. The applications that produce promising results and methods will be reviewed.",
        "link": "https://www.semanticscholar.org/paper/4ec953de1331fe5f720320c9f2f82884b2512701",
        "published": "2020-11-01",
        "pdf_url": "https://www.mdpi.com/1420-3049/25/22/5277/pdf?version=1605176714",
        "txt_path": "data/txt/machine learning_paper_293.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning algorithm validation with a limited sample size",
        "abstract": "Advances in neuroimaging, genomic, motion tracking, eye-tracking and many other technology-based data collection methods have led to a torrent of high dimensional datasets, which commonly have a small number of samples because of the intrinsic high cost of data collection involving human participants. High dimensional data with a small number of samples is of critical importance for identifying biomarkers and conducting feasibility and pilot work, however it can lead to biased machine learning (ML) performance estimates. Our review of studies which have applied ML to predict autistic from non-autistic individuals showed that small sample size is associated with higher reported classification accuracy. Thus, we have investigated whether this bias could be caused by the use of validation methods which do not sufficiently control overfitting. Our simulations show that K-fold Cross-Validation (CV) produces strongly biased performance estimates with small sample sizes, and the bias is still evident with sample size of 1000. Nested CV and train/test split approaches produce robust and unbiased performance estimates regardless of sample size. We also show that feature selection if performed on pooled training and testing data is contributing to bias considerably more than parameter tuning. In addition, the contribution to bias by data dimensionality, hyper-parameter space and number of CV folds was explored, and validation methods were compared with discriminable data. The results suggest how to design robust testing methodologies when working with small datasets and how to interpret the results of other studies based on what validation method was used.",
        "link": "https://www.semanticscholar.org/paper/fbf9812f29156024ec693b4633a21303eead309d",
        "published": "2019-11-07",
        "pdf_url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0224365&type=printable",
        "txt_path": "data/txt/machine learning_paper_294.txt",
        "pdf_path": "data/pdfs/machine learning_paper_294.pdf"
    },
    {
        "title": "Machine learning in medicine: a practical introduction",
        "abstract": "BackgroundFollowing visible successes on a wide range of predictive tasks, machine learning techniques are attracting substantial interest from medical researchers and clinicians. We address the need for capacity development in this area by providing a conceptual introduction to machine learning alongside a practical guide to developing and evaluating predictive algorithms using freely-available open source software and public domain data.MethodsWe demonstrate the use of machine learning techniques by developing three predictive models for cancer diagnosis using descriptions of nuclei sampled from breast masses. These algorithms include regularized General Linear Model regression (GLMs), Support Vector Machines (SVMs) with a radial basis function kernel, and single-layer Artificial Neural Networks. The publicly-available dataset describing the breast mass samples (N=683) was randomly split into evaluation (n=456) and validation (n=227) samples.We trained algorithms on data from the evaluation sample before they were used to predict the diagnostic outcome in the validation dataset. We compared the predictions made on the validation datasets with the real-world diagnostic decisions to calculate the accuracy, sensitivity, and specificity of the three models. We explored the use of averaging and voting ensembles to improve predictive performance. We provide a step-by-step guide to developing algorithms using the open-source R statistical programming environment.ResultsThe trained algorithms were able to classify cell nuclei with high accuracy (.94 -.96), sensitivity (.97 -.99), and specificity (.85 -.94). Maximum accuracy (.96) and area under the curve (.97) was achieved using the SVM algorithm. Prediction performance increased marginally (accuracy =.97, sensitivity =.99, specificity =.95) when algorithms were arranged into a voting ensemble.ConclusionsWe use a straightforward example to demonstrate the theory and practice of machine learning for clinicians and medical researchers. The principals which we demonstrate here can be readily applied to other complex tasks including natural language processing and image recognition.",
        "link": "https://www.semanticscholar.org/paper/5d093bd376ba63495ea442241bc8bc2f0ff30c2b",
        "published": "2019-03-19",
        "pdf_url": "https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-019-0681-4",
        "txt_path": "data/txt/machine learning_paper_295.txt",
        "pdf_path": "data/pdfs/machine learning_paper_295.pdf"
    },
    {
        "title": "A Survey of Deep Learning and Its Applications: A New Paradigm to Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/e67121cd31e95fba6c892724e619323ad7564b03",
        "published": "2019-06-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_296.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": "W ith recent advances in machine learning technology, data-driven research is beginning to permeate natural science and engineering fields. Synchrotron radiation science is also expected to benefit significantly from machine learning. The progress of these studies will make it possible to observe materials that could not be observed in the past or to perform synchrotron radiation measurements and detailed data analysis much more efficiently than before, leading to more effective use of limited beamtime. In addition, machine learning has the potential to bring about advanced and more efficient research through software without the need for major hardware upgrades at synchrotron radiation facilities. The encounter between machine learning and materials science has opened up a new academic field called materials informatics. Especially in the last decades, the progress has been remarkable, and the concept of informatics has been incorporated into all areas of materials science, from material design and material synthesis to measurement and analysis. The rise of materials informatics was due to advances in information science in terms of both hardware and software; namely, the dramatic development of computing power and artificial intelligence technologies such as machine learning, which have made it possible to handle large volumes of complex data that were difficult to handle in the past. In addition, it is now possible to extract useful information and new knowledge from the data, bringing about changes in various fields. Furthermore, machine learning technology has become much easier than in the past, thanks not only to simple programming languages such as Python but also to open source platforms on which an ecosystem for data analysis has been built. Taking synchrotron radiation experiments as an example, the measurement space to be explored in experiments is extremely wide. In order to extract knowledge from complex data analysis, it is necessary to efficiently search a high-dimensional search space consisting of an enormous number of parameters to find the optimal solution. Parameter search in such a highdimensional space, which skilled experts conventionally conduct based on tacit knowledge such as intuition and experience, poses problems such as bottlenecks to automation, human bias, and poor reproducibility, and requires a new research methodology that will fundamentally change conventional research methods. The wide range of new developments in the combination of synchrotron radiation and machine learning discussed in this special issue will extend synchrotron radiation experiments to more advanced measurements, bring about more efficient and automated synchrotron radiation experiments, and increase the amount of information obtained from these experiments. We hope these efforts will contribute significantly to further developing and revitalizing the synchrotron radiation community and opening up new research fields. n Kanta Ono Guest Editor Osaka University, Osaka, Japan ono@ap.eng.osaka-u.ac.jp Synchrotron Radiation News ISSN 0894-0886 is published bi-monthly. Coden Code: SRN EFR",
        "link": "https://www.semanticscholar.org/paper/28e488cc9c0008fb95f7d36edafcbbc9d62ab0dc",
        "published": "2022-07-04",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_297.txt",
        "pdf_path": null
    },
    {
        "title": "Coresets for Data-efficient Training of Machine Learning Models",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/790985a4bee821046992ff3d5322ff11dd1b4262",
        "published": "2019-06-05",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_298.txt",
        "pdf_path": null
    },
    {
        "title": "Monte Carlo Gradient Estimation in Machine Learning",
        "abstract": "This paper is a broad and accessible survey of the methods we have at our disposal for Monte Carlo gradient estimation in machine learning and across the statistical sciences: the problem of computing the gradient of an expectation of a function with respect to parameters defining the distribution that is integrated; the problem of sensitivity analysis. In machine learning research, this gradient problem lies at the core of many learning problems, in supervised, unsupervised and reinforcement learning. We will generally seek to rewrite such gradients in a form that allows for Monte Carlo estimation, allowing them to be easily and efficiently used and analysed. We explore three strategies--the pathwise, score function, and measure-valued gradient estimators--exploring their historical developments, derivation, and underlying assumptions. We describe their use in other fields, show how they are related and can be combined, and expand on their possible generalisations. Wherever Monte Carlo gradient estimators have been derived and deployed in the past, important advances have followed. A deeper and more widely-held understanding of this problem will lead to further advances, and it is these advances that we wish to support.",
        "link": "https://www.semanticscholar.org/paper/c7b08c2e69a338e8d0c8444ce081b51caa50b273",
        "published": "2019-06-25",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_299.txt",
        "pdf_path": null
    },
    {
        "title": "An Introduction to Machine Learning",
        "abstract": "In the last few years, machine learning (ML) and artificial intelligence have seen a new wave of publicity fueled by the huge and ever‐increasing amount of data and computational power as well as the discovery of improved learning algorithms. However, the idea of a computer learning some abstract concept from data and applying them to yet unseen situations is not new and has been around at least since the 1950s. Many of these basic principles are very familiar to the pharmacometrics and clinical pharmacology community. In this paper, we want to introduce the foundational ideas of ML to this community such that readers obtain the essential tools they need to understand publications on the topic. Although we will not go into the very details and theoretical background, we aim to point readers to relevant literature and put applications of ML in molecular biology as well as the fields of pharmacometrics and clinical pharmacology into perspective.",
        "link": "https://www.semanticscholar.org/paper/86713aa23ad99039ba76a670797df40ad65a64b2",
        "published": "2020-03-03",
        "pdf_url": "https://ascpt.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cpt.1796",
        "txt_path": "data/txt/machine learning_paper_300.txt",
        "pdf_path": null
    },
    {
        "title": "Tackling Climate Change with Machine Learning",
        "abstract": "Climate change is one of the greatest challenges facing humanity, and we, as machine learning (ML) experts, may wonder how we can help. Here we describe how ML can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by ML, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the ML community to join the global effort against climate change.",
        "link": "https://www.semanticscholar.org/paper/998039a4876edc440e0cabb0bc42239b0eb29644",
        "published": "2019-06-10",
        "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3485128",
        "txt_path": "data/txt/machine learning_paper_301.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning for active matter",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/9909975dec989fcd55d99533c712c28bab99040e",
        "published": "2020-02-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_302.txt",
        "pdf_path": null
    },
    {
        "title": "Informed Machine Learning – A Taxonomy and Survey of Integrating Prior Knowledge into Learning Systems",
        "abstract": "Despite its great success, machine learning can have its limits when dealing with insufficient training data. A potential solution is the additional integration of prior knowledge into the training process which leads to the notion of informed machine learning. In this paper, we present a structured overview of various approaches in this field. We provide a definition and propose a concept for informed machine learning which illustrates its building blocks and distinguishes it from conventional machine learning. We introduce a taxonomy that serves as a classification framework for informed machine learning approaches. It considers the source of knowledge, its representation, and its integration into the machine learning pipeline. Based on this taxonomy, we survey related research and describe how different knowledge representations such as algebraic equations, logic rules, or simulation results can be used in learning systems. This evaluation of numerous papers on the basis of our taxonomy uncovers key methods in the field of informed machine learning.",
        "link": "https://www.semanticscholar.org/paper/2b49156cf855dbb39768ae0ba7d7cb9263d17e5c",
        "published": "2019-03-29",
        "pdf_url": "https://ieeexplore.ieee.org/ielx7/69/4358933/09429985.pdf",
        "txt_path": "data/txt/machine learning_paper_303.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Methods That Economists Should Know About",
        "abstract": "We discuss the relevance of the recent machine learning (ML) literature for economics and econometrics. First we discuss the differences in goals, methods, and settings between the ML literature and the traditional econometrics and statistics literatures. Then we discuss some specific methods from the ML literature that we view as important for empirical researchers in economics. These include supervised learning methods for regression and classification, unsupervised learning methods, and matrix completion methods. Finally, we highlight newly developed methods at the intersection of ML and econometrics that typically perform better than either off-the-shelf ML or more traditional econometric methods when applied to particular classes of problems, including causal inference for average treatment effects, optimal policy estimation, and estimation of the counterfactual effect of price changes in consumer choice models.",
        "link": "https://www.semanticscholar.org/paper/d75356e2bf674902a06a14bb55d18ee88af5b4bb",
        "published": "2019-03-24",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_304.txt",
        "pdf_path": null
    },
    {
        "title": "A Survey on Distributed Machine Learning",
        "abstract": "The demand for artificial intelligence has grown significantly over the past decade, and this growth has been fueled by advances in machine learning techniques and the ability to leverage hardware acceleration. However, to increase the quality of predictions and render machine learning solutions feasible for more complex applications, a substantial amount of training data is required. Although small machine learning models can be trained with modest amounts of data, the input for training larger models such as neural networks grows exponentially with the number of parameters. Since the demand for processing training data has outpaced the increase in computation power of computing machinery, there is a need for distributing the machine learning workload across multiple machines, and turning the centralized into a distributed system. These distributed systems present new challenges: first and foremost, the efficient parallelization of the training process and the creation of a coherent model. This article provides an extensive overview of the current state-of-the-art in the field by outlining the challenges and opportunities of distributed machine learning over conventional (centralized) machine learning, discussing the techniques used for distributed machine learning, and providing an overview of the systems that are available.",
        "link": "https://www.semanticscholar.org/paper/f9a855ae59579d16dca6a5133cd8daddd3305582",
        "published": "2019-12-20",
        "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3377454",
        "txt_path": "data/txt/machine learning_paper_305.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning and Deep Learning",
        "abstract": "Now-a-days artificial intelligence has become an asset for engineering and experimental studies, just like statistics and calculus. Data science is a growing field for researchers and artificial intelligence, machine learning and deep learning are roots of it. This paper describes the relation between these roots of data science. There is a need of machine learning if any kind of analysis is to be performed. This study describes machine learning from the scratch. It also focuses on Deep Learning. Deep learning can also be known as new trend of machine learning. This paper gives a light on basic architecture of Deep learning. A comparative study of machine learning and deep learning is also given in the paper and allows researcher to have a broad view on these techniques so that they can understand which one will be preferable solution for a particular problem.",
        "link": "https://www.semanticscholar.org/paper/7d291d5fca0e9cd9e0ed72fb6f82289a197f7f02",
        "published": "2019-10-10",
        "pdf_url": "https://doi.org/10.35940/ijitee.l3550.1081219",
        "txt_path": "data/txt/machine learning_paper_306.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning and Deep Learning Methods for Intrusion Detection Systems: A Survey",
        "abstract": "Networks play important roles in modern life, and cyber security has become a vital research area. An intrusion detection system (IDS) which is an important cyber security technique, monitors the state of software and hardware running in the network. Despite decades of development, existing IDSs still face challenges in improving the detection accuracy, reducing the false alarm rate and detecting unknown attacks. To solve the above problems, many researchers have focused on developing IDSs that capitalize on machine learning methods. Machine learning methods can automatically discover the essential differences between normal data and abnormal data with high accuracy. In addition, machine learning methods have strong generalizability, so they are also able to detect unknown attacks. Deep learning is a branch of machine learning, whose performance is remarkable and has become a research hotspot. This survey proposes a taxonomy of IDS that takes data objects as the main dimension to classify and summarize machine learning-based and deep learning-based IDS literature. We believe that this type of taxonomy framework is fit for cyber security researchers. The survey first clarifies the concept and taxonomy of IDSs. Then, the machine learning algorithms frequently used in IDSs, metrics, and benchmark datasets are introduced. Next, combined with the representative literature, we take the proposed taxonomic system as a baseline and explain how to solve key IDS issues with machine learning and deep learning techniques. Finally, challenges and future developments are discussed by reviewing recent representative studies.",
        "link": "https://www.semanticscholar.org/paper/236dfdeb4511754cf71ba220ac569b11973502cd",
        "published": "2019-10-17",
        "pdf_url": "https://www.mdpi.com/2076-3417/9/20/4396/pdf?version=1571308126",
        "txt_path": "data/txt/machine learning_paper_307.txt",
        "pdf_path": null
    },
    {
        "title": "Adversarial attacks on medical machine learning",
        "abstract": "Emerging vulnerabilities demand new conversations With public and academic attention increasingly focused on the new role of machine learning in the health information economy, an unusual and no-longer-esoteric category of vulnerabilities in machine-learning systems could prove important. These vulnerabilities allow a small, carefully designed change in how inputs are presented to a system to completely alter its output, causing it to confidently arrive at manifestly wrong conclusions. These advanced techniques to subvert otherwise-reliable machine-learning systems—so-called adversarial attacks—have, to date, been of interest primarily to computer science researchers (1). However, the landscape of often-competing interests within health care, and billions of dollars at stake in systems' outputs, implies considerable problems. We outline motivations that various players in the health care system may have to use adversarial attacks and begin a discussion of what to do about them. Far from discouraging continued innovation with medical machine learning, we call for active engagement of medical, technical, legal, and ethical experts in pursuit of efficient, broadly available, and effective health care that machine learning will enable.",
        "link": "https://www.semanticscholar.org/paper/e718828e8f776d9f80daa3f8e0af6895f5d34c44",
        "published": "2019-03-21",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_308.txt",
        "pdf_path": null
    },
    {
        "title": "Explainable machine learning in deployment",
        "abstract": "Explainable machine learning offers the potential to provide stakeholders with insights into model behavior by using various methods such as feature importance scores, counterfactual explanations, or influential training data. Yet there is little understanding of how organizations use these methods in practice. This study explores how organizations view and use explainability for stakeholder consumption. We find that, currently, the majority of deployments are not for end users affected by the model but rather for machine learning engineers, who use explainability to debug the model itself. There is thus a gap between explainability in practice and the goal of transparency, since explanations primarily serve internal stakeholders rather than external ones. Our study synthesizes the limitations of current explainability techniques that hamper their use for end users. To facilitate end user interaction, we develop a framework for establishing clear goals for explainability. We end by discussing concerns raised regarding explainability.",
        "link": "https://www.semanticscholar.org/paper/4490ffac416692ab827c5a30e5f3a4b4fd6be949",
        "published": "2019-09-13",
        "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3351095.3375624",
        "txt_path": "data/txt/machine learning_paper_309.txt",
        "pdf_path": null
    },
    {
        "title": "A Quick Review of Machine Learning Algorithms",
        "abstract": "Machine learning is predominantly an area of Artificial Intelligence which has been a key component of digitalization solutions that has caught major attention in the digital arena. In this paper author intends to do a brief review of various machine learning algorithms which are most frequently used and therefore are the most popular ones. The author intends to highlight the merits and demerits of the machine learning algorithms from their application perspective to aid in an informed decision making towards selecting the appropriate learning algorithm to meet the specific requirement of the application.",
        "link": "https://www.semanticscholar.org/paper/8db8166249dfb94dd8d52f88d27917b5755ae049",
        "published": "2019-02-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_310.txt",
        "pdf_path": null
    },
    {
        "title": "A Survey of Machine Learning Techniques Applied to Software Defined Networking (SDN): Research Issues and Challenges",
        "abstract": "In recent years, with the rapid development of current Internet and mobile communication technologies, the infrastructure, devices and resources in networking systems are becoming more complex and heterogeneous. In order to efficiently organize, manage, maintain and optimize networking systems, more intelligence needs to be deployed. However, due to the inherently distributed feature of traditional networks, machine learning techniques are hard to be applied and deployed to control and operate networks. Software defined networking (SDN) brings us new chances to provide intelligence inside the networks. The capabilities of SDN (e.g., logically centralized control, global view of the network, software-based traffic analysis, and dynamic updating of forwarding rules) make it easier to apply machine learning techniques. In this paper, we provide a comprehensive survey on the literature involving machine learning algorithms applied to SDN. First, the related works and background knowledge are introduced. Then, we present an overview of machine learning algorithms. In addition, we review how machine learning algorithms are applied in the realm of SDN, from the perspective of traffic classification, routing optimization, quality of service/quality of experience prediction, resource management and security. Finally, challenges and broader perspectives are discussed.",
        "link": "https://www.semanticscholar.org/paper/a42e380e1b8aafecb3b1e338a8a9a579c6a5a40f",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_311.txt",
        "pdf_path": null
    },
    {
        "title": "Causality for Machine Learning",
        "abstract": "Graphical causal inference as pioneered by Judea Pearl arose from research on artificial intelligence (AI), and for a long time had little connection to the field of machine learning. \nThis article discusses where links have been and should be established, introducing key concepts along the way. It argues that the hard open problems of machine learning and AI are intrinsically related to causality, and explains how the field is beginning to understand them.",
        "link": "https://www.semanticscholar.org/paper/b5461f9c5d65e87561e00848921ee797902dae14",
        "published": "2019-11-24",
        "pdf_url": "https://arxiv.org/pdf/1911.10500",
        "txt_path": "data/txt/machine learning_paper_312.txt",
        "pdf_path": "data/pdfs/machine learning_paper_312.pdf"
    },
    {
        "title": "What Clinicians Want: Contextualizing Explainable Machine Learning for Clinical End Use",
        "abstract": "Translating machine learning (ML) models effectively to clinical practice requires establishing clinicians' trust. Explainability, or the ability of an ML model to justify its outcomes and assist clinicians in rationalizing the model prediction, has been generally understood to be critical to establishing trust. However, the field suffers from the lack of concrete definitions for usable explanations in different settings. To identify specific aspects of explainability that may catalyze building trust in ML models, we surveyed clinicians from two distinct acute care specialties (Intenstive Care Unit and Emergency Department). We use their feedback to characterize when explainability helps to improve clinicians' trust in ML models. We further identify the classes of explanations that clinicians identified as most relevant and crucial for effective translation to clinical practice. Finally, we discern concrete metrics for rigorous evaluation of clinical explainability methods. By integrating perceptions of explainability between clinicians and ML researchers we hope to facilitate the endorsement and broader adoption and sustained use of ML systems in healthcare.",
        "link": "https://www.semanticscholar.org/paper/91ed985917cf4c317b7d91e15c1ec55e746153bf",
        "published": "2019-05-13",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_313.txt",
        "pdf_path": null
    },
    {
        "title": "A Performance and Cost Assessment of Machine Learning Interatomic Potentials.",
        "abstract": "Machine learning of the quantitative relationship between local environment descriptors and the potential energy surface of a system of atoms has emerged as a new frontier in the development of interatomic potentials (IAPs). Here, we present a comprehensive evaluation of ML-IAPs based on four local environment descriptors --- atom-centered symmetry functions (ACSF), smooth overlap of atomic positions (SOAP), the Spectral Neighbor Analysis Potential (SNAP) bispectrum components, and moment tensors --- using a diverse data set generated using high-throughput density functional theory (DFT) calculations. The data set comprising bcc (Li, Mo) and fcc (Cu, Ni) metals and diamond group IV semiconductors (Si, Ge) is chosen to span a range of crystal structures and bonding. All descriptors studied show excellent performance in predicting energies and forces far surpassing that of classical IAPs, as well as predicting properties such as elastic constants and phonon dispersion curves. We observe a general trade-off between accuracy and the degrees of freedom of each model, and consequently computational cost. We will discuss these trade-offs in the context of model selection for molecular dynamics and other applications.",
        "link": "https://www.semanticscholar.org/paper/60446c372811c25acc1e47b044e8e7458f0a4986",
        "published": "2019-06-20",
        "pdf_url": "https://arxiv.org/pdf/1906.08888",
        "txt_path": "data/txt/machine learning_paper_314.txt",
        "pdf_path": "data/pdfs/machine learning_paper_314.pdf"
    },
    {
        "title": "Explainable Machine Learning for Scientific Insights and Discoveries",
        "abstract": "Machine learning methods have been remarkably successful for a wide range of application areas in the extraction of essential information from data. An exciting and relatively recent development is the uptake of machine learning in the natural sciences, where the major goal is to obtain novel scientific insights and discoveries from observational or simulated data. A prerequisite for obtaining a scientific outcome is domain knowledge, which is needed to gain explainability, but also to enhance scientific consistency. In this article, we review explainable machine learning in view of applications in the natural sciences and discuss three core elements that we identified as relevant in this context: transparency, interpretability, and explainability. With respect to these core elements, we provide a survey of recent scientific works that incorporate machine learning and the way that explainable machine learning is used in combination with domain knowledge from the application areas.",
        "link": "https://www.semanticscholar.org/paper/4eca52f892f288c0b33b74aa4cfed56ed968fb4e",
        "published": "2019-05-22",
        "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/8948470/09007737.pdf",
        "txt_path": "data/txt/machine learning_paper_315.txt",
        "pdf_path": null
    },
    {
        "title": "Do no harm: a roadmap for responsible machine learning for health care",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/b0f8a829450e782fe879d9d48a188d611b6dd74d",
        "published": "2019-08-19",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_316.txt",
        "pdf_path": null
    },
    {
        "title": "A Survey of Optimization Methods From a Machine Learning Perspective",
        "abstract": "Machine learning develops rapidly, which has made many theoretical breakthroughs and is widely applied in various fields. Optimization, as an important part of machine learning, has attracted much attention of researchers. With the exponential growth of data amount and the increase of model complexity, optimization methods in machine learning face more and more challenges. A lot of work on solving optimization problems or improving optimization methods in machine learning has been proposed successively. The systematic retrospect and summary of the optimization methods from the perspective of machine learning are of great significance, which can offer guidance for both developments of optimization and machine learning research. In this article, we first describe the optimization problems in machine learning. Then, we introduce the principles and progresses of commonly used optimization methods. Finally, we explore and give some challenges and open problems for the optimization in machine learning.",
        "link": "https://www.semanticscholar.org/paper/3119ea9c7ad7a5e044dc7c267329a4bbf00d0158",
        "published": "2019-06-17",
        "pdf_url": "http://arxiv.org/pdf/1906.06821",
        "txt_path": "data/txt/machine learning_paper_317.txt",
        "pdf_path": "data/pdfs/machine learning_paper_317.pdf"
    },
    {
        "title": "A Detailed Investigation and Analysis of Using Machine Learning Techniques for Intrusion Detection",
        "abstract": "Intrusion detection is one of the important security problems in todays cyber world. A significant number of techniques have been developed which are based on machine learning approaches. However, they are not very successful in identifying all types of intrusions. In this paper, a detailed investigation and analysis of various machine learning techniques have been carried out for finding the cause of problems associated with various machine learning techniques in detecting intrusive activities. Attack classification and mapping of the attack features is provided corresponding to each attack. Issues which are related to detecting low-frequency attacks using network attack dataset are also discussed and viable methods are suggested for improvement. Machine learning techniques have been analyzed and compared in terms of their detection capability for detecting the various category of attacks. Limitations associated with each category of them are also discussed. Various data mining tools for machine learning have also been included in the paper. At the end, future directions are provided for attack detection using machine learning techniques.",
        "link": "https://www.semanticscholar.org/paper/d294d5246e0dd8ed8bd9ec9d24a01fd4ece4fb3c",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_318.txt",
        "pdf_path": null
    },
    {
        "title": "Understanding the Effect of Accuracy on Trust in Machine Learning Models",
        "abstract": "We address a relatively under-explored aspect of human-computer interaction: people's abilities to understand the relationship between a machine learning model's stated performance on held-out data and its expected performance post deployment. We conduct large-scale, randomized human-subject experiments to examine whether laypeople's trust in a model, measured in terms of both the frequency with which they revise their predictions to match those of the model and their self-reported levels of trust in the model, varies depending on the model's stated accuracy on held-out data and on its observed accuracy in practice. We find that people's trust in a model is affected by both its stated accuracy and its observed accuracy, and that the effect of stated accuracy can change depending on the observed accuracy. Our work relates to recent research on interpretable machine learning, but moves beyond the typical focus on model internals, exploring a different component of the machine learning pipeline.",
        "link": "https://www.semanticscholar.org/paper/b4b1cbd74029f46ef9b462290a46111217552761",
        "published": "2019-05-02",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_319.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning-assisted directed protein evolution with combinatorial libraries",
        "abstract": "Significance Proteins often function poorly when used outside their natural contexts; directed evolution can be used to engineer them to be more efficient in new roles. We propose that the expense of experimentally testing a large number of protein variants can be decreased and the outcome can be improved by incorporating machine learning with directed evolution. Simulations on an empirical fitness landscape demonstrate that the expected performance improvement is greater with this approach. Machine learning-assisted directed evolution from a single parent produced enzyme variants that selectively synthesize the enantiomeric products of a new-to-nature chemical transformation. By exploring multiple mutations simultaneously, machine learning efficiently navigates large regions of sequence space to identify improved proteins and also produces diverse solutions to engineering problems. To reduce experimental effort associated with directed protein evolution and to explore the sequence space encoded by mutating multiple positions simultaneously, we incorporate machine learning into the directed evolution workflow. Combinatorial sequence space can be quite expensive to sample experimentally, but machine-learning models trained on tested variants provide a fast method for testing sequence space computationally. We validated this approach on a large published empirical fitness landscape for human GB1 binding protein, demonstrating that machine learning-guided directed evolution finds variants with higher fitness than those found by other directed evolution approaches. We then provide an example application in evolving an enzyme to produce each of the two possible product enantiomers (i.e., stereodivergence) of a new-to-nature carbene Si–H insertion reaction. The approach predicted libraries enriched in functional enzymes and fixed seven mutations in two rounds of evolution to identify variants for selective catalysis with 93% and 79% ee (enantiomeric excess). By greatly increasing throughput with in silico modeling, machine learning enhances the quality and diversity of sequence solutions for a protein engineering problem.",
        "link": "https://www.semanticscholar.org/paper/89f88f324bb3775f63f87cec90a4283a3522ab44",
        "published": "2019-02-20",
        "pdf_url": "https://europepmc.org/articles/pmc6500146?pdf=render",
        "txt_path": "data/txt/machine learning_paper_320.txt",
        "pdf_path": "data/pdfs/machine learning_paper_320.pdf"
    },
    {
        "title": "How to Read Articles That Use Machine Learning: Users' Guides to the Medical Literature.",
        "abstract": "In recent years, many new clinical diagnostic tools have been developed using complicated machine learning methods. Irrespective of how a diagnostic tool is derived, it must be evaluated using a 3-step process of deriving, validating, and establishing the clinical effectiveness of the tool. Machine learning-based tools should also be assessed for the type of machine learning model used and its appropriateness for the input data type and data set size. Machine learning models also generally have additional prespecified settings called hyperparameters, which must be tuned on a data set independent of the validation set. On the validation set, the outcome against which the model is evaluated is termed the reference standard. The rigor of the reference standard must be assessed, such as against a universally accepted gold standard or expert grading.",
        "link": "https://www.semanticscholar.org/paper/97f4a6f87f258053f2677504647696f1803c6794",
        "published": "2019-11-12",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_321.txt",
        "pdf_path": null
    },
    {
        "title": "A Systematic Review on Imbalanced Data Challenges in Machine Learning",
        "abstract": "In machine learning, the data imbalance imposes challenges to perform data analytics in almost all areas of real-world research. The raw primary data often suffers from the skewed perspective of data distribution of one class over the other as in the case of computer vision, information security, marketing, and medical science. The goal of this article is to present a comparative analysis of the approaches from the reference of data pre-processing, algorithmic and hybrid paradigms for contemporary imbalance data analysis techniques, and their comparative study in lieu of different data distribution and their application areas.",
        "link": "https://www.semanticscholar.org/paper/7ac8f533a18f584387dd412a0a27feb9af1c5c93",
        "published": "2019-08-30",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_322.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning at the Network Edge: A Survey",
        "abstract": "Resource-constrained IoT devices, such as sensors and actuators, have become ubiquitous in recent years. This has led to the generation of large quantities of data in real-time, which is an appealing target for AI systems. However, deploying machine learning models on such end-devices is nearly impossible. A typical solution involves offloading data to external computing systems (such as cloud servers) for further processing but this worsens latency, leads to increased communication costs, and adds to privacy concerns. To address this issue, efforts have been made to place additional computing devices at the edge of the network, i.e., close to the IoT devices where the data is generated. Deploying machine learning systems on such edge computing devices alleviates the above issues by allowing computations to be performed close to the data sources. This survey describes major research efforts where machine learning systems have been deployed at the edge of computer networks, focusing on the operational aspects including compression techniques, tools, frameworks, and hardware used in successful applications of intelligent edge systems.",
        "link": "https://www.semanticscholar.org/paper/3e9a40a567c4a95b591530ff5771296b478a0f0c",
        "published": "2019-07-31",
        "pdf_url": "https://arxiv.org/pdf/1908.00080",
        "txt_path": "data/txt/machine learning_paper_323.txt",
        "pdf_path": "data/pdfs/machine learning_paper_323.pdf"
    },
    {
        "title": "Hidden stratification causes clinically meaningful failures in machine learning for medical imaging",
        "abstract": "Machine learning models for medical image analysis often suffer from poor performance on important subsets of a population that are not identified during training or testing. For example, overall performance of a cancer detection model may be high, but the model may still consistently miss a rare but aggressive cancer subtype. We refer to this problem as hidden stratification, and observe that it results from incompletely describing the meaningful variation in a dataset. While hidden stratification can substantially reduce the clinical efficacy of machine learning models, its effects remain difficult to measure. In this work, we assess the utility of several possible techniques for measuring hidden stratification effects, and characterize these effects both via synthetic experiments on the CIFAR-100 benchmark dataset and on multiple real-world medical imaging datasets. Using these measurement techniques, we find evidence that hidden stratification can occur in unidentified imaging subsets with low prevalence, low label quality, subtle distinguishing features, or spurious correlates, and that it can result in relative performance differences of over 20% on clinically important subsets. Finally, we discuss the clinical implications of our findings, and suggest that evaluation of hidden stratification should be a critical component of any machine learning deployment in medical imaging.",
        "link": "https://www.semanticscholar.org/paper/4ce2f55585f3156e332721b8ab4f449389dc2a3c",
        "published": "2019-09-27",
        "pdf_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7665161",
        "txt_path": "data/txt/machine learning_paper_324.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning–Based Model for Prediction of Outcomes in Acute Stroke",
        "abstract": "Background and Purpose— The prediction of long-term outcomes in ischemic stroke patients may be useful in treatment decisions. Machine learning techniques are being increasingly adapted for use in the medical field because of their high accuracy. This study investigated the applicability of machine learning techniques to predict long-term outcomes in ischemic stroke patients. Methods— This was a retrospective study using a prospective cohort that enrolled patients with acute ischemic stroke. Favorable outcome was defined as modified Rankin Scale score 0, 1, or 2 at 3 months. We developed 3 machine learning models (deep neural network, random forest, and logistic regression) and compared their predictability. To evaluate the accuracy of the machine learning models, we also compared them to the Acute Stroke Registry and Analysis of Lausanne (ASTRAL) score. Results— A total of 2604 patients were included in this study, and 2043 (78%) of them had favorable outcomes. The area under the curve for the deep neural network model was significantly higher than that of the ASTRAL score (0.888 versus 0.839; P<0.001), while the areas under the curves of the random forest (0.857; P=0.136) and logistic regression (0.849; P=0.413) models were not significantly higher than that of the ASTRAL score. Using only the 6 variables that are used for the ASTRAL score, the performance of the machine learning models did not significantly differ from that of the ASTRAL score. Conclusions— Machine learning algorithms, particularly the deep neural network, can improve the prediction of long-term outcomes in ischemic stroke patients.",
        "link": "https://www.semanticscholar.org/paper/792d90c2ed5ebbe050bd80b9c865dc416b574c09",
        "published": "2019-05-01",
        "pdf_url": "https://www.ahajournals.org/doi/pdf/10.1161/STROKEAHA.118.024293",
        "txt_path": "data/txt/machine learning_paper_325.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning for molecular simulation",
        "abstract": "Machine learning (ML) is transforming all areas of science. The complex and time-consuming calculations in molecular simulations are particularly suitable for an ML revolution and have already been profoundly affected by the application of existing ML methods. Here we review recent ML methods for molecular simulation, with particular focus on (deep) neural networks for the prediction of quantum-mechanical energies and forces, on coarse-grained molecular dynamics, on the extraction of free energy surfaces and kinetics, and on generative network approaches to sample molecular equilibrium structures and compute thermodynamics. To explain these methods and illustrate open methodological problems, we review some important principles of molecular physics and describe how they can be incorporated into ML structures. Finally, we identify and describe a list of open challenges for the interface between ML and molecular simulation. Expected final online publication date for the Annual Review of Physical Chemistry, Volume 71 is April 20, 2020. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.",
        "link": "https://www.semanticscholar.org/paper/b674a7aee72e9b9cc5390eca13f9c5c7812f2ba0",
        "published": "2019-11-07",
        "pdf_url": "https://orbilu.uni.lu/bitstream/10993/45768/1/159-ML-molecular-simulations-ARPhysChem-2020.pdf",
        "txt_path": "data/txt/machine learning_paper_326.txt",
        "pdf_path": "data/pdfs/machine learning_paper_326.pdf"
    },
    {
        "title": "Machine learning for neuroimaging with scikit-learn",
        "abstract": "Statistical machine learning methods are increasingly used for neuroimaging data analysis. Their main virtue is their ability to model high-dimensional datasets, e.g., multivariate analysis of activation images or resting-state time series. Supervised learning is typically used in decoding or encoding settings to relate brain images to behavioral or clinical observations, while unsupervised learning can uncover hidden structures in sets of images (e.g., resting state functional MRI) or find sub-populations in large cohorts. By considering different functional neuroimaging applications, we illustrate how scikit-learn, a Python machine learning library, can be used to perform some key analysis steps. Scikit-learn contains a very large set of statistical learning algorithms, both supervised and unsupervised, and its application to neuroimaging data provides a versatile tool to study the brain.",
        "link": "https://www.semanticscholar.org/paper/f15367ed93c3505b1d62d802f3f4b769ae0f4ba5",
        "published": "2014-02-21",
        "pdf_url": "https://www.frontiersin.org/articles/10.3389/fninf.2014.00014/pdf",
        "txt_path": "data/txt/machine learning_paper_327.txt",
        "pdf_path": "data/pdfs/machine learning_paper_327.pdf"
    },
    {
        "title": "Machine-learning reprogrammable metasurface imager",
        "abstract": "Conventional microwave imagers usually require either time-consuming data acquisition, or complicated reconstruction algorithms for data post-processing, making them largely ineffective for complex in-situ sensing and monitoring. Here, we experimentally report a real-time digital-metasurface imager that can be trained in-situ to generate the radiation patterns required by machine-learning optimized measurement modes. This imager is electronically reprogrammed in real time to access the optimized solution for an entire data set, realizing storage and transfer of full-resolution raw data in dynamically varying scenes. High-accuracy image coding and recognition are demonstrated in situ for various image sets, including hand-written digits and through-wall body gestures, using a single physical hardware imager, reprogrammed in real time. Our electronically controlled metasurface imager opens new venues for intelligent surveillance, fast data acquisition and processing, imaging at various frequencies, and beyond. Conventional imagers require time-consuming data acquisition, or complicated reconstruction algorithms for data post-processing. Here, the authors demonstrate a real-time digital-metasurface imager that can be trained in-situ to show high accuracy image coding and recognition for various image sets.",
        "link": "https://www.semanticscholar.org/paper/4f2b9cb774489c1a600c224c75edb8da07a24064",
        "published": "2019-03-06",
        "pdf_url": "https://www.nature.com/articles/s41467-019-09103-2.pdf",
        "txt_path": "data/txt/machine learning_paper_328.txt",
        "pdf_path": "data/pdfs/machine learning_paper_328.pdf"
    },
    {
        "title": "Enhancing gravitational-wave science with machine learning",
        "abstract": "Machine learning has emerged as a popular and powerful approach for solving problems in astrophysics. We review applications of machine learning techniques for the analysis of ground-based gravitational-wave (GW) detector data. Examples include techniques for improving the sensitivity of Advanced Laser Interferometer GW Observatory and Advanced Virgo GW searches, methods for fast measurements of the astrophysical parameters of GW sources, and algorithms for reduction and characterization of non-astrophysical detector noise. These applications demonstrate how machine learning techniques may be harnessed to enhance the science that is possible with current and future GW detectors.",
        "link": "https://www.semanticscholar.org/paper/37f239603ce77e8f10be255be0a2cff7070122ad",
        "published": "2020-05-07",
        "pdf_url": "https://doi.org/10.1088/2632-2153/abb93a",
        "txt_path": "data/txt/machine learning_paper_329.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Made Easy: A Review of Scikit-learn Package in Python Programming Language",
        "abstract": "Machine learning is a popular topic in data analysis and modeling. Many different machine learning algorithms have been developed and implemented in a variety of programming languages over the past 20 years. In this article, we first provide an overview of machine learning and clarify its difference from statistical inference. Then, we review Scikit-learn, a machine learning package in the Python programming language that is widely used in data science. The Scikit-learn package includes implementations of a comprehensive list of machine learning methods under unified data and modeling procedure conventions, making it a convenient toolkit for educational and behavior statisticians.",
        "link": "https://www.semanticscholar.org/paper/a8fadb33a38f1096f84f64bd66345717a5bc3241",
        "published": "2019-02-20",
        "pdf_url": "http://repository.unimilitar.edu.co/bitstream/10654/44324/6/RinconValbuenaFernandoAdolfo2022.pdf",
        "txt_path": "data/txt/machine learning_paper_330.txt",
        "pdf_path": "data/pdfs/machine learning_paper_330.pdf"
    },
    {
        "title": "Benchmark and Survey of Automated Machine Learning Frameworks",
        "abstract": "Machine learning (ML) has become a vital part in many aspects of our daily life. However, building well performing machine learning applications requires highly specialized data scientists and domain experts. Automated machine learning (AutoML) aims to reduce the demand for data scientists by enabling domain experts to automatically build machine learning applications without extensive knowledge of statistics and machine learning. This paper is a combination of a survey on current AutoML methods and a benchmark of popular AutoML frameworks on real data sets. Driven by the selected frameworks for evaluation, we summarize and review important AutoML techniques and methods concerning every step in building an ML pipeline. The selected AutoML frameworks are evaluated on 137 different data sets.",
        "link": "https://www.semanticscholar.org/paper/330b5844d170b6b77f5f9fa4c2024150cef2af18",
        "published": "2019-04-26",
        "pdf_url": "https://www.jair.org/index.php/jair/article/download/11854/26651",
        "txt_path": "data/txt/machine learning_paper_331.txt",
        "pdf_path": null
    },
    {
        "title": "Implementing Machine Learning in Health Care - Addressing Ethical Challenges.",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/adfc508b9b3d4fc3903aa383a290dc68fb8bbe5a",
        "published": "2018-03-14",
        "pdf_url": "https://europepmc.org/articles/pmc5962261?pdf=render",
        "txt_path": "data/txt/machine learning_paper_332.txt",
        "pdf_path": "data/pdfs/machine learning_paper_332.pdf"
    },
    {
        "title": "Techniques for interpretable machine learning",
        "abstract": "Uncovering the mysterious ways machine learning models make decisions.",
        "link": "https://www.semanticscholar.org/paper/3df952d4a724655f7520ff95d4b2cef90fff0cae",
        "published": "2018-07-31",
        "pdf_url": "http://arxiv.org/pdf/1808.00033",
        "txt_path": "data/txt/machine learning_paper_333.txt",
        "pdf_path": "data/pdfs/machine learning_paper_333.pdf"
    },
    {
        "title": "Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning",
        "abstract": "As machine learning becomes widely used for automated decisions, attackers have strong incentives to manipulate the results and models generated by machine learning algorithms. In this paper, we perform the first systematic study of poisoning attacks and their countermeasures for linear regression models. In poisoning attacks, attackers deliberately influence the training data to manipulate the results of a predictive model. We propose a theoretically-grounded optimization framework specifically designed for linear regression and demonstrate its effectiveness on a range of datasets and models. We also introduce a fast statistical attack that requires limited knowledge of the training process. Finally, we design a new principled defense method that is highly resilient against all poisoning attacks. We provide formal guarantees about its convergence and an upper bound on the effect of poisoning attacks when the defense is deployed. We evaluate extensively our attacks and defenses on three realistic datasets from health care, loan assessment, and real estate domains.",
        "link": "https://www.semanticscholar.org/paper/efd7b7aafeb83b8a8d6fd90a35d6fb6a62f5f695",
        "published": "2018-04-01",
        "pdf_url": "https://ieeexplore.ieee.org/ielx7/8418581/8418583/08418594.pdf",
        "txt_path": "data/txt/machine learning_paper_334.txt",
        "pdf_path": null
    },
    {
        "title": "What Is Machine Learning: a Primer for the Epidemiologist.",
        "abstract": "Machine learning is a branch of computer science that has the potential to transform epidemiological sciences. Amid a growing focus on \"Big Data,\" it offers epidemiologists new tools to tackle problems for which classical methods are not well-suited. In order to critically evaluate the value of integrating machine learning algorithms and existing methods, however, it is essential to address language and technical barriers between the two fields that can make it difficult for epidemiologists to read and assess machine learning studies. Here, we provide an overview of the concepts and terminology used in machine learning literature, which encompasses a diverse set of tools with goals ranging from prediction, to classification, to clustering. We provide a brief introduction to five common machine learning algorithms and four ensemble-based approaches. We then summarize epidemiological applications of machine learning techniques in the published literature. We recommend approaches to incorporate machine learning in epidemiological research and discuss opportunities and challenges for integrating machine learning and existing epidemiological research methods.",
        "link": "https://www.semanticscholar.org/paper/5ec6039389d448f24183084b503cf1ac899f45fc",
        "published": "2019-10-21",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_335.txt",
        "pdf_path": null
    },
    {
        "title": "MLlib: Machine Learning in Apache Spark",
        "abstract": "Apache Spark is a popular open-source platform for large-scale data processing that is well-suited for iterative machine learning tasks. In this paper we present MLlib, Spark's open-source distributed machine learning library. MLlib provides efficient functionality for a wide range of learning settings and includes several underlying statistical, optimization, and linear algebra primitives. Shipped with Spark, MLlib supports several languages and provides a high-level API that leverages Spark's rich ecosystem to simplify the development of end-to-end machine learning pipelines. MLlib has experienced a rapid growth due to its vibrant open-source community of over 140 contributors, and includes extensive documentation to support further growth and to let users quickly get up to speed.",
        "link": "https://www.semanticscholar.org/paper/3784b73a1f392160523400ec0309191c0a96d86f",
        "published": "2015-05-26",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_336.txt",
        "pdf_path": null
    },
    {
        "title": "Genetic algorithms and Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/c61134ada9f0e3f3373d635c31a8b3caa37f9977",
        "published": "1988-10-01",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf",
        "txt_path": "data/txt/machine learning_paper_337.txt",
        "pdf_path": "data/pdfs/machine learning_paper_337.pdf"
    },
    {
        "title": "Machine Learning for Survival Analysis",
        "abstract": "Survival analysis is a subfield of statistics where the goal is to analyze and model data where the outcome is the time until an event of interest occurs. One of the main challenges in this context is the presence of instances whose event outcomes become unobservable after a certain time point or when some instances do not experience any event during the monitoring period. This so-called censoring can be handled most effectively using survival analysis techniques. Traditionally, statistical approaches have been widely developed in the literature to overcome the issue of censoring. In addition, many machine learning algorithms have been adapted to deal with such censored data and tackle other challenging problems that arise in real-world data. In this survey, we provide a comprehensive and structured review of the statistical methods typically used and the machine learning techniques developed for survival analysis, along with a detailed taxonomy of the existing methods. We also discuss several topics that are closely related to survival analysis and describe several successful applications in a variety of real-world application domains. We hope that this article will give readers a more comprehensive understanding of recent advances in survival analysis and offer some guidelines for applying these approaches to solve new problems arising in applications involving censored data.",
        "link": "https://www.semanticscholar.org/paper/5d500ff62baeac5a27ea7512a833e2a25dcb2354",
        "published": "2019-02-27",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_338.txt",
        "pdf_path": null
    },
    {
        "title": "Tensor Decomposition for Signal Processing and Machine Learning",
        "abstract": "Tensors or <italic>multiway arrays</italic> are functions of three or more indices <inline-formula> <tex-math notation=\"LaTeX\">$(i,j,k,\\ldots)$</tex-math></inline-formula>—similar to matrices (two-way arrays), which are functions of two indices <inline-formula><tex-math notation=\"LaTeX\">$(r,c)$</tex-math></inline-formula> for (row, column). Tensors have a rich history, stretching over almost a century, and touching upon numerous disciplines; but they have only recently become ubiquitous in signal and data analytics at the confluence of signal processing, statistics, data mining, and machine learning. This overview article aims to provide a good starting point for researchers and practitioners interested in learning about and working with tensors. As such, it focuses on fundamentals and motivation (using various application examples), aiming to strike an appropriate balance of breadth <italic>and depth</italic> that will enable someone having taken first graduate courses in matrix algebra and probability to get started doing research and/or developing tensor algorithms and software. Some background in applied optimization is useful but not strictly required. The material covered includes tensor rank and rank decomposition; basic tensor factorization models and their relationships and properties (including fairly good coverage of identifiability); broad coverage of algorithms ranging from alternating optimization to stochastic gradient; statistical performance analysis; and applications ranging from source separation to collaborative filtering, mixture and topic modeling, classification, and multilinear subspace learning.",
        "link": "https://www.semanticscholar.org/paper/eed9fa4483cab37eacd59db0fac4b1441431ee85",
        "published": "2016-07-06",
        "pdf_url": "https://doi.org/10.1109/tsp.2017.2690524",
        "txt_path": "data/txt/machine learning_paper_339.txt",
        "pdf_path": null
    },
    {
        "title": "A Review of Relational Machine Learning for Knowledge Graphs",
        "abstract": "Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be “trained” on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive data sets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google's knowledge vault project as an example of such combination.",
        "link": "https://www.semanticscholar.org/paper/033f25ad905ef2ed32a8331cf38b83953ff15922",
        "published": "2015-03-02",
        "pdf_url": "https://doi.org/10.1109/jproc.2015.2483592",
        "txt_path": "data/txt/machine learning_paper_340.txt",
        "pdf_path": null
    },
    {
        "title": "Potential Biases in Machine Learning Algorithms Using Electronic Health Record Data",
        "abstract": "A promise of machine learning in health care is the avoidance of biases in diagnosis and treatment; a computer algorithm could objectively synthesize and interpret the data in the medical record. Integration of machine learning with clinical decision support tools, such as computerized alerts or diagnostic support, may offer physicians and others who provide health care targeted and timely information that can improve clinical decisions. Machine learning algorithms, however, may also be subject to biases. The biases include those related to missing data and patients not identified by algorithms, sample size and underestimation, and misclassification and measurement error. There is concern that biases and deficiencies in the data used by machine learning algorithms may contribute to socioeconomic disparities in health care. This Special Communication outlines the potential biases that may be introduced into machine learning–based clinical decision support tools that use electronic health record data and proposes potential solutions to the problems of overreliance on automation, algorithms based on biased data, and algorithms that do not provide information that is clinically meaningful. Existing health care disparities should not be amplified by thoughtless or excessive reliance on machines.",
        "link": "https://www.semanticscholar.org/paper/161ce338538f94b0b9be51ae2336db0aa4b012e5",
        "published": "2018-11-01",
        "pdf_url": "https://europepmc.org/articles/pmc6347576?pdf=render",
        "txt_path": "data/txt/machine learning_paper_341.txt",
        "pdf_path": "data/pdfs/machine learning_paper_341.pdf"
    },
    {
        "title": "Points of Significance: Statistics versus machine learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/fa9906b466bbbff3a8c206b499cd34323a91d1b2",
        "published": "2018-04-03",
        "pdf_url": "https://www.nature.com/articles/nmeth.4642.pdf",
        "txt_path": "data/txt/machine learning_paper_342.txt",
        "pdf_path": null
    },
    {
        "title": "A Systematic Review on Supervised and Unsupervised Machine Learning Algorithms for Data Science",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/3b16bcb226bb1c87a6e63e0658be30067ed03f57",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_343.txt",
        "pdf_path": null
    },
    {
        "title": "Predicting Diabetes Mellitus With Machine Learning Techniques",
        "abstract": "Diabetes mellitus is a chronic disease characterized by hyperglycemia. It may cause many complications. According to the growing morbidity in recent years, in 2040, the world’s diabetic patients will reach 642 million, which means that one of the ten adults in the future is suffering from diabetes. There is no doubt that this alarming figure needs great attention. With the rapid development of machine learning, machine learning has been applied to many aspects of medical health. In this study, we used decision tree, random forest and neural network to predict diabetes mellitus. The dataset is the hospital physical examination data in Luzhou, China. It contains 14 attributes. In this study, five-fold cross validation was used to examine the models. In order to verity the universal applicability of the methods, we chose some methods that have the better performance to conduct independent test experiments. We randomly selected 68994 healthy people and diabetic patients’ data, respectively as training set. Due to the data unbalance, we randomly extracted 5 times data. And the result is the average of these five experiments. In this study, we used principal component analysis (PCA) and minimum redundancy maximum relevance (mRMR) to reduce the dimensionality. The results showed that prediction with random forest could reach the highest accuracy (ACC = 0.8084) when all the attributes were used.",
        "link": "https://www.semanticscholar.org/paper/5327bb691a1c63791a06de2d3f0478e47785add5",
        "published": "2018-11-06",
        "pdf_url": "https://www.frontiersin.org/articles/10.3389/fgene.2018.00515/pdf",
        "txt_path": "data/txt/machine learning_paper_344.txt",
        "pdf_path": "data/pdfs/machine learning_paper_344.pdf"
    },
    {
        "title": "Exploiting machine learning for end-to-end drug discovery and development",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/daf468f001c3a5c6f9e667417becb94fa83efb2f",
        "published": "2019-04-18",
        "pdf_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6594828",
        "txt_path": "data/txt/machine learning_paper_345.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning in acoustics: Theory and applications.",
        "abstract": "Acoustic data provide scientific and engineering insights in fields ranging from biology and communications to ocean and Earth science. We survey the recent advances and transformative potential of machine learning (ML), including deep learning, in the field of acoustics. ML is a broad family of techniques, which are often based in statistics, for automatically detecting and utilizing patterns in data. Relative to conventional acoustics and signal processing, ML is data-driven. Given sufficient training data, ML can discover complex relationships between features and desired labels or actions, or between features themselves. With large volumes of training data, ML can discover models describing complex acoustic phenomena such as human speech and reverberation. ML in acoustics is rapidly developing with compelling results and significant future promise. We first introduce ML, then highlight ML developments in four acoustics research areas: source localization in speech processing, source localization in ocean acoustics, bioacoustics, and environmental sounds in everyday scenes.",
        "link": "https://www.semanticscholar.org/paper/2e6c570d277b0b4edd48e2054d5cede4c6bbb50f",
        "published": "2019-05-11",
        "pdf_url": "https://asa.scitation.org/doi/pdf/10.1121/1.5133944",
        "txt_path": "data/txt/machine learning_paper_346.txt",
        "pdf_path": null
    },
    {
        "title": "Selection of Relevant Features and Examples in Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/8f04029d1d83f41eaebf5a216ebecf2a61ff6dc0",
        "published": "1997-12-01",
        "pdf_url": "http://yaroslavvb.com/papers/blum-selection.pdf",
        "txt_path": "data/txt/machine learning_paper_347.txt",
        "pdf_path": null
    },
    {
        "title": "The Impact of Machine Learning on Economics",
        "abstract": "This paper provides an assessment of the early contributions of machine learning to economics, as well as predictions about its future contributions. It begins by brieﬂy overviewing some themes from the literature on machine learning, and then draws some contrasts with traditional approaches to estimating the impact of counterfactual policies in economics. Next, we review some of the initial “oﬀ-the-shelf” applications of machine learning to economics, including applications in analyzing text and images. We then describe new types of questions that have been posed surrounding the application of machine learning to policy problems, including “prediction policy problems,” as well as considerations of fairness and manipulability. Next, we brieﬂy review of some of the emerging econometric literature combining machine learning and causal inference. Finally, we overview a set of predictions about the future impact of machine learning on economics.",
        "link": "https://www.semanticscholar.org/paper/adade3149b2a6177296de352f003471eefa958b8",
        "published": "2018-01-10",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_348.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning and Deep Learning Methods for Cybersecurity",
        "abstract": "With the development of the Internet, cyber-attacks are changing rapidly and the cyber security situation is not optimistic. This survey report describes key literature surveys on machine learning (ML) and deep learning (DL) methods for network analysis of intrusion detection and provides a brief tutorial description of each ML/DL method. Papers representing each method were indexed, read, and summarized based on their temporal or thermal correlations. Because data are so important in ML/DL methods, we describe some of the commonly used network datasets used in ML/DL, discuss the challenges of using ML/DL for cybersecurity and provide suggestions for research directions.",
        "link": "https://www.semanticscholar.org/paper/39361b3507c9f8b0a97780568b645f80a208d78a",
        "published": "2018-05-15",
        "pdf_url": "https://doi.org/10.1109/access.2018.2836950",
        "txt_path": "data/txt/machine learning_paper_349.txt",
        "pdf_path": null
    },
    {
        "title": "Quantum machine learning in high energy physics",
        "abstract": "Machine learning has been used in high energy physics (HEP) for a long time, primarily at the analysis level with supervised classification. Quantum computing was postulated in the early 1980s as way to perform computations that would not be tractable with a classical computer. With the advent of noisy intermediate-scale quantum computing devices, more quantum algorithms are being developed with the aim at exploiting the capacity of the hardware for machine learning applications. An interesting question is whether there are ways to apply quantum machine learning to HEP. This paper reviews the first generation of ideas that use quantum machine learning on problems in HEP and provide an outlook on future applications.",
        "link": "https://www.semanticscholar.org/paper/32c709cf5d6ba1b5a729b4871c3129bb1bf578bf",
        "published": "2020-05-18",
        "pdf_url": "https://iopscience.iop.org/article/10.1088/2632-2153/abc17d/pdf",
        "txt_path": "data/txt/machine learning_paper_350.txt",
        "pdf_path": null
    },
    {
        "title": "An Introduction to MCMC for Machine Learning",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/7c8858eba8571d86abd90252e734a11e3a6dd73f",
        "published": null,
        "pdf_url": "https://link.springer.com/content/pdf/10.1023%2FA%3A1020281327116.pdf",
        "txt_path": "data/txt/machine learning_paper_351.txt",
        "pdf_path": "data/pdfs/machine learning_paper_351.pdf"
    },
    {
        "title": "Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/88a97c8ef539589c55a6fe869c243792e470d6a3",
        "published": "2018-02-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_352.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning, Neural and Statistical Classification",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/fad1bd501aa769f7701c1016f8a4d1473ca77601",
        "published": "2009-08-28",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_353.txt",
        "pdf_path": null
    },
    {
        "title": "Data mining - practical machine learning tools and techniques, Second Edition",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/49d1f40312af25d01da721e33f4a8be8cea29551",
        "published": null,
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_354.txt",
        "pdf_path": null
    },
    {
        "title": "Hands-On Machine Learning with R",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/d73149832c5dc18c8a74b2cc0924eceb51be2e60",
        "published": "2019-11-11",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_355.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning methods for solar radiation forecasting: A review",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/b7621b358485eb3e34a874b97d1ecd6b5d5ac70b",
        "published": "2017-05-01",
        "pdf_url": "https://zenodo.org/records/889123/files/Machine%20Learning%20methods%20for%20solar%20radiation%20forecasting.%20A%20review.pdf",
        "txt_path": "data/txt/machine learning_paper_356.txt",
        "pdf_path": null
    },
    {
        "title": "Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning",
        "abstract": "The correct use of model evaluation, model selection, and algorithm selection techniques is vital in academic machine learning research as well as in many industrial settings. This article reviews different techniques that can be used for each of these three subtasks and discusses the main advantages and disadvantages of each technique with references to theoretical and empirical studies. Further, recommendations are given to encourage best yet feasible practices in research and applications of machine learning. Common methods such as the holdout method for model evaluation and selection are covered, which are not recommended when working with small datasets. Different flavors of the bootstrap technique are introduced for estimating the uncertainty of performance estimates, as an alternative to confidence intervals via normal approximation if bootstrapping is computationally feasible. Common cross-validation techniques such as leave-one-out cross-validation and k-fold cross-validation are reviewed, the bias-variance trade-off for choosing k is discussed, and practical tips for the optimal choice of k are given based on empirical evidence. Different statistical tests for algorithm comparisons are presented, and strategies for dealing with multiple comparisons such as omnibus tests and multiple-comparison corrections are discussed. Finally, alternative methods for algorithm selection, such as the combined F-test 5x2 cross-validation and nested cross-validation, are recommended for comparing machine learning algorithms when datasets are small.",
        "link": "https://www.semanticscholar.org/paper/eef183687fab4d762a381f2e80e357e08e923f0a",
        "published": "2018-11-13",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_357.txt",
        "pdf_path": null
    },
    {
        "title": "Delayed Impact of Fair Machine Learning",
        "abstract": "Static classification has been the predominant focus of the study of fairness in machine learning. While most models do not consider how decisions change populations over time, it is conventional wisdom that fairness criteria promote the long-term well-being of groups they aim to protect. This work studies the interaction of static fairness criteria with temporal indicators of well-being. We show a simple one-step feedback model in which common criteria do not generally promote improvement over time, and may in fact cause harm. Our results highlight the importance of temporal modeling in the evaluation of fairness criteria, suggesting a range of new challenges and trade-offs.",
        "link": "https://www.semanticscholar.org/paper/4f2baff3195b6fc43a38e3e869496dab9fe9dbc3",
        "published": "2018-03-12",
        "pdf_url": "https://www.ijcai.org/proceedings/2019/0862.pdf",
        "txt_path": "data/txt/machine learning_paper_358.txt",
        "pdf_path": "data/pdfs/machine learning_paper_358.pdf"
    },
    {
        "title": "SoK: Security and Privacy in Machine Learning",
        "abstract": "Advances in machine learning (ML) in recent years have enabled a dizzying array of applications such as data analytics, autonomous systems, and security diagnostics. ML is now pervasive—new systems and models are being deployed in every domain imaginable, leading to widespread deployment of software based inference and decision making. There is growing recognition that ML exposes new vulnerabilities in software systems, yet the technical community's understanding of the nature and extent of these vulnerabilities remains limited. We systematize findings on ML security and privacy, focusing on attacks identified on these systems and defenses crafted to date.We articulate a comprehensive threat model for ML, and categorize attacks and defenses within an adversarial framework. Key insights resulting from works both in the ML and security communities are identified and the effectiveness of approaches are related to structural elements of ML algorithms and the data used to train them. In particular, it is apparent that constructing a theoretical understanding of the sensitivity of modern ML algorithms to the data they analyze, à la PAC theory, will foster a science of security and privacy in ML.",
        "link": "https://www.semanticscholar.org/paper/29524f145db94cab2336da99f157e869d805dead",
        "published": "2018-04-01",
        "pdf_url": "https://ink.library.smu.edu.sg/sis_research/4790",
        "txt_path": "data/txt/machine learning_paper_359.txt",
        "pdf_path": null
    },
    {
        "title": "Ensuring Fairness in Machine Learning to Advance Health Equity",
        "abstract": "Machine learning can identify the statistical patterns of data generated by tens of thousands of physicians and billions of patients to train computers to perform specific tasks with sometimes superhuman ability, such as detecting diabetic eye disease better than retinal specialists (1). However, historical data also capture patterns of health care disparities, and machine-learning models trained on these data may perpetuate these inequities. This concern is not just academic. In a model used to predict future crime on the basis of historical arrest records, African American defendants who did not reoffend were classified as high risk at a substantially higher rate than white defendants who did not reoffend (2, 3). Similar biases have been observed in predictive policing (4) and identifying which calls to a child protective services agency required an in-person investigation (5, 6). The implications for health care led the American Medical Association to pass policy recommendations to promote development of thoughtfully designed, high-quality, clinically validated health care AI [artificial or augmented intelligence, such as machine learning] that . . . identifies and takes steps to address bias and avoids introducing or exacerbating health care disparities including when testing or deploying new AI tools on vulnerable populations (7). We argue that health care organizations and policymakers should go beyond the American Medical Association's position of doing no harm and instead proactively design and use machine-learning systems to advance health equity. Whereas much health disparities work has focused on discriminatory decision making and implicit biases by clinicians, policymakers, organizational leaders, and researchers are increasingly focusing on the ill health effects of structural racism and classismhow systems are shaped in ways that harm the health of disempowered, marginalized populations (8). For example, the United States has a shameful history of purposive decisions by government and private businesses to segregate housing. Zoning laws, discrimination in mortgage lending, prejudicial practices by real estate agents, and the ghettoization of public housing all contributed to the concentration of urban African Americans in inferior housing that has led to poor health (9, 10). Even when the goal of decision makers is not outright discrimination against disadvantaged groups, actions may lead to inequities. For example, if the goal of a machine-learning system is to maximize efficiency, that might come at the expense of disadvantaged populations. As a society, we value health equity. For example, the Healthy People 2020 vision statement aims for a society in which all people live long, healthy lives, and one of the mission's goals is to achieve health equity, eliminate disparities, and improve the health of all groups (11). The 4 classic principles of Western clinical medical ethics are justice, autonomy, beneficence, and nonmaleficence. However, health equity will not be attained unless we purposely design our health and social systems, which increasingly will be infused with machine learning (12), to achieve this goal. To ensure fairness in machine learning, we recommend a participatory process that involves key stakeholders, including frequently marginalized populations, and considers distributive justice within specific clinical and organizational contexts. Different technical approaches can configure the mathematical properties of machine-learning models to render predictions that are equitable in various ways. The existence of mathematical levers must be supplemented with criteria for when and why they should be usedeach tool comes with tradeoffs that require ethical reasoning to decide what is best for a given application. We propose incorporating fairness into the design, deployment, and evaluation of machine-learning models. We discuss 2 clinical applications in which machine learning might harm protected groups by being inaccurate, diverting resources, or worsening outcomes, especially if the models are built without consideration for these patients. We then describe the mechanisms by which a model's design, data, and deployment may lead to disparities; explain how different approaches to distributive justice in machine learning can advance health equity; and explore what contexts are more appropriate for different equity approaches in machine learning. Case Study 1: Intensive Care Unit Monitoring A common area of predictive modeling research focuses on creating a monitoring systemfor example, to warn a rapid response team about inpatients at high risk for deterioration (1315), requiring their transfer to an intensive care unit within 6 hours. How might such a system inadvertently result in harm to a protected group? In this thought experiment, we consider African Americans as a protected group. To build the model, our hypothetical researchers collected historical records of patients who had clinical deterioration and those who did not. The model acts like a diagnostic test of risk for intensive care unit transfer. However, if too few African American patients were included in the training datathe data used to construct the modelthe model might be inaccurate for them. For example, it might have a lower sensitivity and miss more patients at risk for deterioration. African American patients might be harmed if clinical teams started relying on alerts to identify at-risk patients without realizing that the prediction system underdetects patients in that group (automation bias) (16). If the model had a lower positive predictive value for African Americans, it might also disproportionately harm them through dismissal biasa generalization of alert fatigue in which clinicians may learn to discount or dismiss alerts for African Americans because they are more likely to be false-positive (17). Case Study 2: Reducing Length of Stay Imagine that a hospital created a model with clinical and social variables to predict which inpatients might be discharged earliest so that it could direct limited case management resources to them to prevent delays. If residence in ZIP codes of socioeconomically depressed or predominantly African American neighborhoods predicted greater lengths of stay (18), this model might disproportionately allocate case management resources to patients from richer, predominantly white neighborhoods and away from African Americans in poorer ones. What Is Machine Learning? Traditionally, computer systems map inputs to outputs according to manually specified ifthen rules. With increasingly complex tasks, such as language translation, manually specifying rules becomes infeasible, and instead the mapping (or model) is learned by the system given only input examples represented through a set of features together with their desired output, referred to as labels. The quality of a model is assessed by computing evaluation metrics on data not used to build the model, such as sensitivity, specificity, or the c-statistic, which measures the ability of a model to distinguish patients with a condition from those without it (19, 20). Once the model's quality is deemed satisfactory, it can be deployed to make predictions on new examples for which the label is unknown when the prediction is made. The quality of the models on retrospective data must be followed with tests of clinical effectiveness, safety, and comparison with current practice, which may require clinical trials (21). Traditionally, statistical models for prediction, such as the pooled-cohort equation (22), have used few variables to predict clinical outcomes, such as cardiovascular risk (23). Modern machine-learning techniques, however, can consider many more features. For example, a recent model to predict hospital readmissions examined hundreds of thousands of pieces of information, including the free text of clinical notes (24). Complex data and models can drive more personalized and accurate predictions but may also make algorithms hard to understand and trust (25). What Can Cause a Machine-Learning System to Be Unfair? The Glossary lists key biases in the design, data, and deployment of a machine-learning model that may perpetuate or exacerbate health care disparities if left unchecked. The Figure reveals how the various biases relate to one another and how the interactions of model predictions with clinicians and patients may exacerbate health care disparities. Biases may arise during the design of a model. For example, if the label is marred by health care disparities, such as predicting the onset of clinical depression in environments where protected groups have been systematically misdiagnosed, then the model will learn to perpetuate this disparity. This represents a generalization of test-referral bias (26) that we refer to as label bias. Moreover, the data on which the model is developed may be biased. Data on patients in the protected group might be distributed differently from those in the nonprotected group because of biological or nonbiological variation (9, 27). For example, the data may not contain enough examples from a group to properly tailor the predictions to them (minority bias) (28), or the data set of the protected group may be less informative because features are missing not at random as a result of more fragmented care (29, 30). Glossary Figure. Conceptual framework of how various biases relate to one another. During model development, differences in the distribution of features used to predict a label between the protected and nonprotected groups may bias a model to be less accurate for protected groups. Moreover, the data used to develop a model may not generalize to the data used during model deployment (trainingserving skew). Biases in model design and data affect patient outcomes through the model's interaction with clinicians and patients. The immediate effect of these differences is that the model may ",
        "link": "https://www.semanticscholar.org/paper/82a5a84528a7ca0409f75e2211a3b33a217e9bac",
        "published": "2018-12-04",
        "pdf_url": "https://europepmc.org/articles/pmc6594166?pdf=render",
        "txt_path": "data/txt/machine learning_paper_360.txt",
        "pdf_path": "data/pdfs/machine learning_paper_360.pdf"
    },
    {
        "title": "Machine Learning Approaches for Clinical Psychology and Psychiatry.",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/d5125164c7fec457d1442cce807a3436841715d0",
        "published": "2018-05-07",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_361.txt",
        "pdf_path": null
    },
    {
        "title": "Tunability: Importance of Hyperparameters of Machine Learning Algorithms",
        "abstract": "Modern supervised machine learning algorithms involve hyperparameters that have to be set before running them. Options for setting hyperparameters are default values from the software package, manual configuration by the user or configuring them for optimal predictive performance by a tuning procedure. The goal of this paper is two-fold. Firstly, we formalize the problem of tuning from a statistical point of view, define data-based defaults and suggest general measures quantifying the tunability of hyperparameters of algorithms. Secondly, we conduct a large-scale benchmarking study based on 38 datasets from the OpenML platform and six common machine learning algorithms. We apply our measures to assess the tunability of their parameters. Our results yield default values for hyperparameters and enable users to decide whether it is worth conducting a possibly time consuming tuning strategy, to focus on the most important hyperparameters and to chose adequate hyperparameter spaces for tuning.",
        "link": "https://www.semanticscholar.org/paper/64f6dab6b4bcf5cd792e352ea15aeca05572e21e",
        "published": "2018-02-26",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_362.txt",
        "pdf_path": null
    },
    {
        "title": "Extreme learning machine: a new learning scheme of feedforward neural networks",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/2b9c0e4d1d473aadbe1c2a76f75bc02bfa6416b0",
        "published": "2004-07-25",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_363.txt",
        "pdf_path": null
    },
    {
        "title": "A General-Purpose Machine Learning Framework for Predicting Properties of Inorganic Materials",
        "abstract": "A very active area of materials research is to devise methods that use machine learning to automatically extract predictive models from existing materials data. While prior examples have demonstrated successful models for some applications, many more applications exist where machine learning can make a strong impact. To enable faster development of machine-learning-based models for such applications, we have created a framework capable of being applied to a broad range of materials data. Our method works by using a chemically diverse list of attributes, which we demonstrate are suitable for describing a wide variety of properties, and a novel method for partitioning the data set into groups of similar materials in order to boost the predictive accuracy. In this manuscript, we demonstrate how this new method can be used to predict diverse properties of crystalline and amorphous materials, such as band gap energy and glass-forming ability.",
        "link": "https://www.semanticscholar.org/paper/a10bc90b3c97a4abe86c73cfb2a8490a9b44373f",
        "published": "2016-06-30",
        "pdf_url": "https://www.nature.com/articles/npjcompumats201628.pdf",
        "txt_path": "data/txt/machine learning_paper_364.txt",
        "pdf_path": "data/pdfs/machine learning_paper_364.pdf"
    },
    {
        "title": "Machine learning phases of matter",
        "abstract": "The success of machine learning techniques in handling big data sets proves ideal for classifying condensed-matter phases and phase transitions. The technique is even amenable to detecting non-trivial states lacking in conventional order. Condensed-matter physics is the study of the collective behaviour of infinitely complex assemblies of electrons, nuclei, magnetic moments, atoms or qubits1. This complexity is reflected in the size of the state space, which grows exponentially with the number of particles, reminiscent of the ‘curse of dimensionality’ commonly encountered in machine learning2. Despite this curse, the machine learning community has developed techniques with remarkable abilities to recognize, classify, and characterize complex sets of data. Here, we show that modern machine learning architectures, such as fully connected and convolutional neural networks3, can identify phases and phase transitions in a variety of condensed-matter Hamiltonians. Readily programmable through modern software libraries4,5, neural networks can be trained to detect multiple types of order parameter, as well as highly non-trivial states with no conventional order, directly from raw state configurations sampled with Monte Carlo6,7.",
        "link": "https://www.semanticscholar.org/paper/dd308eb0d7be24e593fe355476057fc37ab5bf0e",
        "published": "2016-03-17",
        "pdf_url": "https://arxiv.org/pdf/1605.01735",
        "txt_path": "data/txt/machine learning_paper_365.txt",
        "pdf_path": "data/pdfs/machine learning_paper_365.pdf"
    },
    {
        "title": "Stealing Hyperparameters in Machine Learning",
        "abstract": "Hyperparameters are critical in machine learning, as different hyperparameters often result in models with significantly different performance. Hyperparameters may be deemed confidential because of their commercial value and the confidentiality of the proprietary algorithms that the learner uses to learn them. In this work, we propose attacks on stealing the hyperparameters that are learned by a learner. We call our attacks hyperparameter stealing attacks. Our attacks are applicable to a variety of popular machine learning algorithms such as ridge regression, logistic regression, support vector machine, and neural network. We evaluate the effectiveness of our attacks both theoretically and empirically. For instance, we evaluate our attacks on Amazon Machine Learning. Our results demonstrate that our attacks can accurately steal hyperparameters. We also study countermeasures. Our results highlight the need for new defenses against our hyperparameter stealing attacks for certain machine learning algorithms.",
        "link": "https://www.semanticscholar.org/paper/0f5476c9629f8093e8ba8c6a41868415c6a7f2f1",
        "published": "2018-02-14",
        "pdf_url": "https://ieeexplore.ieee.org/ielx7/8418581/8418583/08418595.pdf",
        "txt_path": "data/txt/machine learning_paper_366.txt",
        "pdf_path": null
    },
    {
        "title": "Mol2vec: Unsupervised Machine Learning Approach with Chemical Intuition",
        "abstract": "Inspired by natural language processing techniques, we here introduce Mol2vec, which is an unsupervised machine learning approach to learn vector representations of molecular substructures. Like the Word2vec models, where vectors of closely related words are in close proximity in the vector space, Mol2vec learns vector representations of molecular substructures that point in similar directions for chemically related substructures. Compounds can finally be encoded as vectors by summing the vectors of the individual substructures and, for instance, be fed into supervised machine learning approaches to predict compound properties. The underlying substructure vector embeddings are obtained by training an unsupervised machine learning approach on a so-called corpus of compounds that consists of all available chemical matter. The resulting Mol2vec model is pretrained once, yields dense vector representations, and overcomes drawbacks of common compound feature representations such as sparseness and bit collisions. The prediction capabilities are demonstrated on several compound property and bioactivity data sets and compared with results obtained for Morgan fingerprints as a reference compound representation. Mol2vec can be easily combined with ProtVec, which employs the same Word2vec concept on protein sequences, resulting in a proteochemometric approach that is alignment-independent and thus can also be easily used for proteins with low sequence similarities.",
        "link": "https://www.semanticscholar.org/paper/88a99980f1f7eeac5f36be2e4601898988bdf937",
        "published": "2018-01-10",
        "pdf_url": "https://figshare.com/articles/journal_contribution/Mol2vec_Unsupervised_Machine_Learning_Approach_with_Chemical_Intuition/5773974/1/files/10184214.pdf",
        "txt_path": "data/txt/machine learning_paper_367.txt",
        "pdf_path": "data/pdfs/machine learning_paper_367.pdf"
    },
    {
        "title": "Machine-learning-guided directed evolution for protein engineering",
        "abstract": null,
        "link": "https://www.semanticscholar.org/paper/730fba26faa7f91dc6742a0c3521eb439670a825",
        "published": "2018-11-27",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_368.txt",
        "pdf_path": null
    },
    {
        "title": "A Survey on Data Collection for Machine Learning: A Big Data - AI Integration Perspective",
        "abstract": "Data collection is a major bottleneck in machine learning and an active research topic in multiple communities. There are largely two reasons data collection has recently become a critical issue. First, as machine learning is becoming more widely-used, we are seeing new applications that do not necessarily have enough labeled data. Second, unlike traditional machine learning, deep learning techniques automatically generate features, which saves feature engineering costs, but in return may require larger amounts of labeled data. Interestingly, recent research in data collection comes not only from the machine learning, natural language, and computer vision communities, but also from the data management community due to the importance of handling large amounts of data. In this survey, we perform a comprehensive study of data collection from a data management point of view. Data collection largely consists of data acquisition, data labeling, and improvement of existing data or models. We provide a research landscape of these operations, provide guidelines on which technique to use when, and identify interesting research challenges. The integration of machine learning and data management for data collection is part of a larger trend of Big data and Artificial Intelligence (AI) integration and opens many opportunities for new research.",
        "link": "https://www.semanticscholar.org/paper/3a83d8595e6727269c876fcebd23ee9ddd524b76",
        "published": "2018-11-08",
        "pdf_url": "https://arxiv.org/pdf/1811.03402",
        "txt_path": "data/txt/machine learning_paper_369.txt",
        "pdf_path": "data/pdfs/machine learning_paper_369.pdf"
    },
    {
        "title": "eDoctor: machine learning and the future of medicine",
        "abstract": "Machine learning (ML) is a burgeoning field of medicine with huge resources being applied to fuse computer science and statistics to medical problems. Proponents of ML extol its ability to deal with large, complex and disparate data, often found within medicine and feel that ML is the future for biomedical research, personalized medicine, computer‐aided diagnosis to significantly advance global health care. However, the concepts of ML are unfamiliar to many medical professionals and there is untapped potential in the use of ML as a research tool. In this article, we provide an overview of the theory behind ML, explore the common ML algorithms used in medicine including their pitfalls and discuss the potential future of ML in medicine.",
        "link": "https://www.semanticscholar.org/paper/70f6937b6253db8209d8fd6a4115e766946f04c5",
        "published": "2018-09-03",
        "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/joim.12822",
        "txt_path": "data/txt/machine learning_paper_370.txt",
        "pdf_path": null
    },
    {
        "title": "Super-resolution reconstruction of turbulent flows with machine learning",
        "abstract": "We use machine learning to perform super-resolution analysis of grossly under-resolved turbulent flow field data to reconstruct the high-resolution flow field. Two machine learning models are developed, namely, the convolutional neural network (CNN) and the hybrid downsampled skip-connection/multi-scale (DSC/MS) models. These machine learning models are applied to a two-dimensional cylinder wake as a preliminary test and show remarkable ability to reconstruct laminar flow from low-resolution flow field data. We further assess the performance of these models for two-dimensional homogeneous turbulence. The CNN and DSC/MS models are found to reconstruct turbulent flows from extremely coarse flow field images with remarkable accuracy. For the turbulent flow problem, the machine-leaning-based super-resolution analysis can greatly enhance the spatial resolution with as little as 50 training snapshot data, holding great potential to reveal subgrid-scale physics of complex turbulent flows. With the growing availability of flow field data from high-fidelity simulations and experiments, the present approach motivates the development of effective super-resolution models for a variety of fluid flows.",
        "link": "https://www.semanticscholar.org/paper/a0390b8d4a82daa1d24bba341b317aa710e4ce4d",
        "published": "2018-11-28",
        "pdf_url": "https://arxiv.org/pdf/1811.11328",
        "txt_path": "data/txt/machine learning_paper_371.txt",
        "pdf_path": "data/pdfs/machine learning_paper_371.pdf"
    },
    {
        "title": "Current Applications and Future Impact of Machine Learning in Radiology.",
        "abstract": "Recent advances and future perspectives of machine learning techniques offer promising applications in medical imaging. Machine learning has the potential to improve different steps of the radiology workflow including order scheduling and triage, clinical decision support systems, detection and interpretation of findings, postprocessing and dose estimation, examination quality control, and radiology reporting. In this article, the authors review examples of current applications of machine learning and artificial intelligence techniques in diagnostic radiology. In addition, the future impact and natural extension of these techniques in radiology practice are discussed.",
        "link": "https://www.semanticscholar.org/paper/5fdc2223709079ba5c0f78661cdf66cec2173258",
        "published": "2018-06-26",
        "pdf_url": "https://europepmc.org/articles/pmc6542626?pdf=render",
        "txt_path": "data/txt/machine learning_paper_372.txt",
        "pdf_path": "data/pdfs/machine learning_paper_372.pdf"
    },
    {
        "title": "Interpretable Machine Learning in Healthcare",
        "abstract": "This tutorial extensively covers the definitions, nuances, challenges, and requirements for the design of interpretable and explainable machine learning models and systems in healthcare. We discuss many uses in which interpretable machine learning models are needed in healthcare and how they should be deployed. Additionally, we explore the landscape of recent advances to address the challenges model interpretability in healthcare and also describe how one would go about choosing the right interpretable machine learnig algorithm for a given problem in healthcare.",
        "link": "https://www.semanticscholar.org/paper/7d065e649e3bfc7d6d36166f50eab37b8404eae0",
        "published": "2018-06-01",
        "pdf_url": "",
        "txt_path": "data/txt/machine learning_paper_373.txt",
        "pdf_path": null
    },
    {
        "title": "iml: An R package for Interpretable Machine Learning",
        "abstract": "Complex, non-parametric models, which are typically used in machine learning, have proven to be successful in many prediction tasks. But these models usually operate as black boxes: While they are good at predicting, they are often not interpretable. Many inherently interpretable models have been suggested, which come at the cost of losing predictive power. Another option is to apply interpretability methods to a black box model after model training. Given the velocity of research on new machine learning models, it is preferable to have model-agnostic tools which can be applied to a random forest as well as to a neural network. Tools for model-agnostic interpretability methods should improve the adoption of machine learning.",
        "link": "https://www.semanticscholar.org/paper/ea7887fadc666d6faf92e569d4a10d994ee91297",
        "published": "2018-06-27",
        "pdf_url": "https://joss.theoj.org/papers/10.21105/joss.00786.pdf",
        "txt_path": "data/txt/machine learning_paper_374.txt",
        "pdf_path": "data/pdfs/machine learning_paper_374.pdf"
    },
    {
        "title": "Machine Learning from Theory to Algorithms: An Overview",
        "abstract": "The current SMAC (Social, Mobile, Analytic, Cloud) technology trend paves the way to a future in which intelligent machines, networked processes and big data are brought together. This virtual world has generated vast amount of data which is accelerating the adoption of machine learning solutions & practices. Machine Learning enables computers to imitate and adapt human-like behaviour. Using machine learning, each interaction, each action performed, becomes something the system can learn and use as experience for the next time. This work is an overview of this data analytics method which enables computers to learn and do what comes naturally to humans, i.e. learn from experience. It includes the preliminaries of machine learning, the definition, nomenclature and applications’ describing it’s what, how and why. The technology roadmap of machine learning is discussed to understand and verify its potential as a market & industry practice. The primary intent of this work is to give insight into why machine learning is the future.",
        "link": "https://www.semanticscholar.org/paper/6d67ddd0855c60ada2fb4151f0f944feffdaf357",
        "published": "2018-11-01",
        "pdf_url": "https://doi.org/10.1088/1742-6596/1142/1/012012",
        "txt_path": "data/txt/machine learning_paper_375.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning with sklearn",
        "abstract": "<p>This chapter’s goal is to show how to apply machine learning algorithms in a general setting using some classic methods. In particular, it demonstrates how to apply three important machine learning algorithms, a support vector classifier (SVC), a random forest classifier (RFC), and a multilayer perceptron (MLP). While many of the methods studied later go beyond these now classic methods, this does not mean that these methods are obsolete. Also, the algorithms discussed here provide some form of baseline to discuss advanced methods like probabilistic reasoning and deep learning. The aim here is to demonstrate that applying machine learning methods based on machine learning libraries is not very difficult. It offers an opportunity to discuss evaluation techniques that are very important in practice.</p>",
        "link": "https://doi.org/10.1093/oso/9780198828044.003.0003",
        "published": "2020-01-23T10:54:18Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_376.txt",
        "pdf_path": null
    },
    {
        "title": "Optimization and Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1002/9781119902881",
        "published": "2022-02-25T22:49:03Z",
        "pdf_url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119902881",
        "txt_path": "data/txt/machine learning_paper_377.txt",
        "pdf_path": null
    },
    {
        "title": "Why Use Automated Machine Learning?",
        "abstract": "<p>Machine learning is involved in search, translation, detecting depression, likelihood of college dropout, finding lost children, and to sell all kinds of products. While barely beyond its inception, the current machine learning revolution will affect people and organizations no less than the Industrial Revolution’s effect on weavers and many other skilled laborers. Machine learning will automate hundreds of millions of jobs that were considered too complex for machines ever to take over even a decade ago, including driving, flying, painting, programming, and customer service, as well as many of the jobs previously reserved for humans in the fields of finance, marketing, operations, accounting, and human resources. This section explains how automated machine learning addresses exploratory data analysis, feature engineering, algorithm selection, hyperparameter tuning, and model diagnostics. The section covers the eight criteria considered essential for AutoML to have significant impact: <italic>accuracy, productivity, ease of use, understanding and learning, resource availability, process transparency, generalization</italic>, and <italic>recommended actions.</italic>\n               </p>",
        "link": "https://doi.org/10.1093/oso/9780190941659.003.0001",
        "published": "2021-07-21T12:49:28Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_378.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning and Grammar Induction",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022808826027",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022808826027.pdf",
        "txt_path": "data/txt/machine learning_paper_379.txt",
        "pdf_path": "data/pdfs/machine learning_paper_379.pdf"
    },
    {
        "title": "Editorial: Human and Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022854429410",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022854429410.pdf",
        "txt_path": "data/txt/machine learning_paper_380.txt",
        "pdf_path": "data/pdfs/machine learning_paper_380.pdf"
    },
    {
        "title": "Machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/cbo9780511804779.017",
        "published": "2012-06-19T17:06:44Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/DE69032737ABE83A631835141D577DCB",
        "txt_path": "data/txt/machine learning_paper_381.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/cbo9780511975509.007",
        "published": "2012-08-08T15:35:08Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/05C394CE4126A5C0ACCF582BC37377A3",
        "txt_path": "data/txt/machine learning_paper_382.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning and Qualitative Reasoning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022661713654",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022661713654.pdf",
        "txt_path": "data/txt/machine learning_paper_383.txt",
        "pdf_path": "data/pdfs/machine learning_paper_383.pdf"
    },
    {
        "title": "Research Papers in Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022603230145",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022603230145.pdf",
        "txt_path": "data/txt/machine learning_paper_384.txt",
        "pdf_path": "data/pdfs/machine learning_paper_384.pdf"
    },
    {
        "title": "Machine Learning and Concept Formation",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022896407371",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022896407371.pdf",
        "txt_path": "data/txt/machine learning_paper_385.txt",
        "pdf_path": "data/pdfs/machine learning_paper_385.pdf"
    },
    {
        "title": "Front Matter",
        "abstract": "",
        "link": "https://doi.org/10.1002/9781119902881.fmatter",
        "published": "2022-02-25T22:49:03Z",
        "pdf_url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119902881.fmatter",
        "txt_path": "data/txt/machine learning_paper_386.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning: A Maturing Field",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022665512030",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022665512030.pdf",
        "txt_path": "data/txt/machine learning_paper_387.txt",
        "pdf_path": "data/pdfs/machine learning_paper_387.pdf"
    },
    {
        "title": "Machine learning and medical education",
        "abstract": "",
        "link": "https://doi.org/10.37473//10.1038/s41746-018-0061-1",
        "published": "2020-02-28T10:24:42Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_388.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning as an Experimental Science",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022623814640",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022623814640.pdf",
        "txt_path": "data/txt/machine learning_paper_389.txt",
        "pdf_path": "data/pdfs/machine learning_paper_389.pdf"
    },
    {
        "title": "Machine learning concepts",
        "abstract": "",
        "link": "https://doi.org/10.1017/cbo9780511804779.018",
        "published": "2012-06-19T17:06:44Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/E2A1F5DB3763133F0BE4490E98FC7980",
        "txt_path": "data/txt/machine learning_paper_390.txt",
        "pdf_path": null
    },
    {
        "title": "Index",
        "abstract": "",
        "link": "https://doi.org/10.1002/9781119902881.index",
        "published": "2022-02-25T22:49:03Z",
        "pdf_url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119902881.index",
        "txt_path": "data/txt/machine learning_paper_391.txt",
        "pdf_path": null
    },
    {
        "title": "Editorial: Advice to Machine Learning Authors",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022647305786",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022647305786.pdf",
        "txt_path": "data/txt/machine learning_paper_392.txt",
        "pdf_path": "data/pdfs/machine learning_paper_392.pdf"
    },
    {
        "title": "Editorial: The Terminology of Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022840627593",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022840627593.pdf",
        "txt_path": "data/txt/machine learning_paper_393.txt",
        "pdf_path": "data/pdfs/machine learning_paper_393.pdf"
    },
    {
        "title": "Adversarial Machine Learning Challenges",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781107338548.009",
        "published": "2019-03-14T03:14:16Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_394.txt",
        "pdf_path": null
    },
    {
        "title": "3. Machine Learning Applications",
        "abstract": "",
        "link": "https://doi.org/10.1561/9781638280538.ch3",
        "published": "2022-10-17T12:58:02Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_395.txt",
        "pdf_path": null
    },
    {
        "title": "New Theoretical Directions In Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022817027844",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022817027844.pdf",
        "txt_path": "data/txt/machine learning_paper_396.txt",
        "pdf_path": "data/pdfs/machine learning_paper_396.pdf"
    },
    {
        "title": "Einleitung: Vom Batch Machine Learning zum Online Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-658-42505-0_1",
        "published": "2024-07-22T17:02:37Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-658-42505-0_1",
        "txt_path": "data/txt/machine learning_paper_397.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Overview",
        "abstract": "",
        "link": "https://doi.org/10.5772/9374",
        "published": "2012-04-03T07:55:00Z",
        "pdf_url": "https://www.intechopen.com/download/pdf/10683",
        "txt_path": "data/txt/machine learning_paper_398.txt",
        "pdf_path": null
    },
    {
        "title": "Toward a Unified Science of Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022689616458",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022689616458.pdf",
        "txt_path": "data/txt/machine learning_paper_399.txt",
        "pdf_path": "data/pdfs/machine learning_paper_399.pdf"
    },
    {
        "title": "Machine learning vs. neutrosophic machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1201/9781003606055-5",
        "published": "2025-03-26T14:20:24Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_400.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning, Statistics, and Data Analytics",
        "abstract": "",
        "link": "https://doi.org/10.7551/mitpress/13811.003.0005",
        "published": "2021-08-22T13:21:32Z",
        "pdf_url": "https://direct.mit.edu/books/book/chapter-pdf/2442233/c001800_9780262365369.pdf",
        "txt_path": "data/txt/machine learning_paper_401.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in Context",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-08-050930-3.50018-x",
        "published": "2014-06-30T00:24:55Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B978008050930350018X?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_402.txt",
        "pdf_path": null
    },
    {
        "title": "Einleitung: Vom Batch Machine Learning zum Online Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-658-46162-1_1",
        "published": "2024-09-19T14:13:15Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-658-46162-1_1",
        "txt_path": "data/txt/machine learning_paper_403.txt",
        "pdf_path": null
    },
    {
        "title": "Learning Curves in Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-0-387-30164-8_452",
        "published": "2010-12-29T17:28:18Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-0-387-30164-8_452",
        "txt_path": "data/txt/machine learning_paper_404.txt",
        "pdf_path": null
    },
    {
        "title": "Application of machine learning algorithms for prediction of sinter machine productivity",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2021.100186",
        "published": "2021-10-19T14:15:54Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827021000931?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_405.txt",
        "pdf_path": null
    },
    {
        "title": "Statistics for machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/cbo9780511804779.012",
        "published": "2012-06-19T17:06:44Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/E7FBD4DAEDC949A5208DEF16900243B8",
        "txt_path": "data/txt/machine learning_paper_406.txt",
        "pdf_path": null
    },
    {
        "title": "Introduction to Machine Learning and Supervised Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-981-99-3917-6_1",
        "published": "2023-12-06T00:02:11Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-981-99-3917-6_1",
        "txt_path": "data/txt/machine learning_paper_407.txt",
        "pdf_path": null
    },
    {
        "title": "COMPREHENSIVE BIBLIOGRAPHY OF MACHINE LEARNING",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-08-051054-5.50021-2",
        "published": "2014-06-29T22:28:35Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9780080510545500212?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_408.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-12-800953-6.00002-5",
        "published": "2014-09-29T19:34:39Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9780128009536000025?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_409.txt",
        "pdf_path": null
    },
    {
        "title": "Editorial: Machine Learning and Discovery",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022814715297",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022814715297.pdf",
        "txt_path": "data/txt/machine learning_paper_410.txt",
        "pdf_path": "data/pdfs/machine learning_paper_410.pdf"
    },
    {
        "title": "Capacity Estimation Using Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781108966559.013",
        "published": "2022-06-16T00:05:40Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_411.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Models",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781108552332.004",
        "published": "2020-06-30T06:25:44Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_412.txt",
        "pdf_path": null
    },
    {
        "title": "Reinforcement learning",
        "abstract": "<p>The discussion here considers a much more common learning condition where an agent, such as a human or a robot, has to learn to make decisions in the environment from simple feedback. Such feedback is provided only after periods of actions in the form of reward or punishment without detailing which of the actions has contributed to the outcome. This type of learning scenario is called reinforcement learning. This learning problem is formalized in a Markov decision-making process with a variety of related algorithms. The second part of this chapter will use function approximators with neural networks which have made recent progress as deep reinforcement learning.</p>",
        "link": "https://doi.org/10.1093/oso/9780198828044.003.0010",
        "published": "2020-01-23T10:53:53Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_413.txt",
        "pdf_path": null
    },
    {
        "title": "Statistical physics and machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/cbo9780511975509.009",
        "published": "2012-08-08T15:35:08Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/896ECD043981CD65C0F08839BC0F557E",
        "txt_path": "data/txt/machine learning_paper_414.txt",
        "pdf_path": null
    },
    {
        "title": "Wireless Networks for Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781108966559.014",
        "published": "2022-06-16T00:05:40Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_415.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning for Wireless Networks",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781108966559.003",
        "published": "2022-06-16T00:05:40Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_416.txt",
        "pdf_path": null
    },
    {
        "title": "Introduction to Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1201/9781315371658-9",
        "published": "2016-08-09T09:13:28Z",
        "pdf_url": "http://www.crcnetbase.com/doi/pdf/10.1201/9781315371658-9",
        "txt_path": "data/txt/machine learning_paper_417.txt",
        "pdf_path": null
    },
    {
        "title": "Monotonicity Maintenance in Information-Theoretic Machine Learning Algorithms",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022655006810",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022655006810.pdf",
        "txt_path": "data/txt/machine learning_paper_418.txt",
        "pdf_path": "data/pdfs/machine learning_paper_418.pdf"
    },
    {
        "title": "Why We Are Interested in Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.7551/mitpress/13811.003.0004",
        "published": "2021-08-22T13:21:32Z",
        "pdf_url": "https://direct.mit.edu/books/book/chapter-pdf/2442232/c000500_9780262365369.pdf",
        "txt_path": "data/txt/machine learning_paper_419.txt",
        "pdf_path": null
    },
    {
        "title": "List of Authors",
        "abstract": "",
        "link": "https://doi.org/10.1002/9781119902881.contrib",
        "published": "2022-02-25T22:49:03Z",
        "pdf_url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119902881.contrib",
        "txt_path": "data/txt/machine learning_paper_420.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning: An Overview",
        "abstract": "",
        "link": "https://doi.org/10.1201/b23383-3",
        "published": "2023-10-11T11:08:37Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_421.txt",
        "pdf_path": null
    },
    {
        "title": "Introduction to Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.5772/9394",
        "published": "2012-04-03T07:55:00Z",
        "pdf_url": "https://www.intechopen.com/download/pdf/10703",
        "txt_path": "data/txt/machine learning_paper_422.txt",
        "pdf_path": null
    },
    {
        "title": "Channel Coding via Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781108966559.006",
        "published": "2022-06-16T00:05:40Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_423.txt",
        "pdf_path": null
    },
    {
        "title": "Optimization for Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781009072205.008",
        "published": "2023-01-25T00:05:52Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_424.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning and Medicine",
        "abstract": "",
        "link": "https://doi.org/10.3390/books978-3-7258-4564-4",
        "published": "2025-07-24T09:49:36Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_425.txt",
        "pdf_path": null
    },
    {
        "title": "Developing Machine Learning Skills With No-Code Machine Learning Tools",
        "abstract": "<jats:p>No-code machine learning (ML) tools provide an avenue for individuals who lack advanced ML skills to develop ML applications. Extant literature indicates that by using such tools, individuals can acquire relevant ML skills. However, no explanation has been provided of how the use of no-code ML tools leads to the generation of these skills. Using the theory of technology affordances and constraints, this article undertakes a qualitative evaluation of publicly available no-code ML tools to explain how their usage can lead to the formation of relevant ML skills. Subsequently, the authors show that no-code ML tools generate familiarization affordances, utilization affordances, and administration affordances. Subsequently, they provide a conceptual framework and process model that depicts how these affordances lead to the generating of ML skills.</jats:p>",
        "link": "https://doi.org/10.4018/978-1-7998-9220-5.ch097",
        "published": "2023-01-20T15:44:01Z",
        "pdf_url": "https://www.igi-global.com/viewtitle.aspx?TitleId=317574",
        "txt_path": "data/txt/machine learning_paper_426.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning for Information Extraction in Informal Domains",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007601113994",
        "published": "2002-12-22T05:54:50Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007601113994.pdf",
        "txt_path": "data/txt/machine learning_paper_427.txt",
        "pdf_path": "data/pdfs/machine learning_paper_427.pdf"
    },
    {
        "title": "Applications of Machine Learning in cricket: A systematic review",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2022.100435",
        "published": "2022-12-05T09:05:14Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827022001104?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_428.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Algorithm in Agricultural Machine Vision System",
        "abstract": "",
        "link": "https://doi.org/10.38007/ml.2020.010404",
        "published": "2023-02-06T01:57:18Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_429.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Basics",
        "abstract": "",
        "link": "https://doi.org/10.1201/9780429448782-2",
        "published": "2019-12-17T12:05:05Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_430.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1201/9781003126898-1",
        "published": "2022-01-14T21:58:59Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_431.txt",
        "pdf_path": null
    },
    {
        "title": "Fundamentals of kernel-based machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/cbo9781139176224.003",
        "published": "2014-07-15T06:09:58Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/D0DC65C56B30407B5FD05EDC5709108D",
        "txt_path": "data/txt/machine learning_paper_432.txt",
        "pdf_path": null
    },
    {
        "title": "Basics of machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781009504942.004",
        "published": "2025-06-13T00:05:29Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_433.txt",
        "pdf_path": null
    },
    {
        "title": "Figure 2.1: How machine learning works",
        "abstract": "",
        "link": "https://doi.org/10.3998/mpub.12205632.cmp.5",
        "published": "2023-04-13T12:36:13Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_434.txt",
        "pdf_path": null
    },
    {
        "title": "The Consequences of Personalized Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781009003971.010",
        "published": "2022-01-20T00:05:52Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/5FD86EE8B548CD0430BDCD15F052E92E",
        "txt_path": "data/txt/machine learning_paper_435.txt",
        "pdf_path": null
    },
    {
        "title": "Genetic Algorithms and Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022602019183",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf",
        "txt_path": "data/txt/machine learning_paper_436.txt",
        "pdf_path": "data/pdfs/machine learning_paper_436.pdf"
    },
    {
        "title": "Supervised Learning",
        "abstract": "<p>This chapter provides a brief overview of supervised learning methods as the literature on this topic is vast and rapidly evolving. It focuses on the basic elements of these techniques that seem particularly useful for asset pricing and looks at the material on some of those methods in more detail by reviewing asset pricing applications. Supervised learning methods can be grouped into two categories: classification and regression methods. The chapter explains that classification methods are used in settings where the dependent variable <italic>y</italic> is categorial, while regression methods deal with continuous dependent variables. In asset pricing applications, regression problems are more common, although classification methods can also be useful, for example for prediction of binary events like a corporate default.</p>",
        "link": "https://doi.org/10.23943/princeton/9780691218700.003.0002",
        "published": "2022-05-23T12:43:37Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_437.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in Spill Regulation",
        "abstract": "",
        "link": "https://doi.org/10.2172/2361071",
        "published": "2024-05-26T02:05:37Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_438.txt",
        "pdf_path": null
    },
    {
        "title": "paws.machine.learning: 'Amazon Web Services' Machine Learning Services",
        "abstract": "",
        "link": "https://doi.org/10.32614/cran.package.paws.machine.learning",
        "published": "2024-06-13T10:16:47Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_439.txt",
        "pdf_path": null
    },
    {
        "title": "Tiny Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/979-8-8688-1294-1_1",
        "published": "2025-04-15T13:35:27Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/979-8-8688-1294-1_1",
        "txt_path": "data/txt/machine learning_paper_440.txt",
        "pdf_path": null
    },
    {
        "title": "An Interactive Attention Network with Stacked Ensemble Machine Learning Models for Recommendations",
        "abstract": "",
        "link": "https://doi.org/10.1002/9781119902881.ch5",
        "published": "2022-02-25T22:49:03Z",
        "pdf_url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119902881.ch5",
        "txt_path": "data/txt/machine learning_paper_441.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning for Functional Brain Mapping",
        "abstract": "",
        "link": "https://doi.org/10.5772/8605",
        "published": "2012-03-29T03:50:50Z",
        "pdf_url": "https://www.intechopen.com/download/pdf/9822",
        "txt_path": "data/txt/machine learning_paper_442.txt",
        "pdf_path": null
    },
    {
        "title": "Types of Machine Learning Algorithms",
        "abstract": "",
        "link": "https://doi.org/10.5772/9385",
        "published": "2012-04-03T03:55:00Z",
        "pdf_url": "https://www.intechopen.com/download/pdf/10694",
        "txt_path": "data/txt/machine learning_paper_443.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning and medical education",
        "abstract": "",
        "link": "https://doi.org/10.37473/dac/10.1038/s41746-018-0061-1",
        "published": "2020-02-28T15:27:47Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_444.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning and kernel vector spaces",
        "abstract": "",
        "link": "https://doi.org/10.1017/cbo9781139176224.002",
        "published": "2014-07-15T06:09:58Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/76F4C1E1963CB6EAD12BCF3A36330E51",
        "txt_path": "data/txt/machine learning_paper_445.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Applications",
        "abstract": "",
        "link": "https://doi.org/10.1201/9780429448782-10",
        "published": "2019-12-17T12:05:05Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_446.txt",
        "pdf_path": null
    },
    {
        "title": "Genetics-Based Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-0-387-30164-8_341",
        "published": "2010-12-29T17:43:13Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-0-387-30164-8_341",
        "txt_path": "data/txt/machine learning_paper_447.txt",
        "pdf_path": null
    },
    {
        "title": "GLOSSARY OF SELECTED TERMS IN MACHINE LEARNING",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-08-051054-5.50022-4",
        "published": "2014-06-29T18:28:35Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9780080510545500224?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_448.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning for machine vision",
        "abstract": "",
        "link": "https://doi.org/10.1017/cbo9780511996504.009",
        "published": "2012-08-08T15:38:52Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/A538A38DA5646CE05B938608E8B5E18B",
        "txt_path": "data/txt/machine learning_paper_449.txt",
        "pdf_path": null
    },
    {
        "title": "Multitask Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007379606734",
        "published": "2002-12-22T04:48:21Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007379606734.pdf",
        "txt_path": "data/txt/machine learning_paper_450.txt",
        "pdf_path": "data/pdfs/machine learning_paper_450.pdf"
    },
    {
        "title": "LEARNABLE EVOLUTION MODEL: Evolutionary Processes Guided by Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007677805582",
        "published": "2002-12-22T05:54:50Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007677805582.pdf",
        "txt_path": "data/txt/machine learning_paper_451.txt",
        "pdf_path": "data/pdfs/machine learning_paper_451.pdf"
    },
    {
        "title": "SOMs for Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.5772/9137",
        "published": "2012-03-23T15:40:22Z",
        "pdf_url": "https://www.intechopen.com/download/pdf/10428",
        "txt_path": "data/txt/machine learning_paper_452.txt",
        "pdf_path": null
    },
    {
        "title": "Model-Based Machine Learning for Communications",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781108966559.008",
        "published": "2022-06-16T00:05:40Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_453.txt",
        "pdf_path": null
    },
    {
        "title": "Projection Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007678005361",
        "published": "2002-12-22T05:54:50Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007678005361.pdf",
        "txt_path": "data/txt/machine learning_paper_454.txt",
        "pdf_path": "data/pdfs/machine learning_paper_454.pdf"
    },
    {
        "title": "Machine Learning Preliminaries",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-031-01580-9_2",
        "published": "2022-06-09T13:16:47Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-031-01580-9_2",
        "txt_path": "data/txt/machine learning_paper_455.txt",
        "pdf_path": null
    },
    {
        "title": "Can Machine Learning Offer Anything to Expert Systems?",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022646520981",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022646520981.pdf",
        "txt_path": "data/txt/machine learning_paper_456.txt",
        "pdf_path": "data/pdfs/machine learning_paper_456.pdf"
    },
    {
        "title": "Democratizing Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1002/9781394272426.ch14",
        "published": "2025-07-25T21:17:31Z",
        "pdf_url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781394272426.ch14",
        "txt_path": "data/txt/machine learning_paper_457.txt",
        "pdf_path": null
    },
    {
        "title": "azuremlsdk: Interface to the 'Azure Machine Learning' 'SDK'",
        "abstract": "",
        "link": "https://doi.org/10.32614/cran.package.azuremlsdk",
        "published": "2024-06-11T10:02:56Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_458.txt",
        "pdf_path": null
    },
    {
        "title": "A Comparison of Machine Learning and Deep Learning Models with Advanced Word Embeddings: The Case of Internal Audit Reports",
        "abstract": "",
        "link": "https://doi.org/10.1002/9781119902881.ch6",
        "published": "2022-02-25T22:49:03Z",
        "pdf_url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119902881.ch6",
        "txt_path": "data/txt/machine learning_paper_459.txt",
        "pdf_path": null
    },
    {
        "title": "Classification Accuracy: Machine Learning vs. Explicit Knowledge Acquisition",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022826724635",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022826724635.pdf",
        "txt_path": "data/txt/machine learning_paper_460.txt",
        "pdf_path": "data/pdfs/machine learning_paper_460.pdf"
    },
    {
        "title": "Classification Techniques in Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1002/9781394325634.ch4",
        "published": "2024-10-08T16:48:48Z",
        "pdf_url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781394325634.ch4",
        "txt_path": "data/txt/machine learning_paper_461.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning and Communications: An Introduction",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781108966559.002",
        "published": "2022-06-16T00:05:40Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_462.txt",
        "pdf_path": null
    },
    {
        "title": "Defining Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.4135/9781071982624",
        "published": "2025-01-23T10:43:16Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_463.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-4842-7098-1_2",
        "published": "2021-07-29T20:04:30Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-1-4842-7098-1_2",
        "txt_path": "data/txt/machine learning_paper_464.txt",
        "pdf_path": null
    },
    {
        "title": "Introduction: A Sampler in Knowledge Acquisition for the Machine Learning Community",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022694404143",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022694404143.pdf",
        "txt_path": "data/txt/machine learning_paper_465.txt",
        "pdf_path": "data/pdfs/machine learning_paper_465.pdf"
    },
    {
        "title": "A Machine Learning Approach to POS Tagging",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007673816718",
        "published": "2002-12-22T05:54:50Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007673816718.pdf",
        "txt_path": "data/txt/machine learning_paper_466.txt",
        "pdf_path": "data/pdfs/machine learning_paper_466.pdf"
    },
    {
        "title": "Review on Machine Learning Strategies for Real-World Engineering Applications",
        "abstract": "<jats:p>As we enter the Industry 5.0 era, enormous volumes of data are being created across digital systems. Machine learning techniques have recently achieved immense success in areas such as intelligent control, decision-making, speech recognition, natural language processing, computer graphics, and computer vision. This despite the significant challenge of analyzing and interpreting massive datasets. Owing to their strong performance, deep learning and machine learning algorithms have become widely deployed across various real-time engineering applications. Developing working knowledge of machine learning is now critical for building automated, smart systems that can process data in domains like healthcare, cybersecurity, and intelligent transportation. There exist multiple strategies in machine learning, including reinforcement learning, semi-supervised learning, unsupervised learning, and supervised learning algorithms. This research provides a comprehensive examination of leveraging machine learning for managing real-time engineering systems, with the goal of augmenting their capabilities and intelligence. It contributes to the understanding of how different machine learning approaches can be applied in real-world use cases like cybersecurity, healthcare, and intelligent transportation. Additionally, it highlights ongoing research objectives and difficulties that machine learning techniques encounter while tackling real-world systems. This research serves both industry professionals and academics as a reference, while technically benchmarking decision-making across different application areas and real-world scenarios.</jats:p>",
        "link": "https://doi.org/10.58496/bjml/2023/001",
        "published": "2024-03-22T10:44:11Z",
        "pdf_url": "https://mesopotamian.press/journals/index.php/BJML/article/download/204/194",
        "txt_path": "data/txt/machine learning_paper_467.txt",
        "pdf_path": null
    },
    {
        "title": "Defining Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.4135/9781071982471",
        "published": "2025-01-15T15:44:14Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_468.txt",
        "pdf_path": null
    },
    {
        "title": "Overview of Machine Learning in Geomechanics",
        "abstract": "",
        "link": "https://doi.org/10.1002/9781394325634.ch1",
        "published": "2024-10-08T16:48:48Z",
        "pdf_url": "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781394325634.ch1",
        "txt_path": "data/txt/machine learning_paper_469.txt",
        "pdf_path": null
    },
    {
        "title": "Discrepancy Modeling with Physics Informed Machine Learning",
        "abstract": "<jats:p>This video describes how to combine machine learning with classical physics models to correct for discrepancies in the data (e.g., from nonlinear friction, wind resistance, etc.). Several examples are covered, from modern robotics, to classical connections with Galileo v. Aristotle, and Kepler v. Ptolemy. The examples in this video highlight work and discussions with Prof. Nathan Kutz, especially connections to classical scientific discoveries.</jats:p>",
        "link": "https://doi.org/10.52843/cassyni.ftzlk9",
        "published": "2023-03-28T17:00:31Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_470.txt",
        "pdf_path": null
    },
    {
        "title": "BIBLIOGRAPHY OF RECENT MACHINE LEARNING RESEARCH 1985–1989",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-08-051055-2.50033-x",
        "published": "2014-06-29T21:19:17Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B978008051055250033X?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_471.txt",
        "pdf_path": null
    },
    {
        "title": "A Reply to Hellerstein's Book Review of Machine Learning: A Theoretical Approach",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022643815046",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022643815046.pdf",
        "txt_path": "data/txt/machine learning_paper_472.txt",
        "pdf_path": "data/pdfs/machine learning_paper_472.pdf"
    },
    {
        "title": "Ensemble Machine Learning Model for Software Defect Prediction",
        "abstract": "<jats:p>Software defect prediction is a significant activity in every software firm. It helps in producing quality software by reliable defect prediction, defect elimination, and prediction of modules that are susceptible to defect. Several researchers have proposed different software prediction approaches in the past. However, these conventional software defect predictions are prone to low classification accuracy, time-consuming, and tasking. This paper aims to develop a novel multi-model ensemble machine-learning for software defect prediction. The ensemble technique can reduce inconsistency among training and test datasets and eliminate bias in the training and testing phase of the model, thereby overcoming the downsides that have characterized the existing techniques used for the prediction of a software defect. To address these shortcomings, this paper proposes a new ensemble machine-learning model for software defect prediction using k Nearest Neighbour (kNN), Generalized Linear Model with Elastic Net Regularization (GLMNet), and Linear Discriminant Analysis (LDA) with Random Forest as base learner. Experiments were conducted using the proposed model on CM1, JM1, KC3, and PC3 datasets from the NASA PROMISE repository using the RStudio simulation tool. The ensemble technique achieved 87.69% for CM1 dataset, 81.11% for JM1 dataset, 90.70% for PC3 dataset, and 94.74% for KC3 dataset. The performance of the proposed system was compared with that of other existing techniques in literature in terms of AUC. The ensemble technique achieved 87%, which is better than the other seven state-of-the-art techniques under consideration. On average, the proposed model achieved an overall prediction accuracy of 88.56% for all datasets used for experiments. The results demonstrated that the ensemble model succeeded in effectively predicting the defects in PROMISE datasets that are notorious for their noisy features and high dimensions. This shows that ensemble machine learning is promising and the future of software defect prediction.</jats:p>",
        "link": "https://doi.org/10.33140/amlai.02.01.03",
        "published": "2021-08-23T06:17:45Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_473.txt",
        "pdf_path": null
    },
    {
        "title": "Determinantal Point Processes for Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1561/2200000044",
        "published": "2012-12-18T10:48:57Z",
        "pdf_url": "http://www.nowpublishers.com/article/Download/MAL-044",
        "txt_path": "data/txt/machine learning_paper_474.txt",
        "pdf_path": null
    },
    {
        "title": "Guest Editors' Introduction: Machine Learning and Natural Language",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007580931600",
        "published": "2002-12-22T05:04:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007580931600.pdf",
        "txt_path": "data/txt/machine learning_paper_475.txt",
        "pdf_path": "data/pdfs/machine learning_paper_475.pdf"
    },
    {
        "title": "Chapter 2: Introduction to Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1515/9781683924654-003",
        "published": "2023-08-08T05:15:08Z",
        "pdf_url": "https://www.degruyter.com/document/doi/10.1515/9781683924654-003/xml",
        "txt_path": "data/txt/machine learning_paper_476.txt",
        "pdf_path": null
    },
    {
        "title": "Chapter 3: Classifiers in Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1515/9781683924654-004",
        "published": "2023-08-08T05:15:08Z",
        "pdf_url": "https://www.degruyter.com/document/doi/10.1515/9781683924654-004/xml",
        "txt_path": "data/txt/machine learning_paper_477.txt",
        "pdf_path": null
    },
    {
        "title": "The Difference of Machine Learning and Deep Learning Algorithms",
        "abstract": "<jats:p>In the information era, enormous amounts of data have become available on hand to decision makers. Big data refers to datasets that are not only big, but also high in variety and velocity, which makes them difficult to handle using traditional tools and techniques. Due to the rapid growth of such data, solutions need to be studiedand provided in order to handle and extract value and knowledge from these datasets. Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. Such minimal human intervention can be provided using big data analytics, which is the application of advanced analytics techniques on big data. This paper aims to analyse some of the different machine learning algorithms and methods which can be applied to big data analysis, as well as the opportunities provided by the application of big data analytics in various decision making domains.</jats:p>",
        "link": "https://doi.org/10.5121/csit.2021.111519",
        "published": "2021-09-28T15:58:40Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_478.txt",
        "pdf_path": null
    },
    {
        "title": "Kernel methods for green machine learning technologies",
        "abstract": "",
        "link": "https://doi.org/10.1017/cbo9781139176224.019",
        "published": "2014-07-15T06:09:58Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/D081502FD6173AC8A0BBD9BE03E5DDB2",
        "txt_path": "data/txt/machine learning_paper_479.txt",
        "pdf_path": null
    },
    {
        "title": "Efficient machine learning-assisted failure analysis method for circuit-level defect prediction",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2024.100537",
        "published": "2024-02-25T00:12:12Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827024000136?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_480.txt",
        "pdf_path": null
    },
    {
        "title": "Martin Hilbert Discusses the Necessity of Big Data for Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.4135/9781529795417.n1",
        "published": "2022-06-24T09:07:23Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_481.txt",
        "pdf_path": null
    },
    {
        "title": "Learning Curves in Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-4899-7687-1_452",
        "published": "2019-03-20T20:09:45Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-1-4899-7687-1_452",
        "txt_path": "data/txt/machine learning_paper_482.txt",
        "pdf_path": null
    },
    {
        "title": "Martin Hilbert Discusses Google Translate as an Example of Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.4135/9781529795417.n2",
        "published": "2022-06-24T13:07:23Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_483.txt",
        "pdf_path": null
    },
    {
        "title": "Fundamentals of Machine Learning",
        "abstract": "<p>Machine learning is exploding, both in research and for industrial applications. This book aims to be a brief introduction to this area given the importance of this topic in many disciplines, from sciences to engineering, and even for its broader impact on our society. This book tries to contribute with a style that keeps a balance between brevity of explanations, the rigor of mathematical arguments, and outlining principle ideas. At the same time, this book tries to give some comprehensive overview of a variety of methods to see their relation on specialization within this area. This includes some introduction to Bayesian approaches to modeling as well as deep learning. Writing small programs to apply machine learning techniques is made easy today by the availability of high-level programming systems. This book offers examples in Python with the machine learning libraries sklearn and Keras. The first four chapters concentrate largely on the practical side of applying machine learning techniques. The book then discusses more fundamental concepts and includes their formulation in a probabilistic context. This is followed by chapters on advanced models, that of recurrent neural networks and that of reinforcement learning. The book closes with a brief discussion on the impact of machine learning and AI on our society.</p>",
        "link": "https://doi.org/10.1093/oso/9780198828044.001.0001",
        "published": "2020-01-23T10:55:59Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_484.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1201/9781003119258-3",
        "published": "2022-07-04T23:30:20Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_485.txt",
        "pdf_path": null
    },
    {
        "title": "The Bayesian Approach to Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1201/9781466506299-7",
        "published": "2020-12-23T07:24:00Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_486.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning: When and Where the Horses Went Astray?",
        "abstract": "",
        "link": "https://doi.org/10.5772/9156",
        "published": "2012-03-23T19:40:22Z",
        "pdf_url": "https://www.intechopen.com/download/pdf/10447",
        "txt_path": "data/txt/machine learning_paper_487.txt",
        "pdf_path": null
    },
    {
        "title": "The background of machine learning algorithms",
        "abstract": "",
        "link": "https://doi.org/10.1049/pbpc039e_ch4",
        "published": "2021-03-24T04:09:26Z",
        "pdf_url": "https://digital-library.theiet.org/content/books/10.1049/pbpc039e_ch4?crawler=true&mimetype=application/pdf",
        "txt_path": "data/txt/machine learning_paper_488.txt",
        "pdf_path": null
    },
    {
        "title": "Learning Curves in Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/springerreference_179164",
        "published": "2012-02-07T13:44:39Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_489.txt",
        "pdf_path": null
    },
    {
        "title": "Federated Machine Learning for Systems Medicine",
        "abstract": "",
        "link": "https://doi.org/10.14293/gof.23.06",
        "published": "2023-10-09T15:45:25Z",
        "pdf_url": "https://scienceopen.com/hosted-document?doi=10.14293/GOF.23.06",
        "txt_path": "data/txt/machine learning_paper_490.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning based medical image deepfake detection: A comparative study",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2022.100298",
        "published": "2022-04-11T16:32:51Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827022000263?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_491.txt",
        "pdf_path": null
    },
    {
        "title": "Simple Machine Learning Algorithms",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-030-65900-4_4",
        "published": "2021-02-12T15:21:32Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-3-030-65900-4_4",
        "txt_path": "data/txt/machine learning_paper_492.txt",
        "pdf_path": null
    },
    {
        "title": "Guest Editors' Introduction: On Applied Research in Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007442505281",
        "published": "2002-12-22T04:48:21Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007442505281.pdf",
        "txt_path": "data/txt/machine learning_paper_493.txt",
        "pdf_path": "data/pdfs/machine learning_paper_493.pdf"
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-031-14634-3_4",
        "published": "2022-10-17T15:06:32Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-031-14634-3_4",
        "txt_path": "data/txt/machine learning_paper_494.txt",
        "pdf_path": null
    },
    {
        "title": "Evaluation and Selection of Biases in Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022630017346",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022630017346.pdf",
        "txt_path": "data/txt/machine learning_paper_495.txt",
        "pdf_path": "data/pdfs/machine learning_paper_495.pdf"
    },
    {
        "title": "Statistical Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-12-802121-7.00012-1",
        "published": "2016-02-05T20:17:02Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9780128021217000121?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_496.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Application: Flight Delay Prediction",
        "abstract": "",
        "link": "https://doi.org/10.5220/0013486400004619",
        "published": "2025-07-01T22:23:11Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_497.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning for an explainable cost prediction of medical insurance",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2023.100516",
        "published": "2023-11-24T17:21:17Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827023000695?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_498.txt",
        "pdf_path": null
    },
    {
        "title": "Probably Almost Discriminative Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022870506888",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022870506888.pdf",
        "txt_path": "data/txt/machine learning_paper_499.txt",
        "pdf_path": "data/pdfs/machine learning_paper_499.pdf"
    },
    {
        "title": "Intelligent Learning Analytics in Healthcare Sector Using Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-030-40850-3_3",
        "published": "2020-03-09T17:02:44Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-3-030-40850-3_3",
        "txt_path": "data/txt/machine learning_paper_500.txt",
        "pdf_path": null
    },
    {
        "title": "Hyperparameter Optimization in Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-4842-6579-6",
        "published": "2020-11-28T11:02:33Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-1-4842-6579-6.pdf",
        "txt_path": "data/txt/machine learning_paper_501.txt",
        "pdf_path": null
    },
    {
        "title": "Sociogeographical Machine Learning",
        "abstract": "<jats:title>Abstract</jats:title>\n               <jats:p>This chapter delves into the integration of machine learning (ML) within spatial social science, elucidating its capacity for enhancing the analysis of sociogeographical data. It underscores the distinction between spatial and non-spatial data, emphasizing the importance of spatial context in understanding social phenomena. By exploring various ML methodologies, the chapter assesses their implications for sociogeographical studies, advocating for the incorporation of ML techniques to unravel complex social dynamics within geographical contexts. Through a detailed examination of both unsupervised and supervised learning models, it demonstrates the pivotal role of ML in identifying and categorizing sociospatial phenomena, offering insights into neighborhood effects and the theoretical and practical challenges of applying ML in spatial analysis. The chapter not only showcases the potential of ML to advance spatial social science but also calls for a nuanced understanding of the questions that necessitate ML approaches, positioning ML as a critical tool for future sociospatial research endeavors.</jats:p>",
        "link": "https://doi.org/10.1093/oxfordhb/9780197653609.013.18",
        "published": "2024-03-19T19:42:41Z",
        "pdf_url": "https://academic.oup.com/edited-volume/55209/chapter/444214146",
        "txt_path": "data/txt/machine learning_paper_502.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in Python",
        "abstract": "<jats:p>Diabetes is a disease of the modern world. The modern lifestyle has led to unhealthy eating habits causing type 2 diabetes. Machine learning has gained a lot of popularity in the recent days. It has applications in various fields and has proven to be increasingly effective in the medical field. The purpose of this chapter is to predict the diabetes outcome of a person based on other factors or attributes. Various machine learning algorithms like logistic regression (LR), tuned and not tuned random forest (RF), and multilayer perceptron (MLP) have been used as classifiers for diabetes prediction. This chapter also presents a comparative study of these algorithms based on various performance metrics like accuracy, sensitivity, specificity, and F1 score. </jats:p>",
        "link": "https://doi.org/10.4018/978-1-6684-6291-1.ch046",
        "published": "2022-07-08T15:31:23Z",
        "pdf_url": "https://www.igi-global.com/viewtitle.aspx?TitleId=307489",
        "txt_path": "data/txt/machine learning_paper_503.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning for Healthcare Diagnostics",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-030-40850-3_5",
        "published": "2020-03-09T17:02:44Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-3-030-40850-3_5",
        "txt_path": "data/txt/machine learning_paper_504.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning and Information Retrieval",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-1-55860-377-6.50078-5",
        "published": "2014-06-30T23:01:24Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9781558603776500785?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_505.txt",
        "pdf_path": null
    },
    {
        "title": "Responsible Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781009003872.016",
        "published": "2024-11-07T00:06:30Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_506.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning for Automated Theorem Proving: Learning to Solve SAT and QSAT",
        "abstract": "",
        "link": "https://doi.org/10.1561/2200000081",
        "published": "2021-11-22T08:06:36Z",
        "pdf_url": "http://www.nowpublishers.com/article/Download/MAL-081",
        "txt_path": "data/txt/machine learning_paper_507.txt",
        "pdf_path": null
    },
    {
        "title": "Conformal Prediction for Reliable Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-12-398537-8.00014-6",
        "published": "2014-04-25T19:58:14Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_508.txt",
        "pdf_path": null
    },
    {
        "title": "Connections between Machine Learning and Bioinformatics",
        "abstract": "",
        "link": "https://doi.org/10.1201/b17186-10",
        "published": "2020-12-10T14:53:06Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_509.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Methods from Shallow Learning to Deep Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-031-69499-8_1",
        "published": "2024-10-12T18:01:28Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-031-69499-8_1",
        "txt_path": "data/txt/machine learning_paper_510.txt",
        "pdf_path": null
    },
    {
        "title": "Queries and Concept Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022821128753",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022821128753.pdf",
        "txt_path": "data/txt/machine learning_paper_511.txt",
        "pdf_path": "data/pdfs/machine learning_paper_511.pdf"
    },
    {
        "title": "Machine Learning for Anomaly Detection",
        "abstract": "",
        "link": "https://doi.org/10.1201/b10867-9",
        "published": "2011-05-23T15:23:45Z",
        "pdf_url": "http://www.crcnetbase.com/doi/pdf/10.1201/b10867-9",
        "txt_path": "data/txt/machine learning_paper_512.txt",
        "pdf_path": null
    },
    {
        "title": "A machine learning approach for hierarchical classification of software requirements",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2023.100457",
        "published": "2023-02-27T17:17:12Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827023000105?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_513.txt",
        "pdf_path": null
    },
    {
        "title": "Introduction to Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1002/9781119557500.ch1",
        "published": "2019-04-08T15:11:21Z",
        "pdf_url": "https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.1002%2F9781119557500.ch1",
        "txt_path": "data/txt/machine learning_paper_514.txt",
        "pdf_path": null
    },
    {
        "title": "Solving Real-World Problems with Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1201/b23383-16",
        "published": "2023-10-11T11:08:37Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_515.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Paradigms",
        "abstract": "",
        "link": "https://doi.org/10.1201/9780429342615-6",
        "published": "2020-08-20T15:29:25Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_516.txt",
        "pdf_path": null
    },
    {
        "title": "Unsupervised Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-4842-4961-1_7",
        "published": "2019-09-06T13:49:27Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-1-4842-4961-1_7",
        "txt_path": "data/txt/machine learning_paper_517.txt",
        "pdf_path": null
    },
    {
        "title": "Classic Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1026443024002",
        "published": "2003-11-06T11:45:40Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1026443024002.pdf",
        "txt_path": "data/txt/machine learning_paper_518.txt",
        "pdf_path": "data/pdfs/machine learning_paper_518.pdf"
    },
    {
        "title": "Theoretical Foundations for Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-08-050930-3.50005-1",
        "published": "2014-06-30T00:25:36Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9780080509303500051?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_519.txt",
        "pdf_path": null
    },
    {
        "title": "Mining commit messages to enhance software refactorings recommendation: A machine learning approach",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2022.100316",
        "published": "2022-05-14T15:41:53Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827022000354?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_520.txt",
        "pdf_path": null
    },
    {
        "title": "Automated Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-030-88132-0_1",
        "published": "2022-01-01T02:41:37Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-030-88132-0_1",
        "txt_path": "data/txt/machine learning_paper_521.txt",
        "pdf_path": null
    },
    {
        "title": "Deep Learning to Discover Coordinates for Dynamics: Autoencoders &amp; Physics Informed Machine Learning",
        "abstract": "<jats:p>In this video, we discuss how deep learning is being used to discover effective coordinate systems where simple dynamical systems models may be discovered.</jats:p>",
        "link": "https://doi.org/10.52843/cassyni.4zpjhl",
        "published": "2023-03-28T17:00:15Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_522.txt",
        "pdf_path": null
    },
    {
        "title": "Comprehension Grammars Generated from Machine Learning of Natural Languages",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022663208628",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022663208628.pdf",
        "txt_path": "data/txt/machine learning_paper_523.txt",
        "pdf_path": "data/pdfs/machine learning_paper_523.pdf"
    },
    {
        "title": "Machine Learning and Deep Learning Technologies",
        "abstract": "<jats:p>In the information era, enormous amounts of data have become available on hand to decision makers. Big data refers to datasets that are not only big, but also high in variety and velocity, which makes them difficult to handle using traditional tools and techniques. Due to the rapid growth of such data, solutions need to be studied and provided in order to handle and extract value and knowledge from these datasets. Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. Such minimal human intervention can be provided using machine learning, which is the application of advanced deep learning techniques on big data. This paper aims to analyse some of the different machine learning and deep learning algorithms and methods, aswell as the opportunities provided by the AI applications in various decision making domains.</jats:p>",
        "link": "https://doi.org/10.5121/csit.2021.111214",
        "published": "2021-08-24T05:18:25Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_524.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-031-11534-9_3",
        "published": "2022-08-29T06:03:37Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-031-11534-9_3",
        "txt_path": "data/txt/machine learning_paper_525.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.34235/ml",
        "published": "2019-09-10T22:43:53Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_526.txt",
        "pdf_path": null
    },
    {
        "title": "Interior-Point Methods in Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.7551/mitpress/8996.003.0014",
        "published": "2019-01-09T12:36:04Z",
        "pdf_url": "https://direct.mit.edu/books/edited-volume/chapter-pdf/2273490/9780262298773_cap.pdf",
        "txt_path": "data/txt/machine learning_paper_527.txt",
        "pdf_path": null
    },
    {
        "title": "Deploying Machine Learning Models",
        "abstract": "",
        "link": "https://doi.org/10.1002/9781119557500.ch12",
        "published": "2019-04-08T15:11:21Z",
        "pdf_url": "https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.1002%2F9781119557500.ch12",
        "txt_path": "data/txt/machine learning_paper_528.txt",
        "pdf_path": null
    },
    {
        "title": "The Morgan Kaufmann Series in Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-1-4832-0774-2.50001-9",
        "published": "2014-06-30T12:53:20Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9781483207742500019?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_529.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Preliminaries",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781009003872.005",
        "published": "2024-11-07T00:06:30Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_530.txt",
        "pdf_path": null
    },
    {
        "title": "Optimization, Machine Learning, and Fuzzy Logic",
        "abstract": "<jats:p>Machine learning, a cornerstone of AI, has revolutionized industries and technologies, empowering systems to adapt without direct programming. This abstract delves into the foundational principles of machine learning, elucidating the paradigms of supervised, unsupervised, and reinforcement learning. Supervised learning involves the task of training models on datasets, where each input is associated with a corresponding output. Unsupervised learning diverges from supervised learning by operating on unlabelled datasets, endeavouring to discern inherent structures and patterns autonomously. Principal component analysis (PCA) and other dimensionality reduction methods, such as K-means clustering algorithms, and association rule learning methods uncover latent insights within unannotated data, empowering data-driven decision-making. Reinforcement learning adopts an interactive paradigm, wherein agents navigate environments to accomplish predefined objectives.</jats:p>",
        "link": "https://doi.org/10.4018/979-8-3693-7352-1.ch001",
        "published": "2025-02-20T21:30:06Z",
        "pdf_url": "https://www.igi-global.com/viewtitle.aspx?TitleId=370654",
        "txt_path": "data/txt/machine learning_paper_531.txt",
        "pdf_path": null
    },
    {
        "title": "Corrigendum to “Machine learning for sports betting: should model selection be based on accuracy or calibration?” [Machine Learning with Applications Volume 16, June 2024, 100539]",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2025.100627",
        "published": "2025-02-08T12:33:24Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827025000106?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_532.txt",
        "pdf_path": null
    },
    {
        "title": "Data-driven market segmentation in hospitality using unsupervised machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2022.100414",
        "published": "2022-09-13T11:11:37Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827022000895?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_533.txt",
        "pdf_path": null
    },
    {
        "title": "Learning to Take Actions",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007571119753",
        "published": "2002-12-22T05:04:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007571119753.pdf",
        "txt_path": "data/txt/machine learning_paper_534.txt",
        "pdf_path": "data/pdfs/machine learning_paper_534.pdf"
    },
    {
        "title": "Machine Learning Techniques",
        "abstract": "",
        "link": "https://doi.org/10.1201/9780429342615-4",
        "published": "2020-08-20T15:29:25Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_535.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-84800-007-0_4",
        "published": "2007-12-20T22:07:36Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-1-84800-007-0_4.pdf",
        "txt_path": "data/txt/machine learning_paper_536.txt",
        "pdf_path": null
    },
    {
        "title": "Introduction to Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781108690935.003",
        "published": "2020-02-05T12:11:59Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/42B4B2D2E98F6EDBAC6C62CE92A08059",
        "txt_path": "data/txt/machine learning_paper_537.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Basics: A Comprehensive Guide.  A Review",
        "abstract": "<jats:p>The domain of machine learning has experienced an unparalleled increase in attention and implementation, becoming an essential component of diverse businesses. This review paper provides a thorough analysis of the comprehensive handbook named \"Machine Learning Basics: A Comprehensive Guide.\" Written by [Dr. Jane Doe], this guide has become a vital reference for those at all levels of expertise seeking to comprehend and traverse the intricate realm of machine learning.</jats:p>",
        "link": "https://doi.org/10.58496/bjml/2023/006",
        "published": "2024-04-27T16:51:51Z",
        "pdf_url": "https://mesopotamian.press/journals/index.php/BJML/article/download/214/203",
        "txt_path": "data/txt/machine learning_paper_538.txt",
        "pdf_path": "data/pdfs/machine learning_paper_538.pdf"
    },
    {
        "title": "Methods for large scale machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/cbo9781316402276.011",
        "published": "2016-09-05T05:02:11Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/74EBA2BDD0ECF36A127A6260C7AF1A57",
        "txt_path": "data/txt/machine learning_paper_539.txt",
        "pdf_path": null
    },
    {
        "title": "EXPLANATIONS, MACHINE LEARNING, AND CREATIVITY",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-08-051055-2.50005-5",
        "published": "2014-06-29T21:18:41Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9780080510552500055?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_540.txt",
        "pdf_path": null
    },
    {
        "title": "Adaptive Learning Machine",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-12-804566-4.00014-0",
        "published": "2018-10-26T18:52:39Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9780128045664000140?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_541.txt",
        "pdf_path": null
    },
    {
        "title": "",
        "abstract": "",
        "link": "https://doi.org/10.1117/12.2638492.6314287443112",
        "published": "2022-12-06T19:21:27Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_542.txt",
        "pdf_path": null
    },
    {
        "title": "How Artificial Intelligence and Machine Learning Work",
        "abstract": "",
        "link": "https://doi.org/10.4135/9789354791796.n4",
        "published": "2022-02-16T04:30:42Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_543.txt",
        "pdf_path": null
    },
    {
        "title": "DISCRIMINATIVE APPROACH TO STATISTICAL MACHINE LEARNING",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-12-802121-7.01604-6",
        "published": "2016-02-05T20:16:52Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9780128021217016046?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_544.txt",
        "pdf_path": null
    },
    {
        "title": "Conformal Prediction for Reliable Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-12-398537-8.00015-8",
        "published": "2014-04-25T19:58:14Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_545.txt",
        "pdf_path": null
    },
    {
        "title": "Errata",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1017306117718",
        "published": "2002-12-29T16:40:04Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1017306117718.pdf",
        "txt_path": "data/txt/machine learning_paper_546.txt",
        "pdf_path": "data/pdfs/machine learning_paper_546.pdf"
    },
    {
        "title": "Machine Discovery of Protein Motifs",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022673832367",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022673832367.pdf",
        "txt_path": "data/txt/machine learning_paper_547.txt",
        "pdf_path": "data/pdfs/machine learning_paper_547.pdf"
    },
    {
        "title": "Chapter 6 Advanced Machine Learning Techniques",
        "abstract": "",
        "link": "https://doi.org/10.1515/9783110697186-006",
        "published": "2024-08-22T18:47:27Z",
        "pdf_url": "https://www.degruyter.com/document/doi/10.1515/9783110697186-006/xml",
        "txt_path": "data/txt/machine learning_paper_548.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning-driven predictive modeling of mechanical properties in diverse steels",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2025.100634",
        "published": "2025-02-28T16:48:56Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827025000179?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_549.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in Asset Pricing",
        "abstract": "<p>Investors in financial markets are faced with an abundance of potentially value-relevant information from a wide variety of different sources. In such data-rich, high-dimensional environments, techniques from the rapidly advancing field of machine learning (ML) are well-suited for solving prediction problems. Accordingly, ML methods are quickly becoming part of the toolkit in asset pricing research and quantitative investing. This book examines the promises and challenges of ML applications in asset pricing. Asset pricing problems are substantially different from the settings for which ML tools were developed originally. To realize the potential of ML methods, they must be adapted for the specific conditions in asset pricing applications. Economic considerations, such as portfolio optimization, absence of near arbitrage, and investor learning can guide the selection and modification of ML tools. Beginning with a brief survey of basic supervised ML methods, the book discusses the application of these techniques in empirical research in asset pricing and shows how they promise to advance the theoretical modeling of financial markets. The book presents the exciting possibilities of using cutting-edge methods in research on financial asset valuation.</p>",
        "link": "https://doi.org/10.23943/princeton/9780691218700.001.0001",
        "published": "2022-05-23T12:43:35Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_550.txt",
        "pdf_path": null
    },
    {
        "title": "Erratum",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1017155901277",
        "published": "2002-12-29T15:19:29Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1017155901277.pdf",
        "txt_path": "data/txt/machine learning_paper_551.txt",
        "pdf_path": "data/pdfs/machine learning_paper_551.pdf"
    },
    {
        "title": "Machine Learning",
        "abstract": "<p>This article introduces the type of symbolic machine learning in which decision trees, rules, or case-based classifiers are induced from supervised training examples. It describes the representation of knowledge assumed by each of these approaches and reviews basic algorithms for inducing such representations from annotated training examples and using the acquired knowledge to classify future instances. Machine learning is the study of computational systems that improve performance on some task with experience. Most machine learning methods concern the task of categorizing examples described by a set of features. These techniques can be applied to learn knowledge required for a variety of problems in computational linguistics ranging from part-of-speech tagging and syntactic parsing to word-sense disambiguation and anaphora resolution. Finally, this article reviews the applications to a variety of these problems, such as morphology, part-of-speech tagging, word-sense disambiguation, syntactic parsing, semantic parsing, information extraction, and anaphora resolution.</p>",
        "link": "https://doi.org/10.1093/oxfordhb/9780199276349.013.0020",
        "published": "2013-02-13T10:39:15Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_552.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Operations for Accelerator Control",
        "abstract": "",
        "link": "https://doi.org/10.2172/1973632",
        "published": "2023-05-18T02:11:41Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_553.txt",
        "pdf_path": null
    },
    {
        "title": "Types of Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.4135/9781529688245",
        "published": "2024-03-22T14:03:49Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_554.txt",
        "pdf_path": null
    },
    {
        "title": "Learning Decision Lists",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022607331053",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022607331053.pdf",
        "txt_path": "data/txt/machine learning_paper_555.txt",
        "pdf_path": "data/pdfs/machine learning_paper_555.pdf"
    },
    {
        "title": "Machine Learning for Healthcare: Introduction",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-030-40850-3_1",
        "published": "2020-03-09T17:02:44Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-3-030-40850-3_1",
        "txt_path": "data/txt/machine learning_paper_556.txt",
        "pdf_path": null
    },
    {
        "title": "When and How to Use Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781009072205.003",
        "published": "2023-01-25T00:05:52Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_557.txt",
        "pdf_path": null
    },
    {
        "title": "Bias, noise, and interpretability in machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-12-815739-8.00017-1",
        "published": "2019-11-15T19:02:32Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9780128157398000171?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_558.txt",
        "pdf_path": null
    },
    {
        "title": "Beyond Machine Learning: Autonomous Learning",
        "abstract": "",
        "link": "https://doi.org/10.5220/0006090300970101",
        "published": "2016-11-18T06:36:27Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_559.txt",
        "pdf_path": null
    },
    {
        "title": "Applications of Density Ratios in Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/cbo9781139035613.012",
        "published": "2012-03-05T20:38:40Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/F2F5CF7A5E46570627739F17D67E7BB6",
        "txt_path": "data/txt/machine learning_paper_560.txt",
        "pdf_path": null
    },
    {
        "title": "XIMA: the in-ReRAM machine learning architecture",
        "abstract": "",
        "link": "https://doi.org/10.1049/pbpc039e_ch5",
        "published": "2021-03-24T08:09:26Z",
        "pdf_url": "https://digital-library.theiet.org/content/books/10.1049/pbpc039e_ch5?crawler=true&mimetype=application/pdf",
        "txt_path": "data/txt/machine learning_paper_561.txt",
        "pdf_path": null
    },
    {
        "title": "Reducing MEG interference using machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2023.100462",
        "published": "2023-03-18T02:11:16Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827023000154?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_562.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning for Scan Detection",
        "abstract": "",
        "link": "https://doi.org/10.1201/b10867-11",
        "published": "2011-05-23T19:23:45Z",
        "pdf_url": "http://www.crcnetbase.com/doi/pdf/10.1201/b10867-11",
        "txt_path": "data/txt/machine learning_paper_563.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning for Hybrid Detection",
        "abstract": "",
        "link": "https://doi.org/10.1201/b10867-10",
        "published": "2011-05-23T19:23:45Z",
        "pdf_url": "http://www.crcnetbase.com/doi/pdf/10.1201/b10867-10",
        "txt_path": "data/txt/machine learning_paper_564.txt",
        "pdf_path": null
    },
    {
        "title": "Introduction to Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-981-10-6808-9_3",
        "published": "2017-11-24T11:32:39Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-981-10-6808-9_3",
        "txt_path": "data/txt/machine learning_paper_565.txt",
        "pdf_path": null
    },
    {
        "title": "RESEARCH IN MACHINE LEARNING",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-08-051055-2.50004-3",
        "published": "2014-06-29T21:18:18Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9780080510552500043?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_566.txt",
        "pdf_path": null
    },
    {
        "title": "Special Issue of Machine Learning on Information Retrieval Introduction",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007676028106",
        "published": "2002-12-22T05:54:50Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007676028106.pdf",
        "txt_path": "data/txt/machine learning_paper_567.txt",
        "pdf_path": "data/pdfs/machine learning_paper_567.pdf"
    },
    {
        "title": "Machine learning-based identification of craniosynostosis in newborns",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2022.100292",
        "published": "2022-03-23T17:41:13Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827022000238?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_568.txt",
        "pdf_path": null
    },
    {
        "title": "Using machine learning for detecting liquidity risk in banks",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2023.100511",
        "published": "2023-11-19T03:31:31Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827023000646?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_569.txt",
        "pdf_path": null
    },
    {
        "title": "A Review of Machine Learning at AAAI-87",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022637632387",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022637632387.pdf",
        "txt_path": "data/txt/machine learning_paper_570.txt",
        "pdf_path": "data/pdfs/machine learning_paper_570.pdf"
    },
    {
        "title": "Non-convex Optimization for Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1561/2200000058",
        "published": "2017-12-04T10:44:31Z",
        "pdf_url": "http://www.nowpublishers.com/article/Download/MAL-058",
        "txt_path": "data/txt/machine learning_paper_571.txt",
        "pdf_path": null
    },
    {
        "title": "Detection of fraud in IoT based credit card collected dataset using machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2024.100603",
        "published": "2024-12-09T15:47:05Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827024000793?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_572.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Tutorial - Introduction to Machine Learning [Slides]",
        "abstract": "",
        "link": "https://doi.org/10.2172/1876777",
        "published": "2022-07-22T02:25:37Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_573.txt",
        "pdf_path": null
    },
    {
        "title": "Diagnosis of HIV (AIDS)  by Using deep learning and machine learning",
        "abstract": "<jats:p>Human Immunodeficiency Virus (HIV) is a global health issue that can progress to Acquired Immunodeficiency Syndrome (HIV) if not diagnosed and treated early. The advent of Artificial Intelligence (AI), particularly in machine learning and deep learning, presents new opportunities for improving the accuracy and efficiency of HIV diagnosis. This research explores the application of AI techniques in diagnosing HIV by reviewing previous studies and proposing a novel AI-based approach. The proposed methodology leverages deep learning algorithms, such as convolutional neural networks (CNNs), along with advanced data preprocessing techniques to enhance diagnostic accuracy, sensitivity, and specificity. The results of the proposed CNN-based model show an accuracy of 96.2%, sensitivity of 95.8%, specificity of 96.8%, and an AUC-ROC score of 0.965. Compared to Random Forest (accuracy: 92.1%), SVM (accuracy: 91.5%), and traditional methods (accuracy: 89.0%), the CNN model outperforms existing techniques significantly in terms of accuracy, sensitivity, and specificity. This demonstrates the effectiveness of the proposed AI approach for enhancing early and accurate HIV detection.\r\n </jats:p>",
        "link": "https://doi.org/10.58496/bjml/2023/012",
        "published": "2024-12-18T17:52:27Z",
        "pdf_url": "https://mesopotamian.press/journals/index.php/BJML/article/download/593/446",
        "txt_path": "data/txt/machine learning_paper_574.txt",
        "pdf_path": "data/pdfs/machine learning_paper_574.pdf"
    },
    {
        "title": "Categories of Attacks on Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-031-01580-9_3",
        "published": "2022-06-09T04:43:53Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-031-01580-9_3",
        "txt_path": "data/txt/machine learning_paper_575.txt",
        "pdf_path": null
    },
    {
        "title": "Supervised Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-4842-4961-1_6",
        "published": "2019-09-06T13:49:27Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-1-4842-4961-1_6",
        "txt_path": "data/txt/machine learning_paper_576.txt",
        "pdf_path": null
    },
    {
        "title": "A Review of Machine Learning at AAAI-87",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022637632387",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022637632387.pdf",
        "txt_path": "data/txt/machine learning_paper_577.txt",
        "pdf_path": "data/pdfs/machine learning_paper_577.pdf"
    },
    {
        "title": "Non-convex Optimization for Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1561/2200000058",
        "published": "2017-12-04T10:44:31Z",
        "pdf_url": "http://www.nowpublishers.com/article/Download/MAL-058",
        "txt_path": "data/txt/machine learning_paper_578.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Tutorial - Introduction to Machine Learning [Slides]",
        "abstract": "",
        "link": "https://doi.org/10.2172/1876777",
        "published": "2022-07-22T02:25:37Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_579.txt",
        "pdf_path": null
    },
    {
        "title": "A Nearest Hyperrectangle Learning Method",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022661727670",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022661727670.pdf",
        "txt_path": "data/txt/machine learning_paper_580.txt",
        "pdf_path": "data/pdfs/machine learning_paper_580.pdf"
    },
    {
        "title": "1. Introduction of machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1515/9783110595567-002",
        "published": "2020-05-27T16:39:43Z",
        "pdf_url": "https://www.degruyter.com/view/book/9783110595567/10.1515/9783110595567-002.xml",
        "txt_path": "data/txt/machine learning_paper_581.txt",
        "pdf_path": null
    },
    {
        "title": "Learning Logical Definitions from Relations",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022699322624",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022699322624.pdf",
        "txt_path": "data/txt/machine learning_paper_582.txt",
        "pdf_path": "data/pdfs/machine learning_paper_582.pdf"
    },
    {
        "title": "Machine Learning Through Data Mining",
        "abstract": "<jats:p>In dealing with information it often turns out that one has to face a huge amount of data, often not completely homogeneous and often without an immediate grasp of an underlying simple structure. Many records, each one instantiating many variables, are usually collected with the help of various technologies. Given the opportunity to have so many data not easy to correlate by the human reader, but probably hiding interesting properties, one of the typical goals one has in mind is to classify subjects on the basis of a hopefully reduced meaningful subset of the measured variables. The complexity of the problem makes it worthwhile to resort to automatic classification procedures. Then, the question arises of reconstructing a synthetic mathematical model, capturing the most important relations between variables, in order to both discriminate classes of subjects and possibly also infer rules of behaviours that could help identify their habits. Such interrelated aspects will be the focus of the present contribution. The data mining procedures that will be introduced in order to infer properties hidden in the data are in fact so powerful that care should be put in their capability to unveil regularities that the owner of the data would not want to let the processing tool discover, like for instance, in some cases the customer habits investigated via the usual smart card used in commerce with the apparent reward of discounting. Four main general purpose approaches will be briefly discussed in the present article, underlying the cost effectiveness of each one. In order to reduce the dimensionality of the problem, simplifying both the computation and the subsequent understanding of the solution, the critical issues of selecting the most salient variables must be addressed. This step may already be sensitive, pointing to the very core of the information to look at. A very simple approach is to resort to cascading a divisive partitioning of data orthogonal to the principal directions (PDDP) (Boley, 1998) already proven to be successful in the context of analyzing micro-arrays data (Garatti, Bittanti, Liberati, &amp; Maffezzoli, 2007). A more sophisticated possible approach is to resort to a rule induction method, like the one described in Muselli and Liberati (2000). Such a strategy also offers the advantage to extract underlying rules, implying conjunctions or disjunctions between the identified salient variables. Thus, a first idea of their even nonlinear relations is provided as a first step to design a representative model, whose variables will be the selected ones. Such an approach has been shown (Muselli &amp; Liberati, 2002) to be not less powerful over several benchmarks than the popular decision tree developed by Quinlan (1994). An alternative in this sense can be represented by Adaptive Bayesian networks (Yarmus, 2003) whose advantage is also to be available on a commercial wide spread data base tool like Oracle. Dynamics may matter. A possible approach to blindly build a simple linear approximating model is thus to resort to piece-wise affine (PWA) identification (Ferrari-Trecate, Muselli, Liberati, &amp; Morari, 2003). The joint use of (some of) such four approaches briefly described in this article, starting from data without known priors about their relationships, will allow to reduce dimensionality without significant loss in information, then to infer logical relationships, and, finally, to identify a simple input-output model of the involved process that also could be used for controlling purposes, even those potentially sensitive to ethical and security issues.</jats:p>",
        "link": "https://doi.org/10.4018/978-1-60960-818-7.ch103",
        "published": "2011-10-04T13:46:18Z",
        "pdf_url": "https://www.igi-global.com/viewtitle.aspx?TitleId=56128",
        "txt_path": "data/txt/machine learning_paper_583.txt",
        "pdf_path": null
    },
    {
        "title": "An Overview of Machine Learning Methods",
        "abstract": "",
        "link": "https://doi.org/10.1201/b15088-11",
        "published": "2013-11-21T19:53:59Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_584.txt",
        "pdf_path": null
    },
    {
        "title": "1. Lie group machine learning model",
        "abstract": "",
        "link": "https://doi.org/10.1515/9783110499506-001",
        "published": "2018-10-31T09:01:26Z",
        "pdf_url": "http://www.degruyter.com/view/books/9783110499506/9783110499506-001/9783110499506-001.xml",
        "txt_path": "data/txt/machine learning_paper_585.txt",
        "pdf_path": null
    },
    {
        "title": "Categories of Attacks on Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-031-01580-9_3",
        "published": "2022-06-09T04:43:53Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-031-01580-9_3",
        "txt_path": "data/txt/machine learning_paper_586.txt",
        "pdf_path": null
    },
    {
        "title": "Diagnosis of HIV (AIDS)  by Using deep learning and machine learning",
        "abstract": "<jats:p>Human Immunodeficiency Virus (HIV) is a global health issue that can progress to Acquired Immunodeficiency Syndrome (HIV) if not diagnosed and treated early. The advent of Artificial Intelligence (AI), particularly in machine learning and deep learning, presents new opportunities for improving the accuracy and efficiency of HIV diagnosis. This research explores the application of AI techniques in diagnosing HIV by reviewing previous studies and proposing a novel AI-based approach. The proposed methodology leverages deep learning algorithms, such as convolutional neural networks (CNNs), along with advanced data preprocessing techniques to enhance diagnostic accuracy, sensitivity, and specificity. The results of the proposed CNN-based model show an accuracy of 96.2%, sensitivity of 95.8%, specificity of 96.8%, and an AUC-ROC score of 0.965. Compared to Random Forest (accuracy: 92.1%), SVM (accuracy: 91.5%), and traditional methods (accuracy: 89.0%), the CNN model outperforms existing techniques significantly in terms of accuracy, sensitivity, and specificity. This demonstrates the effectiveness of the proposed AI approach for enhancing early and accurate HIV detection.\r\n </jats:p>",
        "link": "https://doi.org/10.58496/bjml/2023/012",
        "published": "2024-12-18T17:52:27Z",
        "pdf_url": "https://mesopotamian.press/journals/index.php/BJML/article/download/593/446",
        "txt_path": "data/txt/machine learning_paper_587.txt",
        "pdf_path": "data/pdfs/machine learning_paper_587.pdf"
    },
    {
        "title": "Machine Learning Utilized in Prognosis of Hypertension",
        "abstract": "",
        "link": "https://doi.org/10.5220/0012801300003885",
        "published": "2024-06-12T17:41:23Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_588.txt",
        "pdf_path": null
    },
    {
        "title": "Tools for fully data-driven machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/cbo9781316402276.007",
        "published": "2016-09-05T05:02:11Z",
        "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/A3312D22A390270E1B98921590EF22BC",
        "txt_path": "data/txt/machine learning_paper_589.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Algorithms",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-031-46990-9_3",
        "published": "2023-12-26T07:02:26Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-031-46990-9_3",
        "txt_path": "data/txt/machine learning_paper_590.txt",
        "pdf_path": null
    },
    {
        "title": "Editorial: Welcome to APL Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1063/5.0143646",
        "published": "2023-02-14T15:02:05Z",
        "pdf_url": "https://pubs.aip.org/aip/aml/article-pdf/doi/10.1063/5.0143646/16772082/010401_1_online.pdf",
        "txt_path": "data/txt/machine learning_paper_591.txt",
        "pdf_path": null
    },
    {
        "title": "Learning Function-Free Horn Expressions",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007610422992",
        "published": "2002-12-22T05:54:50Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007610422992.pdf",
        "txt_path": "data/txt/machine learning_paper_592.txt",
        "pdf_path": "data/pdfs/machine learning_paper_592.pdf"
    },
    {
        "title": "Pruning Algorithms for Rule Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007329424533",
        "published": "2002-12-22T04:48:21Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007329424533.pdf",
        "txt_path": "data/txt/machine learning_paper_593.txt",
        "pdf_path": "data/pdfs/machine learning_paper_593.pdf"
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-319-30717-6_4",
        "published": "2016-03-18T21:49:47Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-319-30717-6_4",
        "txt_path": "data/txt/machine learning_paper_594.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning for quantum physics and quantum physics for machine learning",
        "abstract": "<jats:p>Research at the intersection of machine learning (ML) and quantum physics is a recent growing field due to the enormous expectations and the success of both fields. ML is arguably one of the most promising technologies that has and will continue to disrupt many aspects of our lives. The way we do research is almost certainly no exception and ML, with its unprecedented ability to find hidden patterns in data, will be assisting future scientific discoveries. Quantum physics on the other side, even though it is sometimes not entirely intuitive, is one of the most successful physical theories and we are on the verge of adopting some quantum technologies in our daily life. Quantum many-body physics is a subfield of quantum physics where we study the collective behavior of particles or atoms and the emergence of phenomena that are due to this collective behavior, such as phases of matter. The study of phase transitions of these systems often requires some intuition of how we can quantify the order parameter of a phase. ML algorithms can imitate something similar to intuition by inferring knowledge from example data. They can, therefore, discover patterns that are invisible to the human eye, which makes them excellent candidates to study phase transitions. At the same time, quantum devices are known to be able to perform some computational task exponentially faster than classical computers and they are able to produce data patterns that are hard to simulate on classical computers. Therefore, there is the hope that ML algorithms run on quantum devices show an advantage over their classical analog. \r\n\r\nThis thesis is devoted to study two different paths along the front lines of ML and quantum physics. On one side, we study the use of neural networks (NN) to classify phases of mater in many-body quantum systems. On the other side, we study ML algorithms that run on quantum computers. The connection between ML for quantum physics and quantum physics for ML in this thesis is an emerging subfield in ML, the interpretability of learning algorithms. A crucial ingredient in the study of phase transitions with NNs is a better understanding of the predictions of the NN, to eventually infer a model of the quantum system and interpretability can assist us in this endeavor. The interpretability method that we study analyzes the influence of the training points on a test prediction and it depends on the curvature of the NN loss landscape. This further inspired an in-depth study of the loss of quantum machine learning (QML) applications which we as well will discuss. \r\n\r\nIn this thesis, we give answers to the questions of how we can leverage NNs to classify phases of matter and we use a method that allows to do domain adaptation to transfer the learned \"intuition\" from systems without noise onto systems with noise. To map the phase diagram of quantum many-body systems in a fully unsupervised manner, we study a method known from anomaly detection that allows us to reduce the human input to a mini mum. We will as well use interpretability methods to study NNs that are trained to distinguish phases of matter to understand if the NNs are learning something similar to an order parameter and if their way of learning can be made more accessible to humans. And finally, inspired by the interpretability of classical NNs, we develop tools to study the loss landscapes of variational quantum circuits to identify possible differences between classical and quantum ML algorithms that might be leveraged for a quantum advantage.</jats:p>\n        <jats:p>La investigación en la intersección del aprendizaje automático (machine learning, ML) y la física cuántica es una área en crecimiento reciente debido al éxito y las enormes expectativas de ambas áreas. ML es posiblemente una de las tecnologías más prometedoras que ha alterado y seguirá alterando muchos aspectos de nuestras vidas. Es casi seguro que la forma en que investigamos no es una excepción y el ML, con su capacidad sin precedentes para encontrar patrones ocultos en los datos ayudará a futuros descubrimientos científicos. La física cuántica, por otro lado, aunque a veces no es del todo intuitiva, es una de las teorías físicas más exitosas, y además estamos a punto de adoptar algunas tecnologías cuánticas en nuestra vida diaria. La física cuántica de los muchos cuerpos (many-body) es una subárea de la física cuántica donde estudiamos el comportamiento colectivo de partículas o átomos y la aparición de fenómenos que se deben a este comportamiento colectivo, como las fases de la materia. El estudio de las transiciones de fase de estos sistemas a menudo requiere cierta intuición de cómo podemos cuantificar el parámetro de orden de una fase. Los algoritmos de ML pueden imitar algo similar a la intuición al inferir conocimientos a partir de datos de ejemplo. Por lo tanto, pueden descubrir patrones que son invisibles para el ojo humano, lo que los convierte en excelentes candidatos para estudiar las transiciones de fase. Al mismo tiempo, se sabe que los dispositivos cuánticos pueden realizar algunas tareas computacionales exponencialmente más rápido que los ordenadores clásicos y pueden producir patrones de datos que son difíciles de simular en los ordenadores clásicos. Por lo tanto, existe la esperanza de que los algoritmos ML que se ejecutan en dispositivos cuánticos muestren una ventaja sobre su analógico clásico. Estudiamos dos caminos diferentes a lo largo de la vanguardia del ML y la física cuántica. Por un lado, estudiamos el uso de redes neuronales (neural network, NN) para clasificar las fases de la materia en sistemas cuánticos de muchos cuerpos. Por otro lado, estudiamos los algoritmos ML que se ejecutan en ordenadores cuánticos. La conexión entre ML para la física cuántica y la física cuántica para ML en esta tesis es un subárea emergente en ML: la interpretabilidad de los algoritmos de aprendizaje. Un ingrediente crucial en el estudio de las transiciones de fase con NN es una mejor comprensión de las predicciones de la NN, para inferir un modelo del sistema cuántico. Así pues, la interpretabilidad de la NN puede ayudarnos en este esfuerzo. El estudio de la interpretabilitad inspiró además un estudio en profundidad de la pérdida de aplicaciones de aprendizaje automático cuántico (quantum machine learning, QML) que también discutiremos. En esta tesis damos respuesta a las preguntas de cómo podemos aprovechar las NN para clasificar las fases de la materia y utilizamos un método que permite hacer una adaptación de dominio para transferir la \"intuición\" aprendida de sistemas sin ruido a sistemas con ruido. Para mapear el diagrama de fase de los sistemas cuánticos de muchos cuerpos de una manera totalmente no supervisada, estudiamos un método conocido de detección de anomalías que nos permite reducir la entrada humana al mínimo. También usaremos métodos de interpretabilidad para estudiar las NN que están entrenadas para distinguir fases de la materia para comprender si las NN están aprendiendo algo similar a un parámetro de orden y si su forma de aprendizaje puede ser más accesible para los humanos. Y finalmente, inspirados por la interpretabilidad de las NN clásicas, desarrollamos herramientas para estudiar los paisajes de pérdida de los circuitos cuánticos variacionales para identificar posibles diferencias entre los algoritmos ML clásicos y cuánticos que podrían aprovecharse para obtener una ventaja cuántica.</jats:p>",
        "link": "https://doi.org/10.5821/dissertation-2117-348901",
        "published": "2023-10-15T05:26:40Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_595.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning—Basics",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-4842-3069-5_4",
        "published": "2017-11-13T06:34:07Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-1-4842-3069-5_4",
        "txt_path": "data/txt/machine learning_paper_596.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning and deep learning in agriculture",
        "abstract": "",
        "link": "https://doi.org/10.1201/b22627-1",
        "published": "2020-12-10T10:57:28Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_597.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning for Biometrics",
        "abstract": "<jats:p>Biometrics aims at reliable and robust identification of humans from their personal traits, mainly for security and authentication purposes, but also for identifying and tracking the users of smarter applications. Frequently considered modalities are fingerprint, face, iris, palmprint and voice, but there are many other possible biometrics, including gait, ear image, retina, DNA, and even behaviours. This chapter presents a survey of machine learning methods used for biometrics applications, and identifies relevant research issues. The author focuses on three areas of interest: offline methods for biometric template construction and recognition, information fusion methods for integrating multiple biometrics to obtain robust results, and methods for dealing with temporal information. By introducing exemplary and influential machine learning approaches in the context of specific biometrics applications, the author hopes to provide the reader with the means to create novel machine learning solutions to challenging biometrics problems.</jats:p>",
        "link": "https://doi.org/10.4018/978-1-60960-818-7.ch402",
        "published": "2011-10-04T09:46:18Z",
        "pdf_url": "https://www.igi-global.com/viewtitle.aspx?TitleId=56172",
        "txt_path": "data/txt/machine learning_paper_598.txt",
        "pdf_path": null
    },
    {
        "title": "Machine learning tensile strength and impact toughness of wheat straw reinforced composites",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2021.100188",
        "published": "2021-10-25T21:47:58Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827021000943?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_599.txt",
        "pdf_path": null
    },
    {
        "title": "Erratum to “New interpretation of GNRVⓇ knee arthrometer results for ACL injury diagnosis support using machine learning” [Machine Learning with Applications 13 (2023) 100480]",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2024.100540",
        "published": "2024-03-02T10:01:40Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827024000161?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_600.txt",
        "pdf_path": null
    },
    {
        "title": "Azure Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-030-26622-6_22",
        "published": "2019-09-24T11:03:17Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-3-030-26622-6_22",
        "txt_path": "data/txt/machine learning_paper_601.txt",
        "pdf_path": null
    },
    {
        "title": "Basics of Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-4842-3564-5_1",
        "published": "2018-06-30T09:12:30Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-1-4842-3564-5_1",
        "txt_path": "data/txt/machine learning_paper_602.txt",
        "pdf_path": null
    },
    {
        "title": "Summarizing AI and Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.4135/9781071982747",
        "published": "2025-01-23T10:43:16Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_603.txt",
        "pdf_path": null
    },
    {
        "title": "Intrusion Detection System Based on Machine Learning Algorithms:( SVM and Genetic Algorithm)",
        "abstract": "<jats:p>The widespread utilization of the internet and computer systems has resulted in notable security concerns, characterized by a surge in intrusions and vulnerabilities. Malicious users manipulate internal systems, resulting in the exploitation of software flaws and default setups.   With the integration of the internet into society, there is an emergence of new risks such as viruses and worms, which highlights the importance of implementing robust security measures.   Intrusion detection systems (IDS) are security technologies utilized to monitor and analyze network traffic or system activity with the purpose of identifying hostile behavior.   This article presents a proposed method for detecting intrusion in network traffic using a hybrid approach, which combines a genetic algorithm and an SVM algorithm.   The model underwent training and testing on the KDDCup99 dataset, with a reduction in features from 42 to 29 using the hybrid approach.   The results demonstrated that throughout the system testing, it exhibited a remarkable accuracy of 0.999. Additionally, it achieved a true positive value of 0.9987 and a false negative rate of 0.012.</jats:p>",
        "link": "https://doi.org/10.58496/bjml/2024/002",
        "published": "2024-03-22T10:44:06Z",
        "pdf_url": "https://mesopotamian.press/journals/index.php/BJML/article/download/256/225",
        "txt_path": "data/txt/machine learning_paper_604.txt",
        "pdf_path": "data/pdfs/machine learning_paper_604.pdf"
    },
    {
        "title": "The mapping of machine learning algorithms on XIMA",
        "abstract": "",
        "link": "https://doi.org/10.1049/pbpc039e_ch6",
        "published": "2021-03-24T08:09:26Z",
        "pdf_url": "https://digital-library.theiet.org/content/books/10.1049/pbpc039e_ch6?crawler=true&mimetype=application/pdf",
        "txt_path": "data/txt/machine learning_paper_605.txt",
        "pdf_path": null
    },
    {
        "title": "Identifying Diseases and Diagnosis Using Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-030-40850-3_16",
        "published": "2020-03-09T13:02:44Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-3-030-40850-3_16",
        "txt_path": "data/txt/machine learning_paper_606.txt",
        "pdf_path": null
    },
    {
        "title": "Genetics-Based Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-4899-7687-1_100188",
        "published": "2020-06-01T22:42:06Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-1-4899-7687-1_100188",
        "txt_path": "data/txt/machine learning_paper_607.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.18356/9789210011143c004",
        "published": "2022-04-01T07:00:34Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_608.txt",
        "pdf_path": null
    },
    {
        "title": "AI/ML+Physics: Recap and Summary [Physics Informed Machine Learning]",
        "abstract": "<jats:p>This video provides a brief recap of this introductory series on Physics Informed Machine Learning.  We revisit the five stages of machine learning, and how physics may be incorporated into these stages.  We also discuss architectures, symmetries, the digital twin, applications in engineering, and the importance of dynamical systems and controls benchmarks.</jats:p>",
        "link": "https://doi.org/10.52843/cassyni.2mt4mr",
        "published": "2024-04-30T15:20:48Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_609.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in Sports 101",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-4842-5772-2_1",
        "published": "2020-08-24T08:03:59Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-1-4842-5772-2_1",
        "txt_path": "data/txt/machine learning_paper_610.txt",
        "pdf_path": null
    },
    {
        "title": "Semi-Supervised Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022653227824",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022653227824.pdf",
        "txt_path": "data/txt/machine learning_paper_611.txt",
        "pdf_path": "data/pdfs/machine learning_paper_611.pdf"
    },
    {
        "title": "Appendix G: Machine Learning Careers",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781009122092.027",
        "published": "2023-01-20T00:09:36Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_612.txt",
        "pdf_path": null
    },
    {
        "title": "Traditional Machine Learning Evaluation",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781009003872.006",
        "published": "2024-11-07T00:06:30Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_613.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781009004992.010",
        "published": "2023-11-27T00:05:48Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_614.txt",
        "pdf_path": null
    },
    {
        "title": "Using Azure Machine Learning Studio",
        "abstract": "",
        "link": "https://doi.org/10.1002/9781119557500.ch11",
        "published": "2019-04-08T15:11:21Z",
        "pdf_url": "https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.1002%2F9781119557500.ch11",
        "txt_path": "data/txt/machine learning_paper_615.txt",
        "pdf_path": null
    },
    {
        "title": "Signal processing and machine learning theory",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-32-391772-8.00006-5",
        "published": "2023-07-06T10:59:21Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9780323917728000065?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_616.txt",
        "pdf_path": null
    },
    {
        "title": "Chapter 5 Classic Machine Learning Algorithms",
        "abstract": "",
        "link": "https://doi.org/10.1515/9783110697186-005",
        "published": "2024-08-22T18:47:27Z",
        "pdf_url": "https://www.degruyter.com/document/doi/10.1515/9783110697186-005/xml",
        "txt_path": "data/txt/machine learning_paper_617.txt",
        "pdf_path": null
    },
    {
        "title": "Formal Machine Learning Algorithms",
        "abstract": "",
        "link": "https://doi.org/10.1201/9781351051507-3",
        "published": "2020-06-24T19:25:08Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_618.txt",
        "pdf_path": null
    },
    {
        "title": "Semisupervised Learning for Machine Translation",
        "abstract": "",
        "link": "https://doi.org/10.7551/mitpress/9780262072977.003.0012",
        "published": "2013-10-10T02:28:14Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_619.txt",
        "pdf_path": null
    },
    {
        "title": "Overview of Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1201/9781003230588-12",
        "published": "2023-06-14T08:08:32Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_620.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning for Profiling Network Traffic",
        "abstract": "",
        "link": "https://doi.org/10.1201/b10867-12",
        "published": "2021-04-10T23:28:27Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_621.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning and Game Playing",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-0-387-30164-8_504",
        "published": "2010-12-29T17:30:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-0-387-30164-8_504",
        "txt_path": "data/txt/machine learning_paper_622.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Tools for Geomorphic Mapping of Planetary Surfaces",
        "abstract": "",
        "link": "https://doi.org/10.5772/9146",
        "published": "2012-03-23T19:40:22Z",
        "pdf_url": "https://www.intechopen.com/download/pdf/10437",
        "txt_path": "data/txt/machine learning_paper_623.txt",
        "pdf_path": null
    },
    {
        "title": "Software for Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-4842-2250-8_3",
        "published": "2016-12-28T06:22:57Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-1-4842-2250-8_3",
        "txt_path": "data/txt/machine learning_paper_624.txt",
        "pdf_path": null
    },
    {
        "title": "Interpretable Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1201/9780367816377-16",
        "published": "2020-01-08T15:46:09Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_625.txt",
        "pdf_path": null
    },
    {
        "title": "MLlib: Machine Learning Library",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-4842-4961-1_5",
        "published": "2019-09-06T13:49:27Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-1-4842-4961-1_5",
        "txt_path": "data/txt/machine learning_paper_626.txt",
        "pdf_path": null
    },
    {
        "title": "Learning from Different Teachers",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022854802097",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022854802097.pdf",
        "txt_path": "data/txt/machine learning_paper_627.txt",
        "pdf_path": "data/pdfs/machine learning_paper_627.pdf"
    },
    {
        "title": "Deriving mapping functions to tie anthropometric measurements to body mass index via interpretable machine learning",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2022.100259",
        "published": "2022-01-28T10:37:45Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827022000068?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_628.txt",
        "pdf_path": null
    },
    {
        "title": "Chapter 1 Introduction to Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1515/9783110697186-001",
        "published": "2024-08-22T18:47:27Z",
        "pdf_url": "https://www.degruyter.com/document/doi/10.1515/9783110697186-001/xml",
        "txt_path": "data/txt/machine learning_paper_629.txt",
        "pdf_path": null
    },
    {
        "title": "1. Dynamic fuzzy machine learning model",
        "abstract": "",
        "link": "https://doi.org/10.1515/9783110520651-001",
        "published": "2017-12-22T22:20:11Z",
        "pdf_url": "https://www.degruyter.com/view/book/9783110520651/10.1515/9783110520651-001.xml",
        "txt_path": "data/txt/machine learning_paper_630.txt",
        "pdf_path": null
    },
    {
        "title": "Alarming Large Scale of Flight Delays: an Application of Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.5772/9142",
        "published": "2012-03-23T19:40:22Z",
        "pdf_url": "https://www.intechopen.com/download/pdf/10433",
        "txt_path": "data/txt/machine learning_paper_631.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Methods",
        "abstract": "",
        "link": "https://doi.org/10.5040/9781978725386.ch-2",
        "published": "2025-05-23T12:14:32Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_632.txt",
        "pdf_path": null
    },
    {
        "title": "Teachable Machine как стартовая точка в Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.34755/irok.2022.89.35.006",
        "published": "2024-12-16T11:42:49Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_633.txt",
        "pdf_path": null
    },
    {
        "title": "Book Review Machine Learning: A Theoretical Approach by Balas K. Natarajan. Morgan Kaufmann Publishers, Inc., 1991",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022691730976",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022691730976.pdf",
        "txt_path": "data/txt/machine learning_paper_634.txt",
        "pdf_path": "data/pdfs/machine learning_paper_634.pdf"
    },
    {
        "title": "What is Machine Learning?",
        "abstract": "",
        "link": "https://doi.org/10.4135/9781529688214",
        "published": "2024-03-22T13:44:08Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_635.txt",
        "pdf_path": null
    },
    {
        "title": "Overview of Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1017/9781009170239.004",
        "published": "2025-02-22T00:05:26Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_636.txt",
        "pdf_path": null
    },
    {
        "title": "Chapter 5 Introduction to Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1515/9781683924937-006",
        "published": "2023-08-08T04:43:08Z",
        "pdf_url": "https://www.degruyter.com/document/doi/10.1515/9781683924937-006/xml",
        "txt_path": "data/txt/machine learning_paper_637.txt",
        "pdf_path": null
    },
    {
        "title": "Medicine: Applications of Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-0-387-30164-8_530",
        "published": "2010-12-29T17:30:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-0-387-30164-8_530",
        "txt_path": "data/txt/machine learning_paper_638.txt",
        "pdf_path": null
    },
    {
        "title": "Dermatological Machine Learning Clinical Decision Support System",
        "abstract": "",
        "link": "https://doi.org/10.1201/9781315101323-2",
        "published": "2021-06-14T19:26:48Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_639.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1142/9789811228155_0002",
        "published": "2021-03-19T05:40:31Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_640.txt",
        "pdf_path": null
    },
    {
        "title": "Disease Detection System (DDS) Using Machine Learning Technique",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-030-40850-3_6",
        "published": "2020-03-09T17:02:44Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-3-030-40850-3_6",
        "txt_path": "data/txt/machine learning_paper_641.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in the Cloud",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-4842-5772-2_11",
        "published": "2020-08-24T08:03:59Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-1-4842-5772-2_11",
        "txt_path": "data/txt/machine learning_paper_642.txt",
        "pdf_path": null
    },
    {
        "title": "Interpretable trading pattern designed for machine learning applications",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2023.100448",
        "published": "2023-01-18T21:12:47Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827023000014?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_643.txt",
        "pdf_path": null
    },
    {
        "title": "Summarizing AI and Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.4135/9781071982587",
        "published": "2025-01-15T15:44:14Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_644.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-031-04648-3_4",
        "published": "2022-11-04T11:08:06Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-031-04648-3_4",
        "txt_path": "data/txt/machine learning_paper_645.txt",
        "pdf_path": null
    },
    {
        "title": "Chapter 4 Foundations of Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1515/9783110697186-004",
        "published": "2024-08-22T18:47:27Z",
        "pdf_url": "https://www.degruyter.com/document/doi/10.1515/9783110697186-004/xml",
        "txt_path": "data/txt/machine learning_paper_646.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning Basics",
        "abstract": "",
        "link": "https://doi.org/10.1533/9780857099440.59",
        "published": "2013-01-12T02:03:30Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B9781904275213500034?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_647.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning in Healthcare",
        "abstract": "",
        "link": "https://doi.org/10.1201/9781003189053-1",
        "published": "2022-03-17T13:03:25Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_648.txt",
        "pdf_path": null
    },
    {
        "title": "Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-3-030-18545-9_4",
        "published": "2019-06-29T07:15:19Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-3-030-18545-9_4",
        "txt_path": "data/txt/machine learning_paper_649.txt",
        "pdf_path": null
    },
    {
        "title": "Why Machine Learning and Artificial Intelligence?",
        "abstract": "",
        "link": "https://doi.org/10.1016/b978-0-08-050930-3.50004-x",
        "published": "2014-06-30T00:25:36Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:B978008050930350004X?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_650.txt",
        "pdf_path": null
    },
    {
        "title": "Adaptive Versus Nonadaptive Attribute-Efficient Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007616604496",
        "published": "2002-12-22T05:54:50Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007616604496.pdf",
        "txt_path": "data/txt/machine learning_paper_651.txt",
        "pdf_path": "data/pdfs/machine learning_paper_651.pdf"
    },
    {
        "title": "On Learning Sets and Functions",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022605311895",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022605311895.pdf",
        "txt_path": "data/txt/machine learning_paper_652.txt",
        "pdf_path": "data/pdfs/machine learning_paper_652.pdf"
    },
    {
        "title": "Online Learning versus Offline Learning",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007465907571",
        "published": "2002-12-22T04:48:21Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007465907571.pdf",
        "txt_path": "data/txt/machine learning_paper_653.txt",
        "pdf_path": "data/pdfs/machine learning_paper_653.pdf"
    },
    {
        "title": "Classification of Heart Rate Time Series Using Machine Learning Algorithms",
        "abstract": "<jats:p>An important diagnostic method for diagnosing abnormalities in the human heart is the electrocardiogram (ECG). A large number of heart patients increase the assignment of physicians. To reduce their assignment, an automatic computer detection system is needed. In this study, a computer system for classifying ECG signals is presented. The MIT-BIH, ECG arrhythmia database is used for analysis. After the ECG signal is noisy in the preprocessing stage, the data feature is extracted. In the feature extraction step, the decision tree is used and the support vector machine (SVM) is constructed to classify the ECG signal into two categories. It is normal or abnormal. The results show that the system classifies the given ECG signal with 90% sensitivity.</jats:p>",
        "link": "https://doi.org/10.33140/amlai.02.01.09",
        "published": "2021-10-28T06:24:37Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_654.txt",
        "pdf_path": null
    },
    {
        "title": "Acknowledgment to the Reviewers of Machine Learning and Knowledge Extraction in 2022",
        "abstract": "<jats:p>High-quality academic publishing is built on rigorous peer review [...]</jats:p>",
        "link": "https://doi.org/10.3390/make5010011",
        "published": "2023-01-18T08:28:38Z",
        "pdf_url": "https://www.mdpi.com/2504-4990/5/1/11/pdf",
        "txt_path": "data/txt/machine learning_paper_655.txt",
        "pdf_path": null
    },
    {
        "title": "Acknowledgment to Reviewers of Machine Learning and Knowledge Extraction in 2021",
        "abstract": "<jats:p>Rigorous peer-reviews are the basis of high-quality academic publishing [...]</jats:p>",
        "link": "https://doi.org/10.3390/make4010005",
        "published": "2022-01-29T10:26:17Z",
        "pdf_url": "https://www.mdpi.com/2504-4990/4/1/5/pdf",
        "txt_path": "data/txt/machine learning_paper_656.txt",
        "pdf_path": null
    },
    {
        "title": "Automating and Consuming Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-1-4842-5772-2_12",
        "published": "2020-08-24T08:03:59Z",
        "pdf_url": "http://link.springer.com/content/pdf/10.1007/978-1-4842-5772-2_12",
        "txt_path": "data/txt/machine learning_paper_657.txt",
        "pdf_path": null
    },
    {
        "title": "An Experimental Evaluation of Integrating Machine Learning with Knowledge Acquisition",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007504102006",
        "published": "2002-12-22T05:04:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007504102006.pdf",
        "txt_path": "data/txt/machine learning_paper_658.txt",
        "pdf_path": "data/pdfs/machine learning_paper_658.pdf"
    },
    {
        "title": "Machine Learning for IT Security",
        "abstract": "",
        "link": "https://doi.org/10.1007/978-0-387-30164-8_505",
        "published": "2010-12-29T17:30:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-0-387-30164-8_505",
        "txt_path": "data/txt/machine learning_paper_659.txt",
        "pdf_path": null
    },
    {
        "title": "Applications of Machine Learning and Deep Learning",
        "abstract": "",
        "link": "https://doi.org/10.2174/9781681089409121010011",
        "published": "2021-12-22T05:21:17Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_660.txt",
        "pdf_path": null
    },
    {
        "title": "Predicting severely imbalanced data disk drive failures with machine learning models",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2022.100361",
        "published": "2022-06-16T02:49:44Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827022000585?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_661.txt",
        "pdf_path": null
    },
    {
        "title": "Reinforcement learning for control of valves",
        "abstract": "",
        "link": "https://doi.org/10.1016/j.mlwa.2021.100030",
        "published": "2021-03-27T00:34:05Z",
        "pdf_url": "https://api.elsevier.com/content/article/PII:S2666827021000116?httpAccept=text/xml",
        "txt_path": "data/txt/machine learning_paper_662.txt",
        "pdf_path": null
    },
    {
        "title": "Learning from Cluster Examples",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1026351106797",
        "published": "2003-11-03T19:30:08Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1026351106797.pdf",
        "txt_path": "data/txt/machine learning_paper_663.txt",
        "pdf_path": "data/pdfs/machine learning_paper_663.pdf"
    },
    {
        "title": "Machine Discovery of Effective Admissible Heuristics",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022875501978",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022875501978.pdf",
        "txt_path": "data/txt/machine learning_paper_664.txt",
        "pdf_path": "data/pdfs/machine learning_paper_664.pdf"
    },
    {
        "title": "Introduction: Special Issue on Computational Learning Theory",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022615931710",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022615931710.pdf",
        "txt_path": "data/txt/machine learning_paper_665.txt",
        "pdf_path": "data/pdfs/machine learning_paper_665.pdf"
    },
    {
        "title": "Editorial: Launching <i>Machine Learning: Earth</i>—a new forum for machine learning in the Earth sciences",
        "abstract": "",
        "link": "https://doi.org/10.1088/3049-4753/adeb8b",
        "published": "2025-07-30T07:55:29Z",
        "pdf_url": "https://iopscience.iop.org/article/10.1088/3049-4753/adeb8b",
        "txt_path": "data/txt/machine learning_paper_666.txt",
        "pdf_path": null
    },
    {
        "title": "Introduction: Cognitive Autonomy in Machine Discovery",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022874916090",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022874916090.pdf",
        "txt_path": "data/txt/machine learning_paper_667.txt",
        "pdf_path": "data/pdfs/machine learning_paper_667.pdf"
    },
    {
        "title": "Introducing the Special Issue of Machine Learning Selected from Papers Presented at the 1997 Conference on Computational Learning Theory, COLT '97",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1007540111909",
        "published": "2002-12-22T05:04:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1007540111909.pdf",
        "txt_path": "data/txt/machine learning_paper_668.txt",
        "pdf_path": "data/pdfs/machine learning_paper_668.pdf"
    },
    {
        "title": "Machine Learning in Metabolic Engineering",
        "abstract": "",
        "link": "https://doi.org/10.1201/9781351029940-4",
        "published": "2018-08-31T20:12:43Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_669.txt",
        "pdf_path": null
    },
    {
        "title": "Matrix Calculus for Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1201/9781351051507-5",
        "published": "2020-06-24T19:25:08Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_670.txt",
        "pdf_path": null
    },
    {
        "title": "News and Notes",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022649902345",
        "published": "2003-04-04T16:55:36Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022649902345.pdf",
        "txt_path": "data/txt/machine learning_paper_671.txt",
        "pdf_path": "data/pdfs/machine learning_paper_671.pdf"
    },
    {
        "title": "Learning at the Knowledge Level",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022858530318",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022858530318.pdf",
        "txt_path": "data/txt/machine learning_paper_672.txt",
        "pdf_path": "data/pdfs/machine learning_paper_672.pdf"
    },
    {
        "title": "Learning From Noisy Examples",
        "abstract": "",
        "link": "https://doi.org/10.1023/a:1022873112823",
        "published": "2003-04-04T16:57:10Z",
        "pdf_url": "https://link.springer.com/content/pdf/10.1023/A:1022873112823.pdf",
        "txt_path": "data/txt/machine learning_paper_673.txt",
        "pdf_path": "data/pdfs/machine learning_paper_673.pdf"
    },
    {
        "title": "Different Machine Learning Models",
        "abstract": "",
        "link": "https://doi.org/10.1201/9780429342615-7",
        "published": "2020-08-20T15:29:25Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_674.txt",
        "pdf_path": null
    },
    {
        "title": "Fundamentals of Machine Learning",
        "abstract": "",
        "link": "https://doi.org/10.1201/9780429330131-1",
        "published": "2020-10-06T08:47:09Z",
        "pdf_url": null,
        "txt_path": "data/txt/machine learning_paper_675.txt",
        "pdf_path": null
    }
]